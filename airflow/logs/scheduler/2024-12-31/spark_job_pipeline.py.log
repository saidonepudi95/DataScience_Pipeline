[2024-12-31T01:21:29.665+0000] {processor.py:186} INFO - Started process (PID=17431) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:21:29.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:21:29.682+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:21:29.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:21:29.861+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:21:31.695+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:21:31.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:21:31.789+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:21:31.789+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:21:31.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 2.309 seconds
[2024-12-31T01:22:02.398+0000] {processor.py:186} INFO - Started process (PID=17464) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:22:02.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:22:02.463+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:22:02.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:22:02.755+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:22:02.856+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:22:02.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:22:02.904+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:22:02.903+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:22:02.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.629 seconds
[2024-12-31T01:22:33.909+0000] {processor.py:186} INFO - Started process (PID=17513) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:22:33.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:22:34.000+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:22:33.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:22:34.209+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:22:34.614+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:22:34.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:22:34.897+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:22:34.896+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:22:35.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.323 seconds
[2024-12-31T01:23:05.596+0000] {processor.py:186} INFO - Started process (PID=17588) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:23:05.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:23:05.607+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:23:05.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:23:05.691+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:23:05.858+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:23:05.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:23:05.961+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:23:05.961+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:23:06.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.431 seconds
[2024-12-31T01:23:36.191+0000] {processor.py:186} INFO - Started process (PID=17613) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:23:36.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:23:36.223+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:23:36.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:23:36.268+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:23:36.371+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:23:36.371+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:23:36.541+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:23:36.541+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:23:36.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.461 seconds
[2024-12-31T01:24:07.010+0000] {processor.py:186} INFO - Started process (PID=17639) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:24:07.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:24:07.017+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:24:07.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:24:07.078+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:24:07.143+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:24:07.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:24:07.216+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:24:07.216+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:24:07.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.277 seconds
[2024-12-31T01:24:38.000+0000] {processor.py:186} INFO - Started process (PID=17673) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:24:38.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:24:38.095+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:24:38.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:40:08.642+0000] {processor.py:186} INFO - Started process (PID=134) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:40:08.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:40:08.819+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:40:08.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:40:09.022+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:40:10.421+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:40:10.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:40:11.112+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:40:11.112+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:40:11.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 2.712 seconds
[2024-12-31T01:40:41.637+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:40:41.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:40:41.642+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:40:41.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:40:41.824+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:40:42.011+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:40:42.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:40:42.144+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:40:42.143+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:40:42.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.706 seconds
[2024-12-31T01:41:13.148+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:41:13.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:41:13.158+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:41:13.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:41:13.248+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:41:13.348+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:41:13.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:41:13.437+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:41:13.436+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:41:13.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.355 seconds
[2024-12-31T01:41:43.645+0000] {processor.py:186} INFO - Started process (PID=262) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:41:43.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:41:43.656+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:41:43.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:41:43.718+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:41:43.798+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:41:43.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:41:43.880+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:41:43.879+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:41:43.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.302 seconds
[2024-12-31T01:42:14.402+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:42:14.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:42:14.406+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:42:14.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:42:14.446+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:42:14.546+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:42:14.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:42:14.576+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:42:14.576+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:42:14.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.260 seconds
[2024-12-31T01:42:44.754+0000] {processor.py:186} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:42:44.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:42:44.757+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:42:44.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:42:44.779+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:42:44.814+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:42:44.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:42:44.848+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:42:44.848+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:42:44.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2024-12-31T01:43:15.106+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:43:15.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:43:15.116+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:43:15.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:43:15.173+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:43:15.204+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:43:15.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:43:15.230+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:43:15.230+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:43:15.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.160 seconds
[2024-12-31T01:43:45.724+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:43:45.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:43:45.732+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:43:45.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:43:45.769+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:43:45.816+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:43:45.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:43:45.858+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:43:45.857+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:43:45.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.179 seconds
[2024-12-31T01:44:16.364+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:44:16.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:44:16.369+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:44:16.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:44:16.393+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:44:16.434+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:44:16.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:44:16.468+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:44:16.468+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:44:16.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.141 seconds
[2024-12-31T01:44:47.015+0000] {processor.py:186} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:44:47.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:44:47.025+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:44:47.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:44:47.080+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:44:47.149+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:44:47.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:44:47.215+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:44:47.214+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:44:47.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.276 seconds
[2024-12-31T01:45:17.847+0000] {processor.py:186} INFO - Started process (PID=445) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:45:17.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:45:17.854+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:45:17.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:45:17.895+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:45:17.944+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:45:17.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:45:17.989+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:45:17.989+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:45:18.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.189 seconds
[2024-12-31T01:45:48.336+0000] {processor.py:186} INFO - Started process (PID=471) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:45:48.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:45:48.341+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:45:48.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:45:48.379+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:45:48.432+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:45:48.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:45:48.494+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:45:48.494+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:45:48.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.218 seconds
[2024-12-31T01:46:18.977+0000] {processor.py:186} INFO - Started process (PID=499) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:46:18.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:46:18.983+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:46:18.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:46:19.011+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:46:19.038+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:46:19.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:46:19.070+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:46:19.069+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:46:19.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2024-12-31T01:46:49.224+0000] {processor.py:186} INFO - Started process (PID=525) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:46:49.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:46:49.232+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:46:49.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:46:49.271+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:46:49.306+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:46:49.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:46:49.338+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:46:49.338+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:46:49.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.146 seconds
[2024-12-31T01:47:19.600+0000] {processor.py:186} INFO - Started process (PID=551) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:47:19.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:47:19.608+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:47:19.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:47:19.665+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:47:19.722+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:47:19.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:47:19.794+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:47:19.794+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:47:19.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.256 seconds
[2024-12-31T01:47:49.967+0000] {processor.py:186} INFO - Started process (PID=577) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:47:49.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:47:49.975+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:47:49.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:47:50.045+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:47:50.114+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:47:50.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:47:50.149+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:47:50.148+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:47:50.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.229 seconds
[2024-12-31T01:48:20.257+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:48:20.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:48:20.262+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:48:20.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:48:20.291+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:48:20.352+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:48:20.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:48:20.400+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:48:20.399+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:48:20.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.200 seconds
[2024-12-31T01:48:50.729+0000] {processor.py:186} INFO - Started process (PID=629) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:48:50.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:48:50.741+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:48:50.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:48:50.760+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:48:50.783+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:48:50.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:48:50.818+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:48:50.818+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:48:50.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2024-12-31T01:49:21.001+0000] {processor.py:186} INFO - Started process (PID=656) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:49:21.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T01:49:21.012+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:49:21.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:49:21.076+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T01:49:21.152+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:49:21.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T01:49:21.229+0000] {logging_mixin.py:190} INFO - [2024-12-31T01:49:21.227+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 00:00:00+00:00, run_after=2024-12-31 01:00:00+00:00
[2024-12-31T01:49:21.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.298 seconds
[2024-12-31T04:03:54.930+0000] {processor.py:186} INFO - Started process (PID=678) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T04:03:54.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T04:03:54.945+0000] {logging_mixin.py:190} INFO - [2024-12-31T04:03:54.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T04:03:55.541+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T04:03:55.747+0000] {logging_mixin.py:190} INFO - [2024-12-31T04:03:55.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T04:03:55.874+0000] {logging_mixin.py:190} INFO - [2024-12-31T04:03:55.873+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 03:00:00+00:00, run_after=2024-12-31 04:00:00+00:00
[2024-12-31T04:03:56.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.121 seconds
[2024-12-31T14:15:50.673+0000] {processor.py:186} INFO - Started process (PID=698) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:15:50.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T14:15:50.693+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:15:50.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:15:50.892+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:15:51.083+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:15:51.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T14:15:51.315+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:15:51.314+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 13:00:00+00:00, run_after=2024-12-31 14:00:00+00:00
[2024-12-31T14:15:51.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.937 seconds
[2024-12-31T14:16:22.497+0000] {processor.py:186} INFO - Started process (PID=737) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:16:22.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T14:16:22.502+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:16:22.502+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:16:22.542+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:16:22.579+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:16:22.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T14:16:22.635+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:16:22.635+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 13:00:00+00:00, run_after=2024-12-31 14:00:00+00:00
[2024-12-31T14:16:22.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.174 seconds
[2024-12-31T14:16:52.876+0000] {processor.py:186} INFO - Started process (PID=775) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:16:52.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T14:16:52.883+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:16:52.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:16:52.926+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:16:52.973+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:16:52.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T14:16:53.003+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:16:53.003+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 13:00:00+00:00, run_after=2024-12-31 14:00:00+00:00
[2024-12-31T14:16:53.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.161 seconds
[2024-12-31T14:17:23.781+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:17:23.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-31T14:17:23.794+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:17:23.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:17:23.836+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-31T14:17:23.886+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:17:23.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-31T14:17:23.941+0000] {logging_mixin.py:190} INFO - [2024-12-31T14:17:23.941+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-31 13:00:00+00:00, run_after=2024-12-31 14:00:00+00:00
[2024-12-31T14:17:23.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.205 seconds
