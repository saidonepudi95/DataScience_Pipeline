[2024-12-30T15:15:14.768+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:15:14.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:15:14.773+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:15:14.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:15:15.047+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:15:16.946+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:15:16.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:15:17.065+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:15:17.065+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:15:17.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 2.501 seconds
[2024-12-30T15:15:47.463+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:15:47.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:15:47.472+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:15:47.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:15:47.513+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:15:47.541+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:15:47.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:15:47.568+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:15:47.568+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:15:47.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2024-12-30T15:16:17.890+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:16:17.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:16:17.899+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:16:17.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:16:18.005+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:16:18.190+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:16:18.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:16:18.381+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:16:18.380+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:16:18.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.716 seconds
[2024-12-30T15:16:49.098+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:16:49.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:16:49.261+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:16:49.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:16:49.457+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:16:49.710+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:16:49.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:16:49.883+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:16:49.883+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:16:49.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.874 seconds
[2024-12-30T15:17:20.450+0000] {processor.py:186} INFO - Started process (PID=277) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:17:20.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:17:20.455+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:17:20.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:17:20.501+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:17:20.590+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:17:20.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:17:20.672+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:17:20.672+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:17:20.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.257 seconds
[2024-12-30T15:17:50.874+0000] {processor.py:186} INFO - Started process (PID=303) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:17:50.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:17:50.879+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:17:50.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:17:50.903+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:17:50.959+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:17:50.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:17:51.069+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:17:51.068+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:17:51.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.300 seconds
[2024-12-30T15:20:12.565+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:20:12.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:20:12.571+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:20:12.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:20:13.469+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:20:13.989+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:20:13.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:20:14.489+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:20:14.489+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:20:15.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 3.494 seconds
[2024-12-30T15:20:47.868+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:20:47.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:20:47.899+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:20:47.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:20:48.091+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:20:48.363+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:20:48.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:20:48.658+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:20:48.657+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:20:48.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.183 seconds
[2024-12-30T15:21:19.268+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:21:19.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:21:19.275+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:21:19.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:21:19.336+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:21:19.555+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:21:19.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:21:19.634+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:21:19.634+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:21:19.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.431 seconds
[2024-12-30T15:21:50.006+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:21:50.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:21:50.014+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:21:50.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:21:50.163+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:21:50.286+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:21:50.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:21:50.388+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:21:50.387+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:21:50.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.477 seconds
[2024-12-30T15:22:20.928+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:22:20.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:22:20.936+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:22:20.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:22:20.980+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:22:21.133+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:22:21.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:22:21.337+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:22:21.336+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:22:21.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.533 seconds
[2024-12-30T15:22:51.939+0000] {processor.py:186} INFO - Started process (PID=304) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:22:51.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:22:51.948+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:22:51.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:22:52.044+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:22:52.232+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:22:52.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:22:52.345+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:22:52.344+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:22:52.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.531 seconds
[2024-12-30T15:23:23.060+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:23:23.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:23:23.141+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:23:23.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:23:23.196+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:23:23.271+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:23:23.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:23:23.371+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:23:23.371+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:23:23.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.483 seconds
[2024-12-30T15:23:54.054+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:23:54.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:23:54.063+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:23:54.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:23:54.146+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:23:54.424+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:23:54.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:23:54.638+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:23:54.638+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:23:54.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.712 seconds
[2024-12-30T15:24:25.272+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:24:25.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:24:25.308+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:24:25.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:24:25.342+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:24:25.381+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:24:25.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:24:25.436+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:24:25.436+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:24:25.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.202 seconds
[2024-12-30T15:24:55.798+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:24:55.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:24:55.806+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:24:55.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:24:55.891+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:24:56.076+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:24:56.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:24:56.108+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:24:56.107+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:24:56.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.413 seconds
[2024-12-30T15:25:26.675+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:25:26.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:25:26.679+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:25:26.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:25:26.701+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:25:26.764+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:25:26.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:25:26.797+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:25:26.797+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:25:26.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.213 seconds
[2024-12-30T15:25:57.130+0000] {processor.py:186} INFO - Started process (PID=464) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:25:57.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:25:57.150+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:25:57.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:25:57.254+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:25:57.469+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:25:57.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:25:57.742+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:25:57.742+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:25:57.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.796 seconds
[2024-12-30T15:26:28.332+0000] {processor.py:186} INFO - Started process (PID=492) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:26:28.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:26:28.338+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:26:28.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:26:28.443+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:26:28.556+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:26:28.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:26:28.737+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:26:28.737+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:26:28.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.501 seconds
[2024-12-30T15:26:59.042+0000] {processor.py:186} INFO - Started process (PID=518) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:26:59.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:26:59.049+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:26:59.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:26:59.163+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:26:59.240+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:26:59.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:26:59.335+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:26:59.335+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:26:59.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.393 seconds
[2024-12-30T15:27:29.719+0000] {processor.py:186} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:27:29.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:27:29.726+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:27:29.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:27:29.761+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:27:29.829+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:27:29.828+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:27:29.919+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:27:29.918+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:27:30.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.297 seconds
[2024-12-30T15:28:00.500+0000] {processor.py:186} INFO - Started process (PID=571) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:28:00.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:28:00.507+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:28:00.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:28:00.571+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:28:00.652+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:28:00.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:28:00.780+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:28:00.779+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:28:00.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.331 seconds
[2024-12-30T15:28:31.381+0000] {processor.py:186} INFO - Started process (PID=597) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:28:31.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:28:31.393+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:28:31.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:28:31.499+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:28:31.694+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:28:31.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:28:31.800+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:28:31.799+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:28:31.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.539 seconds
[2024-12-30T15:29:02.467+0000] {processor.py:186} INFO - Started process (PID=623) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:29:02.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:29:02.477+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:29:02.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:29:02.571+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:29:02.696+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:29:02.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:29:02.868+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:29:02.868+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:29:02.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.544 seconds
[2024-12-30T15:29:33.520+0000] {processor.py:186} INFO - Started process (PID=649) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:29:33.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:29:33.557+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:29:33.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:29:33.632+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:29:33.777+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:29:33.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:29:33.969+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:29:33.969+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:29:34.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.579 seconds
[2024-12-30T15:30:04.661+0000] {processor.py:186} INFO - Started process (PID=675) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:30:04.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:30:04.667+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:30:04.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:30:04.703+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:30:04.779+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:30:04.779+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:30:04.874+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:30:04.874+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:30:04.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.292 seconds
[2024-12-30T15:30:35.604+0000] {processor.py:186} INFO - Started process (PID=701) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:30:35.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:30:35.610+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:30:35.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:30:35.647+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:30:35.783+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:30:35.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:30:35.911+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:30:35.911+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:30:36.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.418 seconds
[2024-12-30T15:31:06.691+0000] {processor.py:186} INFO - Started process (PID=727) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:31:06.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:31:06.701+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:31:06.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:31:06.793+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:31:06.912+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:31:06.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:31:07.006+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:31:07.006+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:31:07.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.375 seconds
[2024-12-30T15:31:37.678+0000] {processor.py:186} INFO - Started process (PID=752) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:31:37.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:31:37.685+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:31:37.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:31:37.778+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:31:37.828+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:31:37.828+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:31:38.004+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:31:38.004+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:31:38.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.493 seconds
[2024-12-30T15:32:08.664+0000] {processor.py:186} INFO - Started process (PID=778) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:32:08.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:32:08.672+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:32:08.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:32:08.770+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:32:09.061+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:32:09.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:32:09.389+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:32:09.388+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:32:09.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.923 seconds
[2024-12-30T15:32:39.988+0000] {processor.py:186} INFO - Started process (PID=804) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:32:39.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:32:39.999+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:32:39.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:32:40.083+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:32:40.263+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:32:40.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:32:40.397+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:32:40.396+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:32:40.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.524 seconds
[2024-12-30T15:33:11.115+0000] {processor.py:186} INFO - Started process (PID=830) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:33:11.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:33:11.146+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:33:11.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:33:11.193+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:33:11.341+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:33:11.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:33:11.455+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:33:11.455+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:33:11.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.453 seconds
[2024-12-30T15:33:42.120+0000] {processor.py:186} INFO - Started process (PID=856) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:33:42.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:33:42.152+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:33:42.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:33:42.222+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:33:42.374+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:33:42.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:33:42.478+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:33:42.478+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:33:42.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.476 seconds
[2024-12-30T15:34:13.156+0000] {processor.py:186} INFO - Started process (PID=880) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:34:13.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:34:13.163+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:34:13.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:34:13.224+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:34:13.306+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:34:13.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:34:13.456+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:34:13.455+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:34:13.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.348 seconds
[2024-12-30T15:34:43.644+0000] {processor.py:186} INFO - Started process (PID=903) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:34:43.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:34:43.654+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:34:43.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:34:43.731+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:34:43.809+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:34:43.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:34:43.878+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:34:43.878+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:34:43.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.317 seconds
[2024-12-30T15:35:15.042+0000] {processor.py:186} INFO - Started process (PID=932) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:35:15.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:35:15.053+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:35:15.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:35:15.154+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:35:15.360+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:35:15.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:35:15.465+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:35:15.465+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:35:15.661+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.668 seconds
[2024-12-30T15:35:46.282+0000] {processor.py:186} INFO - Started process (PID=963) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:35:46.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:35:46.333+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:35:46.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:35:46.427+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:35:46.537+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:35:46.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:35:46.666+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:35:46.666+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:35:46.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.485 seconds
[2024-12-30T15:36:17.298+0000] {processor.py:186} INFO - Started process (PID=989) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:36:17.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:36:17.304+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:36:17.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:36:17.340+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:36:17.374+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:36:17.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:36:17.449+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:36:17.449+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:36:17.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.228 seconds
[2024-12-30T15:36:48.024+0000] {processor.py:186} INFO - Started process (PID=1015) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:36:48.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:36:48.031+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:36:48.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:36:48.138+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:36:48.325+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:36:48.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:36:48.437+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:36:48.436+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:36:48.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.517 seconds
[2024-12-30T15:37:19.103+0000] {processor.py:186} INFO - Started process (PID=1039) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:37:19.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:37:19.108+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:37:19.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:37:19.196+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:37:19.308+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:37:19.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:37:19.392+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:37:19.392+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:37:19.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.369 seconds
[2024-12-30T15:37:49.942+0000] {processor.py:186} INFO - Started process (PID=1067) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:37:49.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:37:49.953+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:37:49.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:37:50.065+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:37:50.247+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:37:50.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:37:50.367+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:37:50.366+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:37:50.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.601 seconds
[2024-12-30T15:38:20.900+0000] {processor.py:186} INFO - Started process (PID=1093) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:38:20.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:38:20.904+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:38:20.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:38:20.932+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:38:20.967+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:38:20.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:38:21.044+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:38:21.043+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:38:21.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.225 seconds
[2024-12-30T15:38:51.586+0000] {processor.py:186} INFO - Started process (PID=1119) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:38:51.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:38:51.592+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:38:51.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:38:51.637+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:38:51.715+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:38:51.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:38:51.800+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:38:51.799+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:38:51.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.247 seconds
[2024-12-30T15:39:22.353+0000] {processor.py:186} INFO - Started process (PID=1146) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:39:22.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:39:22.371+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:39:22.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:39:22.459+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:39:22.560+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:39:22.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:39:22.774+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:39:22.774+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:39:22.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.556 seconds
[2024-12-30T15:39:53.385+0000] {processor.py:186} INFO - Started process (PID=1172) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:39:53.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:39:53.393+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:39:53.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:39:53.481+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:39:53.652+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:39:53.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:39:53.760+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:39:53.759+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:39:53.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.469 seconds
[2024-12-30T15:40:24.429+0000] {processor.py:186} INFO - Started process (PID=1197) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:40:24.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:40:24.436+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:40:24.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:40:24.481+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:40:24.571+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:40:24.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:40:24.740+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:40:24.740+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:40:25.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.606 seconds
[2024-12-30T15:40:55.552+0000] {processor.py:186} INFO - Started process (PID=1224) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:40:55.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:40:55.559+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:40:55.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:40:55.628+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:40:55.812+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:40:55.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:40:55.930+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:40:55.930+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:40:56.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.466 seconds
[2024-12-30T15:41:26.416+0000] {processor.py:186} INFO - Started process (PID=1250) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:41:26.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:41:26.421+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:41:26.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:41:26.507+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:41:26.578+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:41:26.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:41:26.612+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:41:26.612+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:41:26.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.292 seconds
[2024-12-30T15:41:56.758+0000] {processor.py:186} INFO - Started process (PID=1277) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:41:56.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:41:56.763+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:41:56.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:41:56.786+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:41:56.850+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:41:56.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:41:56.879+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:41:56.879+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:41:56.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.199 seconds
[2024-12-30T15:42:27.214+0000] {processor.py:186} INFO - Started process (PID=1303) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:42:27.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:42:27.218+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:42:27.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:42:27.248+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:42:27.320+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:42:27.319+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:42:27.359+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:42:27.358+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:42:27.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.256 seconds
[2024-12-30T15:42:57.819+0000] {processor.py:186} INFO - Started process (PID=1329) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:42:57.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:42:57.889+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:42:57.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:42:57.934+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:42:58.005+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:42:58.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:42:58.033+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:42:58.033+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:42:58.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.305 seconds
[2024-12-30T15:43:28.446+0000] {processor.py:186} INFO - Started process (PID=1354) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:43:28.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:43:28.454+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:43:28.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:43:28.500+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:43:28.621+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:43:28.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:43:28.741+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:43:28.741+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:43:28.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.402 seconds
[2024-12-30T15:43:59.040+0000] {processor.py:186} INFO - Started process (PID=1379) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:43:59.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:43:59.043+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:43:59.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:43:59.072+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:43:59.110+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:43:59.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:43:59.139+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:43:59.139+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:43:59.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.159 seconds
[2024-12-30T15:44:29.654+0000] {processor.py:186} INFO - Started process (PID=1408) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:44:29.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:44:29.692+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:44:29.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:44:29.775+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:44:29.854+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:44:29.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:44:29.889+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:44:29.889+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:44:29.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.321 seconds
[2024-12-30T15:45:00.340+0000] {processor.py:186} INFO - Started process (PID=1434) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:45:00.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:45:00.347+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:45:00.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:45:00.378+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:45:00.512+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:45:00.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:45:00.612+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:45:00.612+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:45:00.661+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.328 seconds
[2024-12-30T15:45:30.929+0000] {processor.py:186} INFO - Started process (PID=1460) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:45:30.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:45:30.936+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:45:30.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:45:30.990+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:45:31.090+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:45:31.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:45:31.135+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:45:31.134+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:45:31.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.314 seconds
[2024-12-30T15:46:01.575+0000] {processor.py:186} INFO - Started process (PID=1486) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:46:01.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:46:01.648+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:46:01.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:46:01.755+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:46:01.843+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:46:01.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:46:01.872+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:46:01.871+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:46:01.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.336 seconds
[2024-12-30T15:46:32.195+0000] {processor.py:186} INFO - Started process (PID=1513) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:46:32.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:46:32.207+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:46:32.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:46:32.318+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:46:32.456+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:46:32.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:46:32.610+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:46:32.610+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:46:32.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.556 seconds
[2024-12-30T15:47:02.917+0000] {processor.py:186} INFO - Started process (PID=1540) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:47:02.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:47:02.938+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:47:02.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:47:03.041+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:47:03.246+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:47:03.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:47:03.359+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:47:03.359+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:47:03.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.563 seconds
[2024-12-30T15:47:34.018+0000] {processor.py:186} INFO - Started process (PID=1566) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:47:34.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:47:34.084+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:47:34.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:47:34.181+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:47:34.311+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:47:34.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:47:34.496+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:47:34.496+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:47:34.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.680 seconds
[2024-12-30T15:48:05.245+0000] {processor.py:186} INFO - Started process (PID=1592) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:48:05.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:48:05.252+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:48:05.251+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:48:05.452+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:48:05.625+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:48:05.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:48:05.731+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:48:05.731+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:48:05.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.537 seconds
[2024-12-30T15:48:36.182+0000] {processor.py:186} INFO - Started process (PID=1624) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:48:36.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:48:36.189+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:48:36.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:48:36.223+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:48:36.331+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:48:36.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:48:36.498+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:48:36.497+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:48:36.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.416 seconds
[2024-12-30T15:49:07.025+0000] {processor.py:186} INFO - Started process (PID=1650) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:49:07.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:49:07.031+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:49:07.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:49:07.076+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:49:07.160+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:49:07.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:49:07.196+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:49:07.196+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:49:07.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.255 seconds
[2024-12-30T15:49:37.544+0000] {processor.py:186} INFO - Started process (PID=1676) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:49:37.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:49:37.553+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:49:37.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:49:37.647+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:49:37.743+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:49:37.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:49:37.791+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:49:37.791+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:49:37.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.356 seconds
[2024-12-30T15:50:08.338+0000] {processor.py:186} INFO - Started process (PID=1701) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:50:08.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:50:08.345+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:50:08.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:50:08.434+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:50:08.616+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:50:08.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:50:08.819+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:50:08.818+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:50:08.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.548 seconds
[2024-12-30T15:50:39.671+0000] {processor.py:186} INFO - Started process (PID=1728) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:50:39.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:50:39.675+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:50:39.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:50:39.719+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:50:39.757+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:50:39.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:50:39.817+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:50:39.817+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:50:39.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.238 seconds
[2024-12-30T15:51:10.390+0000] {processor.py:186} INFO - Started process (PID=1754) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:51:10.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:51:10.396+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:51:10.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:51:10.423+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:51:10.458+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:51:10.458+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:51:10.528+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:51:10.527+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:51:10.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.218 seconds
[2024-12-30T15:51:41.026+0000] {processor.py:186} INFO - Started process (PID=1780) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:51:41.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:51:41.032+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:51:41.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:51:41.092+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:51:41.126+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:51:41.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:51:41.396+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:51:41.395+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:51:41.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.512 seconds
[2024-12-30T15:52:12.021+0000] {processor.py:186} INFO - Started process (PID=1808) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:52:12.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:52:12.027+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:52:12.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:52:12.057+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:52:12.108+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:52:12.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:52:12.138+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:52:12.138+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:52:12.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.203 seconds
[2024-12-30T15:52:42.487+0000] {processor.py:186} INFO - Started process (PID=1833) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:52:42.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:52:42.494+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:52:42.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:52:42.539+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:52:42.606+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:52:42.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:52:42.696+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:52:42.696+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:52:42.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.319 seconds
[2024-12-30T15:53:13.288+0000] {processor.py:186} INFO - Started process (PID=1859) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:53:13.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:53:13.295+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:53:13.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:53:13.351+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:53:13.505+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:53:13.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:53:13.694+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:53:13.693+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:53:13.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.526 seconds
[2024-12-30T15:53:44.507+0000] {processor.py:186} INFO - Started process (PID=1884) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:53:44.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:53:44.520+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:53:44.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:53:44.709+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:53:44.849+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:53:44.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:53:45.029+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:53:45.029+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:53:45.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.850 seconds
[2024-12-30T15:54:15.775+0000] {processor.py:186} INFO - Started process (PID=1911) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:54:15.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:54:15.807+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:54:15.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:54:15.901+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:54:16.005+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:54:16.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:54:16.127+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:54:16.126+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:54:16.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.445 seconds
[2024-12-30T15:54:46.796+0000] {processor.py:186} INFO - Started process (PID=1937) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:54:46.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:54:46.802+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:54:46.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:54:46.833+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:54:47.008+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:54:47.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:54:47.135+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:54:47.134+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:54:47.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.426 seconds
[2024-12-30T15:55:18.109+0000] {processor.py:186} INFO - Started process (PID=1964) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:55:18.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:55:18.118+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:55:18.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:55:18.216+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:55:18.344+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:55:18.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:55:18.512+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:55:18.511+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:55:18.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.566 seconds
[2024-12-30T15:55:49.247+0000] {processor.py:186} INFO - Started process (PID=1990) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:55:49.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:55:49.258+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:55:49.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:55:49.420+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:55:49.714+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:55:49.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:55:49.848+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:55:49.848+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:55:50.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.796 seconds
[2024-12-30T15:56:20.631+0000] {processor.py:186} INFO - Started process (PID=2016) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:56:20.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:56:20.701+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:56:20.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:56:20.803+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:56:20.845+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:56:20.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:56:20.999+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:56:20.998+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:56:21.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.411 seconds
[2024-12-30T15:56:51.614+0000] {processor.py:186} INFO - Started process (PID=2042) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:56:51.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:56:51.621+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:56:51.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:56:51.666+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:56:51.796+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:56:51.795+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:56:51.843+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:56:51.843+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:56:51.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.335 seconds
[2024-12-30T15:57:22.587+0000] {processor.py:186} INFO - Started process (PID=2068) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:57:22.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:57:22.592+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:57:22.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:57:22.621+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:57:22.686+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:57:22.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:57:22.728+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:57:22.728+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:57:22.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.267 seconds
[2024-12-30T15:57:53.420+0000] {processor.py:186} INFO - Started process (PID=2094) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:57:53.423+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:57:53.481+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:57:53.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:57:53.554+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:57:53.688+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:57:53.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:57:53.809+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:57:53.808+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:57:53.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.515 seconds
[2024-12-30T15:58:24.493+0000] {processor.py:186} INFO - Started process (PID=2120) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:58:24.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:58:24.500+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:58:24.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:58:24.541+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:58:24.612+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:58:24.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:58:24.705+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:58:24.705+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:58:24.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.304 seconds
[2024-12-30T15:58:54.981+0000] {processor.py:186} INFO - Started process (PID=2152) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:58:54.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:58:54.987+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:58:54.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:58:55.158+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:58:55.373+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:58:55.371+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:58:55.567+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:58:55.566+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:58:55.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.684 seconds
[2024-12-30T15:59:26.094+0000] {processor.py:186} INFO - Started process (PID=2178) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:59:26.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:59:26.101+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:59:26.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:59:26.164+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:59:26.260+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:59:26.260+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:59:26.383+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:59:26.383+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:59:26.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.466 seconds
[2024-12-30T15:59:56.938+0000] {processor.py:186} INFO - Started process (PID=2204) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:59:56.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T15:59:56.944+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:59:56.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:59:56.997+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T15:59:57.088+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:59:57.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T15:59:57.213+0000] {logging_mixin.py:190} INFO - [2024-12-30T15:59:57.212+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 14:00:00+00:00, run_after=2024-12-30 15:00:00+00:00
[2024-12-30T15:59:57.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.455 seconds
[2024-12-30T16:00:28.083+0000] {processor.py:186} INFO - Started process (PID=2230) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:00:28.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:00:28.088+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:00:28.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:00:28.144+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:00:28.244+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:00:28.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:00:28.279+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:00:28.278+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:00:28.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.280 seconds
[2024-12-30T16:00:58.661+0000] {processor.py:186} INFO - Started process (PID=2256) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:00:58.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:00:58.670+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:00:58.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:00:58.746+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:00:58.930+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:00:58.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:00:59.055+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:00:59.054+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:00:59.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.693 seconds
[2024-12-30T16:01:29.572+0000] {processor.py:186} INFO - Started process (PID=2283) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:01:29.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:01:29.615+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:01:29.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:01:29.677+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:01:29.827+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:01:29.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:01:30.032+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:01:30.032+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:01:30.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.662 seconds
[2024-12-30T16:02:00.909+0000] {processor.py:186} INFO - Started process (PID=2309) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:02:00.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:02:00.916+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:02:00.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:02:00.973+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:02:01.113+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:02:01.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:02:01.211+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:02:01.210+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:02:01.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.459 seconds
[2024-12-30T16:02:31.904+0000] {processor.py:186} INFO - Started process (PID=2332) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:02:31.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:02:31.911+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:02:31.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:02:31.952+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:02:31.985+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:02:31.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:02:32.011+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:02:32.011+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:02:35.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 3.615 seconds
[2024-12-30T16:03:06.026+0000] {processor.py:186} INFO - Started process (PID=2365) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:03:06.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:03:06.037+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:03:06.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:03:06.124+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:03:06.296+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:03:06.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:03:06.369+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:03:06.368+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:03:06.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.428 seconds
[2024-12-30T16:03:36.762+0000] {processor.py:186} INFO - Started process (PID=2391) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:03:36.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:03:36.795+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:03:36.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:03:36.904+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:03:36.999+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:03:36.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:03:37.064+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:03:37.063+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:03:37.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.365 seconds
[2024-12-30T16:04:07.376+0000] {processor.py:186} INFO - Started process (PID=2416) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:04:07.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:04:07.380+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:04:07.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:04:07.417+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:04:07.449+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:04:07.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:04:07.473+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:04:07.472+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:04:07.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2024-12-30T16:04:38.057+0000] {processor.py:186} INFO - Started process (PID=2442) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:04:38.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:04:38.063+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:04:38.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:04:38.098+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:04:38.174+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:04:38.174+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:04:38.204+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:04:38.204+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:04:38.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.194 seconds
[2024-12-30T16:05:08.591+0000] {processor.py:186} INFO - Started process (PID=2468) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:05:08.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:05:08.600+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:05:08.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:05:08.676+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:05:08.756+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:05:08.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:05:08.861+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:05:08.860+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:05:08.920+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.350 seconds
[2024-12-30T16:05:39.429+0000] {processor.py:186} INFO - Started process (PID=2494) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:05:39.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:05:39.437+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:05:39.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:05:39.541+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:05:39.591+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:05:39.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:05:39.650+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:05:39.649+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:05:39.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.255 seconds
[2024-12-30T16:06:10.141+0000] {processor.py:186} INFO - Started process (PID=2519) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:06:10.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:06:10.147+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:06:10.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:06:10.191+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:06:10.240+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:06:10.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:06:10.294+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:06:10.294+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:06:10.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.201 seconds
[2024-12-30T16:06:40.663+0000] {processor.py:186} INFO - Started process (PID=2545) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:06:40.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:06:40.668+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:06:40.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:06:40.709+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:06:40.744+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:06:40.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:06:40.768+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:06:40.768+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:06:44.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 3.371 seconds
[2024-12-30T16:07:14.592+0000] {processor.py:186} INFO - Started process (PID=2578) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:07:14.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:07:14.607+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:07:14.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:07:14.684+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:07:14.803+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:07:14.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:07:14.851+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:07:14.850+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:07:14.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.348 seconds
[2024-12-30T16:07:45.205+0000] {processor.py:186} INFO - Started process (PID=2604) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:07:45.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:07:45.215+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:07:45.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:07:45.253+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:07:45.285+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:07:45.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:07:45.330+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:07:45.329+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:07:45.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.167 seconds
[2024-12-30T16:08:15.915+0000] {processor.py:186} INFO - Started process (PID=2630) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:08:15.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:08:15.926+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:08:15.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:08:16.062+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:08:16.168+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:08:16.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:08:16.199+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:08:16.198+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:08:16.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.370 seconds
[2024-12-30T16:08:46.825+0000] {processor.py:186} INFO - Started process (PID=2656) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:08:46.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:08:46.854+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:08:46.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:08:46.954+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:08:47.005+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:08:47.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:08:47.032+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:08:47.032+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:08:47.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.391 seconds
[2024-12-30T16:09:17.346+0000] {processor.py:186} INFO - Started process (PID=2682) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:09:17.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:09:17.356+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:09:17.355+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:09:17.412+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:09:17.460+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:09:17.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:09:17.501+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:09:17.501+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:09:17.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.209 seconds
[2024-12-30T16:09:47.810+0000] {processor.py:186} INFO - Started process (PID=2707) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:09:47.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:09:47.818+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:09:47.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:09:47.866+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:09:47.956+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:09:47.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:09:48.026+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:09:48.025+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:09:48.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.261 seconds
[2024-12-30T16:10:18.418+0000] {processor.py:186} INFO - Started process (PID=2734) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:10:18.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:10:18.425+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:10:18.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:10:18.467+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:10:18.529+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:10:18.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:10:18.570+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:10:18.570+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:10:18.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.224 seconds
[2024-12-30T16:10:48.866+0000] {processor.py:186} INFO - Started process (PID=2760) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:10:48.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:10:48.876+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:10:48.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:10:48.942+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:10:49.098+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:10:49.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:10:49.224+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:10:49.224+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:10:49.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.737 seconds
[2024-12-30T16:11:19.907+0000] {processor.py:186} INFO - Started process (PID=2786) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:11:19.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:11:19.913+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:11:19.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:11:19.962+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:11:20.013+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:11:20.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:11:20.058+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:11:20.058+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:11:20.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.197 seconds
[2024-12-30T16:11:50.614+0000] {processor.py:186} INFO - Started process (PID=2812) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:11:50.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:11:50.621+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:11:50.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:11:50.681+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:11:50.734+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:11:50.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:11:50.778+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:11:50.778+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:11:50.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.222 seconds
[2024-12-30T16:12:21.419+0000] {processor.py:186} INFO - Started process (PID=2838) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:12:21.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:12:21.424+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:12:21.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:12:21.455+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:12:21.486+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:12:21.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:12:21.513+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:12:21.513+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:12:21.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.178 seconds
[2024-12-30T16:12:51.792+0000] {processor.py:186} INFO - Started process (PID=2864) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:12:51.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:12:51.799+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:12:51.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:12:51.846+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:12:51.896+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:12:51.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:12:51.941+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:12:51.940+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:12:52.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.473 seconds
[2024-12-30T16:13:22.792+0000] {processor.py:186} INFO - Started process (PID=2890) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:13:22.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:13:22.802+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:13:22.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:13:22.884+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:13:22.966+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:13:22.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:13:23.040+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:13:23.040+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:13:23.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.314 seconds
[2024-12-30T16:13:53.681+0000] {processor.py:186} INFO - Started process (PID=2916) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:13:53.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:13:53.691+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:13:53.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:13:53.783+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:13:53.877+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:13:53.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:13:53.994+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:13:53.994+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:13:54.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.400 seconds
[2024-12-30T16:14:24.466+0000] {processor.py:186} INFO - Started process (PID=2943) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:14:24.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:14:24.474+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:14:24.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:14:24.557+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:14:24.681+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:14:24.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:14:24.792+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:14:24.792+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:14:24.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.375 seconds
[2024-12-30T16:14:55.348+0000] {processor.py:186} INFO - Started process (PID=2969) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:14:55.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:14:55.357+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:14:55.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:14:55.432+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:14:55.509+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:14:55.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:14:55.600+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:14:55.599+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:14:55.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.530 seconds
[2024-12-30T16:15:26.070+0000] {processor.py:186} INFO - Started process (PID=2995) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:15:26.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:15:26.081+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:15:26.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:15:26.172+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:15:26.271+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:15:26.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:15:26.356+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:15:26.355+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:15:26.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.364 seconds
[2024-12-30T16:15:56.948+0000] {processor.py:186} INFO - Started process (PID=3021) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:15:56.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:15:56.958+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:15:56.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:15:57.031+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:15:57.101+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:15:57.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:15:57.146+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:15:57.146+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:15:57.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.285 seconds
[2024-12-30T16:16:27.763+0000] {processor.py:186} INFO - Started process (PID=3047) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:16:27.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:16:27.773+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:16:27.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:16:27.849+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:16:27.964+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:16:27.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:16:28.117+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:16:28.117+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:16:28.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.479 seconds
[2024-12-30T16:16:59.018+0000] {processor.py:186} INFO - Started process (PID=3074) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:16:59.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:16:59.021+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:16:59.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:16:59.043+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:16:59.068+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:16:59.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:16:59.095+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:16:59.095+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:16:59.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.450 seconds
[2024-12-30T16:17:30.044+0000] {processor.py:186} INFO - Started process (PID=3100) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:17:30.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:17:30.095+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:17:30.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:17:30.209+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:17:30.504+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:17:30.503+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:17:30.710+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:17:30.709+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:17:30.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.801 seconds
[2024-12-30T16:18:01.502+0000] {processor.py:186} INFO - Started process (PID=3127) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:18:01.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:18:01.512+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:18:01.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:18:01.575+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:18:01.607+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:18:01.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:18:01.635+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:18:01.634+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:18:01.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.207 seconds
[2024-12-30T16:18:32.229+0000] {processor.py:186} INFO - Started process (PID=3153) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:18:32.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:18:32.239+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:18:32.238+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:18:32.322+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:18:32.405+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:18:32.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:18:32.480+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:18:32.479+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:18:32.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.324 seconds
[2024-12-30T16:19:03.131+0000] {processor.py:186} INFO - Started process (PID=3179) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:19:03.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:19:03.147+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:19:03.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:19:03.220+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:19:03.290+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:19:03.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:19:03.368+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:19:03.368+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:19:03.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.795 seconds
[2024-12-30T16:19:34.443+0000] {processor.py:186} INFO - Started process (PID=3204) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:19:34.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:19:34.455+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:19:34.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:19:34.534+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:19:34.581+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:19:34.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:19:34.634+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:19:34.633+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:19:34.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.302 seconds
[2024-12-30T16:20:05.311+0000] {processor.py:186} INFO - Started process (PID=3237) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:20:05.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:20:05.324+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:20:05.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:20:05.410+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:20:05.493+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:20:05.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:20:05.556+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:20:05.555+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:20:05.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.322 seconds
[2024-12-30T16:20:36.254+0000] {processor.py:186} INFO - Started process (PID=3264) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:20:36.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:20:36.267+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:20:36.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:20:36.321+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:20:36.382+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:20:36.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:20:36.454+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:20:36.454+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:20:36.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.272 seconds
[2024-12-30T16:21:07.153+0000] {processor.py:186} INFO - Started process (PID=3290) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:21:07.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:21:07.156+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:21:07.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:21:07.180+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:21:07.213+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:21:07.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:21:07.245+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:21:07.245+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:21:07.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.559 seconds
[2024-12-30T16:21:38.238+0000] {processor.py:186} INFO - Started process (PID=3317) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:21:38.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:21:38.246+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:21:38.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:21:38.297+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:21:38.350+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:21:38.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:21:38.410+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:21:38.409+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:21:38.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.244 seconds
[2024-12-30T16:22:09.026+0000] {processor.py:186} INFO - Started process (PID=3342) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:22:09.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:22:09.036+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:22:09.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:22:09.084+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:22:09.148+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:22:09.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:22:09.208+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:22:09.207+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:22:09.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.284 seconds
[2024-12-30T16:22:39.808+0000] {processor.py:186} INFO - Started process (PID=3368) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:22:39.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:22:39.857+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:22:39.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:22:39.911+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:22:40.006+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:22:40.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:22:40.079+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:22:40.079+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:22:40.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.337 seconds
[2024-12-30T16:23:10.671+0000] {processor.py:186} INFO - Started process (PID=3395) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:23:10.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:23:10.682+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:23:10.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:23:10.762+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:23:10.872+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:23:10.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:23:10.938+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:23:10.937+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:23:11.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.692 seconds
[2024-12-30T16:23:41.869+0000] {processor.py:186} INFO - Started process (PID=3421) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:23:41.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:23:41.890+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:23:41.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:23:41.927+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:23:42.020+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:23:42.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:23:42.092+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:23:42.091+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:23:42.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.297 seconds
[2024-12-30T16:24:12.723+0000] {processor.py:186} INFO - Started process (PID=3447) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:24:12.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:24:12.735+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:24:12.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:24:12.811+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:24:12.921+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:24:12.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:24:13.009+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:24:13.009+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:24:13.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.335 seconds
[2024-12-30T16:24:43.631+0000] {processor.py:186} INFO - Started process (PID=3474) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:24:43.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:24:43.642+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:24:43.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:24:43.727+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:24:43.915+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:24:43.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:24:43.979+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:24:43.978+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:24:44.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.427 seconds
[2024-12-30T16:25:14.224+0000] {processor.py:186} INFO - Started process (PID=3500) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:25:14.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:25:14.230+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:25:14.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:25:14.278+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:25:14.384+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:25:14.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:25:14.463+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:25:14.463+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:25:15.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.910 seconds
[2024-12-30T16:25:45.652+0000] {processor.py:186} INFO - Started process (PID=3526) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:25:45.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:25:45.662+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:25:45.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:25:45.718+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:25:45.808+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:25:45.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:25:45.884+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:25:45.884+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:25:45.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.303 seconds
[2024-12-30T16:26:16.460+0000] {processor.py:186} INFO - Started process (PID=3552) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:26:16.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:26:16.466+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:26:16.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:26:16.512+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:26:16.618+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:26:16.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:26:16.690+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:26:16.689+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:26:16.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.302 seconds
[2024-12-30T16:26:47.222+0000] {processor.py:186} INFO - Started process (PID=3578) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:26:47.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:26:47.233+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:26:47.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:26:47.312+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:26:47.494+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:26:47.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:26:47.635+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:26:47.634+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:26:47.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.491 seconds
[2024-12-30T16:27:18.142+0000] {processor.py:186} INFO - Started process (PID=3603) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:27:18.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:27:18.146+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:27:18.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:27:18.166+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:27:18.228+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:27:18.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:27:18.261+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:27:18.260+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:27:18.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.330 seconds
[2024-12-30T16:27:48.996+0000] {processor.py:186} INFO - Started process (PID=3628) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:27:48.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:27:49.007+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:27:49.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:27:49.071+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:27:49.171+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:27:49.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:27:49.333+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:27:49.333+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:27:49.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.444 seconds
[2024-12-30T16:28:19.965+0000] {processor.py:186} INFO - Started process (PID=3654) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:28:19.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:28:19.978+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:28:19.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:28:20.034+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:28:20.138+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:28:20.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:28:20.232+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:28:20.232+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:28:20.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.386 seconds
[2024-12-30T16:28:50.518+0000] {processor.py:186} INFO - Started process (PID=3680) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:28:50.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:28:50.524+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:28:50.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:28:50.593+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:28:50.701+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:28:50.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:28:50.772+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:28:50.772+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:28:50.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.322 seconds
[2024-12-30T16:29:21.370+0000] {processor.py:186} INFO - Started process (PID=3706) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:29:21.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:29:21.375+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:29:21.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:29:21.406+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:29:21.442+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:29:21.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:29:21.471+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:29:21.471+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:29:21.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.327 seconds
[2024-12-30T16:29:52.335+0000] {processor.py:186} INFO - Started process (PID=3733) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:29:52.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:29:52.345+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:29:52.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:29:52.440+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:29:52.526+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:29:52.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:29:52.631+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:29:52.629+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:29:52.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.414 seconds
[2024-12-30T16:30:23.025+0000] {processor.py:186} INFO - Started process (PID=3759) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:30:23.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:30:23.034+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:30:23.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:30:23.169+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:30:23.247+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:30:23.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:30:23.312+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:30:23.310+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:30:23.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.355 seconds
[2024-12-30T16:30:53.571+0000] {processor.py:186} INFO - Started process (PID=3779) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:30:53.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:30:53.583+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:30:53.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:30:53.692+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:30:53.889+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:30:53.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:30:54.175+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:30:54.174+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:30:54.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.758 seconds
[2024-12-30T16:31:24.831+0000] {processor.py:186} INFO - Started process (PID=3805) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:31:24.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:31:24.837+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:31:24.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:31:24.954+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:31:25.127+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:31:25.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:31:25.169+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:31:25.168+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:31:26.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.248 seconds
[2024-12-30T16:31:56.738+0000] {processor.py:186} INFO - Started process (PID=3837) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:31:56.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:31:56.748+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:31:56.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:31:56.905+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:31:57.031+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:31:57.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:31:57.310+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:31:57.309+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:31:57.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.787 seconds
[2024-12-30T16:32:28.105+0000] {processor.py:186} INFO - Started process (PID=3863) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:32:28.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:32:28.115+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:32:28.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:32:28.305+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:32:28.588+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:32:28.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:32:28.809+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:32:28.809+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:32:28.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.909 seconds
[2024-12-30T16:32:59.513+0000] {processor.py:186} INFO - Started process (PID=3889) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:32:59.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:32:59.519+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:32:59.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:32:59.767+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:32:59.975+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:32:59.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:33:00.171+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:33:00.170+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:33:00.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.708 seconds
[2024-12-30T16:33:30.769+0000] {processor.py:186} INFO - Started process (PID=3915) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:33:30.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:33:30.772+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:33:30.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:33:30.808+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:33:30.863+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:33:30.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:33:30.894+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:33:30.894+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:33:31.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.540 seconds
[2024-12-30T16:34:02.145+0000] {processor.py:186} INFO - Started process (PID=3941) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:34:02.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:34:02.149+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:34:02.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:34:02.202+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:34:02.263+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:34:02.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:34:02.284+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:34:02.284+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:34:02.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.236 seconds
[2024-12-30T16:34:32.657+0000] {processor.py:186} INFO - Started process (PID=3967) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:34:32.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:34:32.660+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:34:32.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:34:32.679+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:34:32.705+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:34:32.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:34:32.725+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:34:32.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:34:32.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-30T16:35:03.151+0000] {processor.py:186} INFO - Started process (PID=3991) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:35:03.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:35:03.154+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:35:03.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:35:03.178+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:35:03.210+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:35:03.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:35:03.232+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:35:03.231+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:35:03.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.184 seconds
[2024-12-30T16:35:33.446+0000] {processor.py:186} INFO - Started process (PID=4019) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:35:33.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:35:33.468+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:35:33.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:35:33.515+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:35:33.588+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:35:33.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:35:33.699+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:35:33.699+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:35:34.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.581 seconds
[2024-12-30T16:36:05.341+0000] {processor.py:186} INFO - Started process (PID=4044) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:36:05.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:36:05.344+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:36:05.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:36:05.376+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:36:05.424+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:36:05.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:36:05.469+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:36:05.469+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:36:05.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.173 seconds
[2024-12-30T16:36:35.813+0000] {processor.py:186} INFO - Started process (PID=4071) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:36:35.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:36:35.819+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:36:35.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:36:35.858+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:36:35.898+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:36:35.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:36:35.933+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:36:35.933+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:36:35.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.174 seconds
[2024-12-30T16:37:06.294+0000] {processor.py:186} INFO - Started process (PID=4097) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:37:06.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:37:06.298+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:37:06.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:37:06.319+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:37:06.367+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:37:06.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:37:06.388+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:37:06.388+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:37:06.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2024-12-30T16:37:36.618+0000] {processor.py:186} INFO - Started process (PID=4123) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:37:36.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:37:36.622+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:37:36.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:37:36.644+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:37:36.680+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:37:36.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:37:36.714+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:37:36.714+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:37:37.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.571 seconds
[2024-12-30T16:38:07.502+0000] {processor.py:186} INFO - Started process (PID=4149) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:38:07.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:38:07.506+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:38:07.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:38:07.528+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:38:07.580+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:38:07.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:38:07.955+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:38:07.954+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:38:07.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.481 seconds
[2024-12-30T16:38:38.218+0000] {processor.py:186} INFO - Started process (PID=4175) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:38:38.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:38:38.225+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:38:38.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:38:38.255+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:38:38.299+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:38:38.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:38:38.352+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:38:38.352+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:38:38.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.167 seconds
[2024-12-30T16:39:08.654+0000] {processor.py:186} INFO - Started process (PID=4201) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:39:08.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:39:08.659+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:39:08.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:39:08.688+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:39:08.767+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:39:08.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:39:08.842+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:39:08.842+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:39:08.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.222 seconds
[2024-12-30T16:39:39.122+0000] {processor.py:186} INFO - Started process (PID=4227) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:39:39.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:39:39.153+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:39:39.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:39:39.175+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:39:39.210+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:39:39.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:39:39.244+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:39:39.244+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:39:39.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.732 seconds
[2024-12-30T16:40:10.194+0000] {processor.py:186} INFO - Started process (PID=4254) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:40:10.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:40:10.197+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:40:10.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:40:10.222+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:40:10.256+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:40:10.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:40:10.730+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:40:10.730+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:40:10.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.576 seconds
[2024-12-30T16:40:41.090+0000] {processor.py:186} INFO - Started process (PID=4280) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:40:41.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:40:41.094+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:40:41.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:40:41.119+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:40:41.154+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:40:41.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:40:41.183+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:40:41.183+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:40:41.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.155 seconds
[2024-12-30T16:41:11.338+0000] {processor.py:186} INFO - Started process (PID=4305) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:41:11.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:41:11.341+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:41:11.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:41:11.365+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:41:11.421+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:41:11.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:41:11.456+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:41:11.455+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:41:11.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.153 seconds
[2024-12-30T16:41:41.614+0000] {processor.py:186} INFO - Started process (PID=4331) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:41:41.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:41:41.619+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:41:41.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:41:41.645+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:41:41.684+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:41:41.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:41:41.727+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:41:41.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:41:42.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.847 seconds
[2024-12-30T16:42:12.736+0000] {processor.py:186} INFO - Started process (PID=4357) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:42:12.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:42:12.739+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:42:12.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:42:12.763+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:42:12.826+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:42:12.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:42:13.324+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:42:13.324+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:42:13.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.619 seconds
[2024-12-30T16:42:43.793+0000] {processor.py:186} INFO - Started process (PID=4383) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:42:43.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:42:43.797+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:42:43.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:42:43.821+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:42:43.853+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:42:43.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:42:43.909+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:42:43.909+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:42:43.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.148 seconds
[2024-12-30T16:43:14.067+0000] {processor.py:186} INFO - Started process (PID=4409) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:43:14.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:43:14.072+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:43:14.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:43:14.134+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:43:14.181+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:43:14.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:43:14.221+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:43:14.221+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:43:14.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.188 seconds
[2024-12-30T16:43:44.495+0000] {processor.py:186} INFO - Started process (PID=4435) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:43:44.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:43:44.498+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:43:44.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:43:44.515+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:43:44.541+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:43:44.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:43:44.631+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:43:44.631+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:43:45.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.655 seconds
[2024-12-30T16:44:15.532+0000] {processor.py:186} INFO - Started process (PID=4462) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:44:15.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:44:15.535+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:44:15.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:44:15.559+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:44:15.701+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:44:15.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:44:19.026+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:44:19.026+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:44:19.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 3.581 seconds
[2024-12-30T16:44:49.501+0000] {processor.py:186} INFO - Started process (PID=4494) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:44:49.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:44:49.506+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:44:49.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:44:49.545+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:44:49.601+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:44:49.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:44:49.627+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:44:49.627+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:44:49.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.161 seconds
[2024-12-30T16:45:19.860+0000] {processor.py:186} INFO - Started process (PID=4520) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:45:19.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:45:19.864+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:45:19.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:45:19.940+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:45:20.002+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:45:20.002+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:45:20.110+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:45:20.110+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:45:20.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.379 seconds
[2024-12-30T16:45:50.305+0000] {processor.py:186} INFO - Started process (PID=4545) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:45:50.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:45:50.309+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:45:50.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:45:50.327+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:45:50.407+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:45:50.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:45:50.429+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:45:50.429+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:45:50.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.622 seconds
[2024-12-30T16:46:21.237+0000] {processor.py:186} INFO - Started process (PID=4571) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:46:21.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:46:21.240+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:46:21.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:46:21.271+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:46:21.312+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:46:21.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:46:21.809+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:46:21.809+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:46:21.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.670 seconds
[2024-12-30T16:46:52.262+0000] {processor.py:186} INFO - Started process (PID=4597) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:46:52.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:46:52.272+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:46:52.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:46:52.304+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:46:52.348+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:46:52.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:46:52.391+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:46:52.390+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:46:52.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.170 seconds
[2024-12-30T16:47:22.558+0000] {processor.py:186} INFO - Started process (PID=4623) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:47:22.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:47:22.563+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:47:22.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:47:22.584+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:47:22.617+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:47:22.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:47:22.646+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:47:22.646+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:47:22.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.142 seconds
[2024-12-30T16:47:53.051+0000] {processor.py:186} INFO - Started process (PID=4650) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:47:53.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:47:53.087+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:47:53.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:47:53.110+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:47:53.195+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:47:53.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:47:53.231+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:47:53.231+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:47:53.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.695 seconds
[2024-12-30T16:48:24.137+0000] {processor.py:186} INFO - Started process (PID=4676) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:48:24.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:48:24.149+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:48:24.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:48:24.224+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:48:24.292+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:48:24.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:48:24.613+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:48:24.613+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:48:24.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.515 seconds
[2024-12-30T16:48:55.023+0000] {processor.py:186} INFO - Started process (PID=4702) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:48:55.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:48:55.029+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:48:55.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:48:55.057+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:48:55.094+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:48:55.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:48:55.130+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:48:55.130+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:48:55.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.171 seconds
[2024-12-30T16:49:25.378+0000] {processor.py:186} INFO - Started process (PID=4727) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:49:25.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:49:25.382+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:49:25.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:49:25.401+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:49:25.434+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:49:25.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:49:25.482+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:49:25.482+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:49:25.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2024-12-30T16:49:55.817+0000] {processor.py:186} INFO - Started process (PID=4755) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:49:55.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:49:55.820+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:49:55.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:49:55.846+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:49:55.886+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:49:55.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:49:55.927+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:49:55.926+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:49:56.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.479 seconds
[2024-12-30T16:50:26.652+0000] {processor.py:186} INFO - Started process (PID=4780) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:50:26.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:50:26.655+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:50:26.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:50:26.675+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:50:26.705+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:50:26.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:50:27.083+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:50:27.083+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:50:27.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.459 seconds
[2024-12-30T16:50:57.509+0000] {processor.py:186} INFO - Started process (PID=4806) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:50:57.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:50:57.512+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:50:57.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:50:57.529+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:50:57.594+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:50:57.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:50:57.693+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:50:57.693+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:50:57.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.212 seconds
[2024-12-30T16:51:27.836+0000] {processor.py:186} INFO - Started process (PID=4833) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:51:27.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:51:27.839+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:51:27.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:51:27.858+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:51:27.888+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:51:27.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:51:27.927+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:51:27.927+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:51:27.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.141 seconds
[2024-12-30T16:51:58.291+0000] {processor.py:186} INFO - Started process (PID=4860) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:51:58.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:51:58.294+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:51:58.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:51:58.315+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:51:58.372+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:51:58.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:51:58.395+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:51:58.395+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:51:58.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.410 seconds
[2024-12-30T16:52:29.079+0000] {processor.py:186} INFO - Started process (PID=4886) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:52:29.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:52:29.082+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:52:29.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:52:29.101+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:52:29.163+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:52:29.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:52:29.582+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:52:29.582+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:52:29.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.589 seconds
[2024-12-30T16:53:00.094+0000] {processor.py:186} INFO - Started process (PID=4912) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:53:00.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:53:00.097+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:53:00.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:53:00.114+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:53:00.162+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:53:00.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:53:00.185+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:53:00.185+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:53:00.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2024-12-30T16:53:30.404+0000] {processor.py:186} INFO - Started process (PID=4938) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:53:30.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:53:30.408+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:53:30.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:53:30.427+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:53:30.469+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:53:30.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:53:30.496+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:53:30.496+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:53:30.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.168 seconds
[2024-12-30T16:54:00.885+0000] {processor.py:186} INFO - Started process (PID=4964) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:54:00.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:54:00.888+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:54:00.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:54:00.948+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:54:00.978+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:54:00.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:54:01.051+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:54:01.050+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:54:01.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.514 seconds
[2024-12-30T16:54:31.764+0000] {processor.py:186} INFO - Started process (PID=4990) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:54:31.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:54:31.767+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:54:31.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:54:31.786+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:54:31.844+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:54:31.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:54:32.369+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:54:32.369+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:54:32.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.631 seconds
[2024-12-30T16:55:02.832+0000] {processor.py:186} INFO - Started process (PID=5015) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:55:02.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:55:02.837+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:55:02.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:55:02.858+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:55:02.888+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:55:02.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:55:02.943+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:55:02.943+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:55:02.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.142 seconds
[2024-12-30T16:55:33.185+0000] {processor.py:186} INFO - Started process (PID=5040) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:55:33.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:55:33.189+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:55:33.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:55:33.207+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:55:33.235+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:55:33.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:55:33.256+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:55:33.256+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:55:33.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-30T16:56:03.569+0000] {processor.py:186} INFO - Started process (PID=5066) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:56:03.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:56:03.575+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:56:03.575+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:56:03.643+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:56:03.737+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:56:03.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:56:03.762+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:56:03.762+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:56:04.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.886 seconds
[2024-12-30T16:56:34.753+0000] {processor.py:186} INFO - Started process (PID=5091) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:56:34.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:56:34.759+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:56:34.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:56:34.827+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:56:34.871+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:56:34.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:56:35.458+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:56:35.457+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:56:35.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.787 seconds
[2024-12-30T16:57:05.875+0000] {processor.py:186} INFO - Started process (PID=5123) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:57:05.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:57:05.879+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:57:05.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:57:05.903+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:57:05.945+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:57:05.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:57:05.971+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:57:05.971+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:57:06.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.170 seconds
[2024-12-30T16:57:36.158+0000] {processor.py:186} INFO - Started process (PID=5150) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:57:36.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:57:36.164+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:57:36.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:57:36.212+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:57:36.309+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:57:36.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:57:36.338+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:57:36.338+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:57:36.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.213 seconds
[2024-12-30T16:58:06.655+0000] {processor.py:186} INFO - Started process (PID=5176) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:58:06.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:58:06.661+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:58:06.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:58:06.685+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:58:06.714+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:58:06.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:58:06.740+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:58:06.739+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:58:07.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.492 seconds
[2024-12-30T16:58:37.484+0000] {processor.py:186} INFO - Started process (PID=5202) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:58:37.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:58:37.509+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:58:37.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:58:37.557+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:58:37.627+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:58:37.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:58:38.806+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:58:38.806+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:58:38.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.377 seconds
[2024-12-30T16:59:09.160+0000] {processor.py:186} INFO - Started process (PID=5229) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:59:09.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:59:09.183+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:59:09.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:59:09.205+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:59:09.294+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:59:09.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:59:09.318+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:59:09.318+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:59:09.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.188 seconds
[2024-12-30T16:59:39.520+0000] {processor.py:186} INFO - Started process (PID=5255) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:59:39.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T16:59:39.523+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:59:39.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:59:39.550+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T16:59:39.608+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:59:39.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T16:59:39.722+0000] {logging_mixin.py:190} INFO - [2024-12-30T16:59:39.721+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 15:00:00+00:00, run_after=2024-12-30 16:00:00+00:00
[2024-12-30T16:59:39.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.262 seconds
[2024-12-30T17:00:09.907+0000] {processor.py:186} INFO - Started process (PID=5281) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:00:09.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:00:09.911+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:00:09.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:00:09.929+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:00:09.984+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:00:09.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:00:10.008+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:00:10.007+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:00:10.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.442 seconds
[2024-12-30T17:00:40.734+0000] {processor.py:186} INFO - Started process (PID=5308) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:00:40.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:00:40.737+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:00:40.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:00:40.755+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:00:40.783+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:00:40.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:00:41.283+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:00:41.283+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:00:41.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.583 seconds
[2024-12-30T17:01:11.718+0000] {processor.py:186} INFO - Started process (PID=5334) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:01:11.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:01:11.722+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:01:11.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:01:11.741+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:01:11.770+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:01:11.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:01:11.794+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:01:11.794+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:01:11.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-30T17:01:41.994+0000] {processor.py:186} INFO - Started process (PID=5360) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:01:41.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:01:41.997+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:01:41.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:01:42.017+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:01:42.065+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:01:42.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:01:42.089+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:01:42.088+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:01:42.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2024-12-30T17:02:12.429+0000] {processor.py:186} INFO - Started process (PID=5386) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:02:12.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:02:12.432+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:02:12.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:02:12.450+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:02:12.484+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:02:12.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:02:12.511+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:02:12.511+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:02:12.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.461 seconds
[2024-12-30T17:02:43.242+0000] {processor.py:186} INFO - Started process (PID=5412) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:02:43.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:02:43.245+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:02:43.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:02:43.262+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:02:43.289+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:02:43.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:02:43.605+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:02:43.605+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:02:43.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.444 seconds
[2024-12-30T17:03:14.018+0000] {processor.py:186} INFO - Started process (PID=5438) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:03:14.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:03:14.022+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:03:14.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:03:14.039+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:03:14.064+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:03:14.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:03:14.085+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:03:14.085+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:03:14.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-30T17:03:44.343+0000] {processor.py:186} INFO - Started process (PID=5465) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:03:44.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:03:44.347+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:03:44.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:03:44.370+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:03:44.404+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:03:44.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:03:44.451+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:03:44.451+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:03:44.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.138 seconds
[2024-12-30T17:04:14.638+0000] {processor.py:186} INFO - Started process (PID=5491) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:04:14.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:04:14.642+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:04:14.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:04:14.662+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:04:14.688+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:04:14.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:04:14.752+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:04:14.751+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:04:15.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.437 seconds
[2024-12-30T17:04:45.344+0000] {processor.py:186} INFO - Started process (PID=5518) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:04:45.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:04:45.349+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:04:45.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:04:45.404+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:04:45.436+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:04:45.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:04:45.878+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:04:45.878+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:04:45.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.604 seconds
[2024-12-30T17:05:16.261+0000] {processor.py:186} INFO - Started process (PID=5544) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:05:16.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:05:16.266+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:05:16.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:05:16.287+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:05:16.736+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:05:16.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:05:16.829+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:05:16.829+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:05:16.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.601 seconds
[2024-12-30T17:05:47.212+0000] {processor.py:186} INFO - Started process (PID=5570) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:05:47.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:05:47.216+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:05:47.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:05:47.235+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:05:47.263+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:05:47.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:05:47.285+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:05:47.285+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:05:47.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.159 seconds
[2024-12-30T17:06:17.664+0000] {processor.py:186} INFO - Started process (PID=5596) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:06:17.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:06:17.672+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:06:17.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:06:17.700+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:06:17.737+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:06:17.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:06:17.800+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:06:17.769+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:06:18.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.598 seconds
[2024-12-30T17:06:48.638+0000] {processor.py:186} INFO - Started process (PID=5622) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:06:48.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:06:48.642+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:06:48.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:06:48.665+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:06:48.723+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:06:48.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:06:49.129+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:06:49.128+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:06:49.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.519 seconds
[2024-12-30T17:07:19.596+0000] {processor.py:186} INFO - Started process (PID=5648) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:07:19.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:07:19.607+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:07:19.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:07:19.640+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:07:20.135+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:07:20.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:07:20.212+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:07:20.211+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:07:20.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.649 seconds
[2024-12-30T17:07:50.670+0000] {processor.py:186} INFO - Started process (PID=5674) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:07:50.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:07:50.676+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:07:50.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:07:50.698+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:07:50.724+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:07:50.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:07:50.747+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:07:50.747+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:07:50.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.169 seconds
[2024-12-30T17:08:21.112+0000] {processor.py:186} INFO - Started process (PID=5699) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:08:21.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:08:21.115+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:08:21.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:08:21.133+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:08:21.190+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:08:21.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:08:21.214+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:08:21.214+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:08:21.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.496 seconds
[2024-12-30T17:08:52.067+0000] {processor.py:186} INFO - Started process (PID=5725) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:08:52.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:08:52.071+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:08:52.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:08:52.092+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:08:52.122+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:08:52.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:08:52.498+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:08:52.498+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:08:52.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.495 seconds
[2024-12-30T17:09:22.911+0000] {processor.py:186} INFO - Started process (PID=5757) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:09:22.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:09:22.914+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:09:22.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:09:22.933+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:09:23.385+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:09:23.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:09:23.406+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:09:23.406+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:09:23.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.522 seconds
[2024-12-30T17:09:53.738+0000] {processor.py:186} INFO - Started process (PID=5783) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:09:53.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:09:53.743+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:09:53.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:09:53.768+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:09:53.808+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:09:53.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:09:53.837+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:09:53.837+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:09:53.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.148 seconds
[2024-12-30T17:10:24.047+0000] {processor.py:186} INFO - Started process (PID=5809) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:10:24.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:10:24.051+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:10:24.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:10:24.081+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:10:24.115+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:10:24.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:10:24.173+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:10:24.173+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:10:24.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.771 seconds
[2024-12-30T17:10:55.155+0000] {processor.py:186} INFO - Started process (PID=5835) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:10:55.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:10:55.160+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:10:55.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:10:55.179+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:10:55.210+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:10:55.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:10:55.682+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:10:55.682+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:10:55.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.553 seconds
[2024-12-30T17:11:26.042+0000] {processor.py:186} INFO - Started process (PID=5861) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:11:26.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:11:26.046+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:11:26.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:11:26.066+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:11:26.474+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:11:26.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:11:26.493+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:11:26.493+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:11:26.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.477 seconds
[2024-12-30T17:11:56.923+0000] {processor.py:186} INFO - Started process (PID=5887) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:11:56.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:11:56.926+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:11:56.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:11:56.947+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:11:56.976+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:11:56.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:11:56.999+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:11:56.998+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:11:57.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2024-12-30T17:12:27.229+0000] {processor.py:186} INFO - Started process (PID=5913) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:12:27.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:12:27.232+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:12:27.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:12:27.252+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:12:27.284+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:12:27.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:12:27.309+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:12:27.309+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:12:27.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.631 seconds
[2024-12-30T17:12:58.249+0000] {processor.py:186} INFO - Started process (PID=5939) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:12:58.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:12:58.254+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:12:58.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:12:58.282+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:12:58.346+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:12:58.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:12:58.771+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:12:58.771+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:12:58.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.619 seconds
[2024-12-30T17:13:29.243+0000] {processor.py:186} INFO - Started process (PID=5965) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:13:29.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:13:29.247+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:13:29.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:13:29.278+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:13:29.768+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:13:29.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:13:29.787+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:13:29.787+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:13:29.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.643 seconds
[2024-12-30T17:14:00.667+0000] {processor.py:186} INFO - Started process (PID=5993) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:14:00.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:14:00.670+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:14:00.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:14:00.685+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:14:00.756+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:14:00.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:14:00.775+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:14:00.774+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:14:00.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2024-12-30T17:14:31.206+0000] {processor.py:186} INFO - Started process (PID=6017) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:14:31.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:14:31.229+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:14:31.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:14:31.284+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:14:31.378+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:14:31.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:14:31.455+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:14:31.455+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:14:31.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.320 seconds
[2024-12-30T17:15:01.868+0000] {processor.py:186} INFO - Started process (PID=6046) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:15:01.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:15:01.935+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:15:01.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:15:02.065+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:15:02.205+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:15:02.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:15:02.275+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:15:02.275+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:15:02.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.457 seconds
[2024-12-30T17:15:32.647+0000] {processor.py:186} INFO - Started process (PID=6073) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:15:32.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:15:32.655+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:15:32.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:15:32.684+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:15:32.766+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:15:32.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:15:32.845+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:15:32.845+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:15:32.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.228 seconds
[2024-12-30T17:16:02.940+0000] {processor.py:186} INFO - Started process (PID=6096) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:16:02.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:16:02.946+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:16:02.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:16:02.982+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:16:03.044+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:16:03.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:16:03.076+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:16:03.076+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:16:03.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.169 seconds
[2024-12-30T17:16:33.489+0000] {processor.py:186} INFO - Started process (PID=6126) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:16:33.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:16:33.493+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:16:33.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:16:33.536+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:16:33.723+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:16:33.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:16:33.849+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:16:33.848+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:16:33.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.473 seconds
[2024-12-30T17:17:04.340+0000] {processor.py:186} INFO - Started process (PID=6152) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:17:04.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:17:04.347+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:17:04.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:17:04.376+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:17:04.406+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:17:04.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:17:04.451+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:17:04.451+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:17:04.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.142 seconds
[2024-12-30T17:17:34.613+0000] {processor.py:186} INFO - Started process (PID=6178) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:17:34.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:17:34.616+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:17:34.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:17:34.634+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:17:34.667+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:17:34.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:17:34.734+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:17:34.734+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:17:34.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2024-12-30T17:18:05.117+0000] {processor.py:186} INFO - Started process (PID=6204) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:18:05.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:18:05.120+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:18:05.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:18:05.142+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:18:05.170+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:18:05.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:18:05.221+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:18:05.220+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:18:05.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.131 seconds
[2024-12-30T17:18:35.495+0000] {processor.py:186} INFO - Started process (PID=6230) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:18:35.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:18:35.498+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:18:35.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:18:35.516+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:18:35.543+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:18:35.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:18:35.566+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:18:35.566+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:18:35.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.100 seconds
[2024-12-30T17:19:05.967+0000] {processor.py:186} INFO - Started process (PID=6255) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:19:05.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:19:05.971+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:19:05.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:19:05.989+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:19:06.030+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:19:06.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:19:06.072+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:19:06.072+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:19:06.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.157 seconds
[2024-12-30T17:19:36.481+0000] {processor.py:186} INFO - Started process (PID=6281) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:19:36.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:19:36.484+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:19:36.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:19:36.502+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:19:36.531+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:19:36.531+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:19:36.570+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:19:36.570+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:19:36.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2024-12-30T17:20:06.948+0000] {processor.py:186} INFO - Started process (PID=6306) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:20:06.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:20:06.951+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:20:06.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:20:06.968+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:20:07.014+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:20:07.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:20:07.044+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:20:07.044+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:20:07.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2024-12-30T17:20:37.265+0000] {processor.py:186} INFO - Started process (PID=6331) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:20:37.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:20:37.268+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:20:37.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:20:37.286+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:20:37.316+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:20:37.315+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:20:37.337+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:20:37.337+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:20:37.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-30T17:21:07.784+0000] {processor.py:186} INFO - Started process (PID=6357) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:21:07.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:21:07.791+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:21:07.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:21:07.814+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:21:07.850+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:21:07.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:21:07.904+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:21:07.904+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:21:07.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.159 seconds
[2024-12-30T17:21:38.046+0000] {processor.py:186} INFO - Started process (PID=6383) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:21:38.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:21:38.050+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:21:38.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:21:38.073+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:21:38.122+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:21:38.122+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:21:38.150+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:21:38.150+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:21:38.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.179 seconds
[2024-12-30T17:22:08.518+0000] {processor.py:186} INFO - Started process (PID=6409) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:22:08.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:22:08.521+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:22:08.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:22:08.552+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:22:08.597+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:22:08.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:22:08.618+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:22:08.618+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:22:08.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2024-12-30T17:22:38.964+0000] {processor.py:186} INFO - Started process (PID=6435) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:22:38.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:22:38.967+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:22:38.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:22:38.986+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:22:39.017+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:22:39.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:22:39.041+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:22:39.041+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:22:39.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.144 seconds
[2024-12-30T17:23:09.454+0000] {processor.py:186} INFO - Started process (PID=6461) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:23:09.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:23:09.458+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:23:09.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:23:09.479+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:23:09.515+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:23:09.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:23:09.549+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:23:09.549+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:23:09.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.162 seconds
[2024-12-30T17:23:39.899+0000] {processor.py:186} INFO - Started process (PID=6486) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:23:39.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:23:39.903+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:23:39.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:23:39.921+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:23:39.947+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:23:39.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:23:40.001+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:23:40.001+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:23:40.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.132 seconds
[2024-12-30T17:24:10.398+0000] {processor.py:186} INFO - Started process (PID=6511) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:24:10.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:24:10.402+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:24:10.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:24:10.422+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:24:10.491+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:24:10.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:24:10.518+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:24:10.517+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:24:10.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2024-12-30T17:24:40.885+0000] {processor.py:186} INFO - Started process (PID=6538) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:24:40.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:24:40.889+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:24:40.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:24:40.942+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:24:41.032+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:24:41.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:24:41.189+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:24:41.189+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:24:41.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.408 seconds
[2024-12-30T17:25:11.571+0000] {processor.py:186} INFO - Started process (PID=6571) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:25:11.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:25:11.576+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:25:11.575+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:25:11.599+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:25:11.695+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:25:11.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:25:11.790+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:25:11.789+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:25:11.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.251 seconds
[2024-12-30T17:25:42.232+0000] {processor.py:186} INFO - Started process (PID=6597) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:25:42.233+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:25:42.242+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:25:42.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:25:42.310+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:25:42.373+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:25:42.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:25:42.394+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:25:42.394+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:25:42.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.204 seconds
[2024-12-30T17:26:12.692+0000] {processor.py:186} INFO - Started process (PID=6622) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:26:12.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:26:12.695+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:26:12.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:26:12.713+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:26:12.769+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:26:12.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:26:12.797+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:26:12.797+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:26:12.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.137 seconds
[2024-12-30T17:26:43.273+0000] {processor.py:186} INFO - Started process (PID=6647) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:26:43.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:26:43.276+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:26:43.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:26:43.293+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:26:43.323+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:26:43.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:26:43.377+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:26:43.377+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:26:43.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2024-12-30T17:27:13.522+0000] {processor.py:186} INFO - Started process (PID=6673) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:27:13.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:27:13.526+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:27:13.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:27:13.542+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:27:13.588+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:27:13.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:27:13.610+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:27:13.610+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:27:13.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2024-12-30T17:27:43.895+0000] {processor.py:186} INFO - Started process (PID=6699) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:27:43.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:27:43.898+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:27:43.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:27:43.916+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:27:43.987+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:27:43.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:27:44.012+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:27:44.012+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:27:44.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.186 seconds
[2024-12-30T17:28:14.216+0000] {processor.py:186} INFO - Started process (PID=6725) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:28:14.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:28:14.219+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:28:14.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:28:14.237+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:28:14.299+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:28:14.299+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:28:14.320+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:28:14.320+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:28:14.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2024-12-30T17:28:44.508+0000] {processor.py:186} INFO - Started process (PID=6751) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:28:44.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:28:44.511+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:28:44.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:28:44.530+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:28:44.555+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:28:44.555+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:28:44.607+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:28:44.607+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:28:44.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.132 seconds
[2024-12-30T17:29:14.979+0000] {processor.py:186} INFO - Started process (PID=6777) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:29:14.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:29:14.986+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:29:14.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:29:15.003+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:29:15.035+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:29:15.034+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:29:15.116+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:29:15.115+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:29:15.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.169 seconds
[2024-12-30T17:29:45.282+0000] {processor.py:186} INFO - Started process (PID=6803) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:29:45.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:29:45.285+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:29:45.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:29:45.315+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:29:45.346+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:29:45.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:29:45.403+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:29:45.403+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:29:45.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.157 seconds
[2024-12-30T17:30:15.611+0000] {processor.py:186} INFO - Started process (PID=6828) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:30:15.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:30:15.615+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:30:15.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:30:15.632+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:30:15.703+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:30:15.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:30:15.725+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:30:15.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:30:15.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.141 seconds
[2024-12-30T17:30:46.119+0000] {processor.py:186} INFO - Started process (PID=6853) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:30:46.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:30:46.123+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:30:46.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:30:46.143+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:30:46.170+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:30:46.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:30:46.210+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:30:46.210+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:30:46.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.152 seconds
[2024-12-30T17:31:16.569+0000] {processor.py:186} INFO - Started process (PID=6879) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:31:16.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:31:16.573+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:31:16.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:31:16.599+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:31:16.629+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:31:16.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:31:16.654+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:31:16.654+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:31:16.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2024-12-30T17:31:46.868+0000] {processor.py:186} INFO - Started process (PID=6905) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:31:46.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:31:46.871+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:31:46.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:31:46.890+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:31:46.916+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:31:46.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:31:46.938+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:31:46.938+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:31:46.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2024-12-30T17:32:17.269+0000] {processor.py:186} INFO - Started process (PID=6931) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:32:17.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:32:17.272+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:32:17.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:32:17.290+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:32:17.326+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:32:17.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:32:17.380+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:32:17.380+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:32:17.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.138 seconds
[2024-12-30T17:32:47.576+0000] {processor.py:186} INFO - Started process (PID=6957) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:32:47.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:32:47.580+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:32:47.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:32:47.600+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:32:47.629+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:32:47.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:32:47.685+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:32:47.685+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:32:47.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2024-12-30T17:33:18.513+0000] {processor.py:186} INFO - Started process (PID=6983) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:33:18.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:33:18.521+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:33:18.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:33:18.559+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:33:18.625+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:33:18.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:33:18.651+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:33:18.651+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:33:18.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.181 seconds
[2024-12-30T17:33:48.803+0000] {processor.py:186} INFO - Started process (PID=7009) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:33:48.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:33:48.807+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:33:48.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:33:48.823+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:33:48.861+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:33:48.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:33:48.883+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:33:48.883+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:33:48.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.112 seconds
[2024-12-30T17:34:19.124+0000] {processor.py:186} INFO - Started process (PID=7035) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:34:19.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:34:19.127+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:34:19.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:34:19.153+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:34:19.190+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:34:19.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:34:19.269+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:34:19.269+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:34:19.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.250 seconds
[2024-12-30T17:34:49.601+0000] {processor.py:186} INFO - Started process (PID=7061) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:34:49.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:34:49.605+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:34:49.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:34:49.623+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:34:49.664+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:34:49.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:34:49.686+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:34:49.686+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:34:49.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2024-12-30T17:35:20.077+0000] {processor.py:186} INFO - Started process (PID=7087) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:35:20.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:35:20.081+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:35:20.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:35:20.103+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:35:20.162+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:35:20.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:35:20.184+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:35:20.184+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:35:20.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2024-12-30T17:35:50.413+0000] {processor.py:186} INFO - Started process (PID=7113) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:35:50.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:35:50.416+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:35:50.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:35:50.435+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:35:50.461+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:35:50.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:35:50.483+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:35:50.483+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:35:50.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2024-12-30T17:36:20.896+0000] {processor.py:186} INFO - Started process (PID=7138) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:36:20.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:36:20.903+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:36:20.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:36:20.938+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:36:20.968+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:36:20.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:36:20.990+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:36:20.990+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:36:21.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.170 seconds
[2024-12-30T17:36:51.176+0000] {processor.py:186} INFO - Started process (PID=7163) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:36:51.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:36:51.179+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:36:51.179+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:36:51.230+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:36:51.256+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:36:51.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:36:51.278+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:36:51.278+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:36:51.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.170 seconds
[2024-12-30T17:37:21.625+0000] {processor.py:186} INFO - Started process (PID=7189) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:37:21.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:37:21.628+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:37:21.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:37:21.653+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:37:21.683+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:37:21.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:37:21.727+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:37:21.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:37:21.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2024-12-30T17:37:52.159+0000] {processor.py:186} INFO - Started process (PID=7215) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:37:52.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:37:52.163+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:37:52.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:37:52.182+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:37:52.226+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:37:52.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:37:52.248+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:37:52.248+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:37:52.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.120 seconds
[2024-12-30T17:38:22.483+0000] {processor.py:186} INFO - Started process (PID=7241) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:38:22.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:38:22.486+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:38:22.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:38:22.505+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:38:22.535+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:38:22.535+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:38:22.558+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:38:22.558+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:38:22.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.138 seconds
[2024-12-30T17:38:52.948+0000] {processor.py:186} INFO - Started process (PID=7267) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:38:52.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:38:52.951+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:38:52.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:38:52.972+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:38:53.017+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:38:53.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:38:53.042+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:38:53.042+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:38:53.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2024-12-30T17:39:23.316+0000] {processor.py:186} INFO - Started process (PID=7293) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:39:23.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:39:23.320+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:39:23.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:39:23.343+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:39:23.426+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:39:23.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:39:23.455+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:39:23.455+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:39:23.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.207 seconds
[2024-12-30T17:39:53.682+0000] {processor.py:186} INFO - Started process (PID=7319) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:39:53.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:39:53.685+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:39:53.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:39:53.704+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:39:53.735+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:39:53.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:39:53.812+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:39:53.811+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:39:53.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.220 seconds
[2024-12-30T17:40:24.255+0000] {processor.py:186} INFO - Started process (PID=7349) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:40:24.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:40:24.260+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:40:24.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:40:24.282+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:40:24.312+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:40:24.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:40:24.335+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:40:24.335+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:40:24.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2024-12-30T17:40:54.696+0000] {processor.py:186} INFO - Started process (PID=7375) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:40:54.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:40:54.704+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:40:54.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:40:54.733+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:40:54.765+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:40:54.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:40:54.793+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:40:54.793+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:40:54.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2024-12-30T17:41:25.111+0000] {processor.py:186} INFO - Started process (PID=7402) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:41:25.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:41:25.116+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:41:25.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:41:25.134+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:41:25.163+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:41:25.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:41:25.187+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:41:25.187+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:41:25.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2024-12-30T17:41:55.549+0000] {processor.py:186} INFO - Started process (PID=7429) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:41:55.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:41:55.554+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:41:55.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:41:55.578+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:41:55.613+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:41:55.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:41:55.638+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:41:55.638+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:41:55.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.123 seconds
[2024-12-30T17:42:25.860+0000] {processor.py:186} INFO - Started process (PID=7455) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:42:25.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:42:25.865+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:42:25.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:42:25.894+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:42:25.928+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:42:25.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:42:25.964+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:42:25.964+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:42:25.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2024-12-30T17:42:56.284+0000] {processor.py:186} INFO - Started process (PID=7481) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:42:56.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:42:56.288+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:42:56.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:42:56.307+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:42:56.332+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:42:56.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:42:56.351+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:42:56.351+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:42:56.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-30T17:43:26.702+0000] {processor.py:186} INFO - Started process (PID=7507) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:43:26.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:43:26.709+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:43:26.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:43:26.734+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:43:26.769+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:43:26.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:43:26.799+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:43:26.799+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:43:26.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2024-12-30T17:43:57.168+0000] {processor.py:186} INFO - Started process (PID=7534) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:43:57.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:43:57.172+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:43:57.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:43:57.193+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:43:57.221+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:43:57.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:43:57.246+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:43:57.246+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:43:57.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2024-12-30T17:44:27.561+0000] {processor.py:186} INFO - Started process (PID=7560) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:44:27.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:44:27.564+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:44:27.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:44:27.583+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:44:27.615+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:44:27.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:44:27.638+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:44:27.638+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:44:27.661+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-30T17:44:57.988+0000] {processor.py:186} INFO - Started process (PID=7586) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:44:57.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:44:57.995+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:44:57.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:44:58.017+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:44:58.054+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:44:58.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:44:58.087+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:44:58.087+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:44:58.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2024-12-30T17:45:28.360+0000] {processor.py:186} INFO - Started process (PID=7612) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:45:28.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:45:28.367+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:45:28.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:45:28.393+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:45:28.432+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:45:28.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:45:28.460+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:45:28.460+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:45:28.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2024-12-30T17:45:58.779+0000] {processor.py:186} INFO - Started process (PID=7638) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:45:58.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:45:58.783+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:45:58.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:45:58.802+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:45:58.832+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:45:58.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:45:58.855+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:45:58.855+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:45:58.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2024-12-30T17:46:29.185+0000] {processor.py:186} INFO - Started process (PID=7665) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:46:29.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:46:29.189+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:46:29.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:46:29.207+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:46:29.232+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:46:29.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:46:29.252+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:46:29.252+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:46:29.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-30T17:46:59.607+0000] {processor.py:186} INFO - Started process (PID=7691) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:46:59.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:46:59.613+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:46:59.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:46:59.638+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:46:59.670+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:46:59.670+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:46:59.694+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:46:59.694+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:46:59.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2024-12-30T17:47:30.028+0000] {processor.py:186} INFO - Started process (PID=7718) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:47:30.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:47:30.032+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:47:30.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:47:30.050+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:47:30.074+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:47:30.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:47:30.095+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:47:30.095+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:47:30.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-30T17:48:00.505+0000] {processor.py:186} INFO - Started process (PID=7744) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:48:00.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:48:00.519+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:48:00.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:48:00.542+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:48:00.578+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:48:00.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:48:00.601+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:48:00.601+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:48:00.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2024-12-30T17:48:30.815+0000] {processor.py:186} INFO - Started process (PID=7769) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:48:30.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:48:30.821+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:48:30.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:48:30.842+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:48:30.868+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:48:30.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:48:30.890+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:48:30.890+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:48:30.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T17:49:01.264+0000] {processor.py:186} INFO - Started process (PID=7796) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:49:01.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:49:01.276+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:49:01.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:49:01.337+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:49:01.408+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:49:01.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:49:01.462+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:49:01.461+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:49:01.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.257 seconds
[2024-12-30T17:49:31.629+0000] {processor.py:186} INFO - Started process (PID=7822) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:49:31.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:49:31.649+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:49:31.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:49:31.695+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:49:31.727+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:49:31.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:49:31.753+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:49:31.753+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:49:31.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.164 seconds
[2024-12-30T17:50:02.036+0000] {processor.py:186} INFO - Started process (PID=7854) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:50:02.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:50:02.041+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:50:02.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:50:02.103+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:50:02.187+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:50:02.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:50:02.256+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:50:02.255+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:50:02.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.256 seconds
[2024-12-30T17:50:32.422+0000] {processor.py:186} INFO - Started process (PID=7880) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:50:32.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:50:32.426+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:50:32.426+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:50:32.447+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:50:32.475+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:50:32.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:50:32.498+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:50:32.498+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:50:32.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T17:51:02.859+0000] {processor.py:186} INFO - Started process (PID=7906) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:51:02.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:51:02.868+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:51:02.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:51:02.895+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:51:02.931+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:51:02.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:51:02.990+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:51:02.990+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:51:03.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.173 seconds
[2024-12-30T17:51:33.199+0000] {processor.py:186} INFO - Started process (PID=7932) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:51:33.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:51:33.206+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:51:33.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:51:33.236+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:51:33.271+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:51:33.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:51:33.304+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:51:33.303+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:51:33.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.140 seconds
[2024-12-30T17:52:03.650+0000] {processor.py:186} INFO - Started process (PID=7959) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:52:03.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:52:03.658+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:52:03.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:52:03.687+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:52:03.730+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:52:03.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:52:03.769+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:52:03.769+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:52:03.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.151 seconds
[2024-12-30T17:52:34.108+0000] {processor.py:186} INFO - Started process (PID=7986) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:52:34.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:52:34.113+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:52:34.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:52:34.139+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:52:34.179+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:52:34.179+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:52:34.212+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:52:34.211+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:52:34.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2024-12-30T17:53:04.525+0000] {processor.py:186} INFO - Started process (PID=8012) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:53:04.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:53:04.531+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:53:04.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:53:04.554+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:53:04.596+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:53:04.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:53:04.631+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:53:04.631+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:53:04.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.140 seconds
[2024-12-30T17:53:34.886+0000] {processor.py:186} INFO - Started process (PID=8038) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:53:34.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:53:34.894+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:53:34.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:53:34.928+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:53:34.969+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:53:34.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:53:35.014+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:53:35.014+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:53:35.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.168 seconds
[2024-12-30T17:54:05.370+0000] {processor.py:186} INFO - Started process (PID=8064) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:54:05.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:54:05.375+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:54:05.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:54:05.398+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:54:05.433+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:54:05.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:54:05.461+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:54:05.461+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:54:05.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2024-12-30T17:54:35.790+0000] {processor.py:186} INFO - Started process (PID=8090) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:54:35.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:54:35.794+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:54:35.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:54:35.812+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:54:35.838+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:54:35.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:54:35.860+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:54:35.860+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:54:35.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-30T17:55:06.175+0000] {processor.py:186} INFO - Started process (PID=8116) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:55:06.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:55:06.182+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:55:06.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:55:06.206+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:55:06.244+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:55:06.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:55:06.279+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:55:06.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:55:06.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.141 seconds
[2024-12-30T17:55:36.490+0000] {processor.py:186} INFO - Started process (PID=8142) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:55:36.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:55:36.494+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:55:36.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:55:36.513+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:55:36.540+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:55:36.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:55:36.562+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:55:36.562+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:55:36.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T17:56:06.920+0000] {processor.py:186} INFO - Started process (PID=8168) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:56:06.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:56:06.926+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:56:06.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:56:06.949+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:56:06.990+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:56:06.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:56:07.023+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:56:07.023+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:56:07.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.144 seconds
[2024-12-30T17:56:37.384+0000] {processor.py:186} INFO - Started process (PID=8194) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:56:37.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:56:37.388+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:56:37.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:56:37.410+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:56:37.437+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:56:37.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:56:37.460+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:56:37.459+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:56:37.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.107 seconds
[2024-12-30T17:57:07.864+0000] {processor.py:186} INFO - Started process (PID=8220) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:57:07.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:57:07.870+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:57:07.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:57:07.897+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:57:07.927+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:57:07.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:57:07.957+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:57:07.957+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:57:07.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2024-12-30T17:57:38.267+0000] {processor.py:186} INFO - Started process (PID=8245) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:57:38.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:57:38.271+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:57:38.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:57:38.290+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:57:38.316+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:57:38.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:57:38.339+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:57:38.339+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:57:38.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-30T17:58:08.668+0000] {processor.py:186} INFO - Started process (PID=8272) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:58:08.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:58:08.672+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:58:08.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:58:08.691+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:58:08.719+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:58:08.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:58:08.742+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:58:08.742+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:58:08.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2024-12-30T17:58:39.147+0000] {processor.py:186} INFO - Started process (PID=8299) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:58:39.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:58:39.153+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:58:39.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:58:39.180+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:58:39.214+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:58:39.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:58:39.253+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:58:39.253+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:58:39.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.144 seconds
[2024-12-30T17:59:09.574+0000] {processor.py:186} INFO - Started process (PID=8325) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:59:09.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:59:09.578+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:59:09.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:59:09.597+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:59:09.622+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:59:09.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:59:09.643+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:59:09.643+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:59:09.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-30T17:59:39.993+0000] {processor.py:186} INFO - Started process (PID=8351) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:59:39.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T17:59:39.998+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:59:39.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:59:40.021+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T17:59:40.049+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:59:40.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T17:59:40.073+0000] {logging_mixin.py:190} INFO - [2024-12-30T17:59:40.073+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 16:00:00+00:00, run_after=2024-12-30 17:00:00+00:00
[2024-12-30T17:59:40.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2024-12-30T18:00:10.407+0000] {processor.py:186} INFO - Started process (PID=8378) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:00:10.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:00:10.412+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:00:10.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:00:10.432+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:00:10.458+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:00:10.458+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:00:10.479+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:00:10.479+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:00:10.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-30T18:00:40.871+0000] {processor.py:186} INFO - Started process (PID=8404) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:00:40.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:00:40.879+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:00:40.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:00:40.900+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:00:40.930+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:00:40.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:00:40.963+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:00:40.963+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:00:40.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2024-12-30T18:01:11.329+0000] {processor.py:186} INFO - Started process (PID=8430) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:01:11.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:01:11.333+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:01:11.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:01:11.352+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:01:11.377+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:01:11.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:01:11.397+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:01:11.397+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:01:11.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-30T18:01:41.730+0000] {processor.py:186} INFO - Started process (PID=8456) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:01:41.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:01:41.735+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:01:41.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:01:41.759+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:01:41.791+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:01:41.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:01:41.822+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:01:41.822+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:01:41.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2024-12-30T18:02:12.221+0000] {processor.py:186} INFO - Started process (PID=8482) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:02:12.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:02:12.225+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:02:12.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:02:12.245+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:02:12.274+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:02:12.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:02:12.296+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:02:12.296+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:02:12.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.113 seconds
[2024-12-30T18:02:42.733+0000] {processor.py:186} INFO - Started process (PID=8507) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:02:42.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:02:42.738+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:02:42.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:02:42.760+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:02:42.788+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:02:42.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:02:42.813+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:02:42.813+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:02:42.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2024-12-30T18:03:13.134+0000] {processor.py:186} INFO - Started process (PID=8533) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:03:13.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:03:13.139+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:03:13.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:03:13.160+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:03:13.187+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:03:13.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:03:13.218+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:03:13.218+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:03:13.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2024-12-30T18:03:43.764+0000] {processor.py:186} INFO - Started process (PID=8559) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:03:43.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:03:43.771+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:03:43.771+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:03:43.792+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:03:43.823+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:03:43.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:03:43.851+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:03:43.851+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:03:43.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2024-12-30T18:04:14.105+0000] {processor.py:186} INFO - Started process (PID=8586) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:04:14.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:04:14.109+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:04:14.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:04:14.129+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:04:14.159+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:04:14.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:04:14.185+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:04:14.185+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:04:14.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.117 seconds
[2024-12-30T18:04:44.552+0000] {processor.py:186} INFO - Started process (PID=8612) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:04:44.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:04:44.558+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:04:44.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:04:44.579+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:04:44.611+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:04:44.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:04:44.636+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:04:44.636+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:04:44.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2024-12-30T18:05:14.954+0000] {processor.py:186} INFO - Started process (PID=8637) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:05:14.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:05:14.958+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:05:14.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:05:14.977+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:05:15.006+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:05:15.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:05:15.047+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:05:15.047+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:05:15.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2024-12-30T18:05:45.442+0000] {processor.py:186} INFO - Started process (PID=8663) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:05:45.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:05:45.446+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:05:45.446+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:05:45.466+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:05:45.506+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:05:45.506+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:05:45.535+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:05:45.535+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:05:45.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.123 seconds
[2024-12-30T18:06:15.915+0000] {processor.py:186} INFO - Started process (PID=8689) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:06:15.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:06:15.921+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:06:15.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:06:15.943+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:06:15.974+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:06:15.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:06:16.000+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:06:16.000+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:06:16.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2024-12-30T18:06:46.227+0000] {processor.py:186} INFO - Started process (PID=8715) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:06:46.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:06:46.232+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:06:46.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:06:46.258+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:06:46.289+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:06:46.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:06:46.312+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:06:46.312+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:06:46.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2024-12-30T18:07:16.667+0000] {processor.py:186} INFO - Started process (PID=8741) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:07:16.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:07:16.671+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:07:16.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:07:16.691+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:07:16.720+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:07:16.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:07:16.743+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:07:16.742+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:07:16.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2024-12-30T18:07:47.148+0000] {processor.py:186} INFO - Started process (PID=8767) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:07:47.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:07:47.152+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:07:47.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:07:47.173+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:07:47.201+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:07:47.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:07:47.223+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:07:47.223+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:07:47.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-30T18:08:17.654+0000] {processor.py:186} INFO - Started process (PID=8793) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:08:17.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:08:17.666+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:08:17.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:08:17.706+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:08:17.758+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:08:17.758+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:08:17.800+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:08:17.800+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:08:17.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.195 seconds
[2024-12-30T18:08:47.974+0000] {processor.py:186} INFO - Started process (PID=8818) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:08:47.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:08:47.978+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:08:47.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:08:47.998+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:08:48.026+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:08:48.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:08:48.047+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:08:48.046+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:08:48.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-30T18:09:18.418+0000] {processor.py:186} INFO - Started process (PID=8844) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:09:18.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:09:18.422+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:09:18.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:09:18.440+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:09:18.482+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:09:18.482+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:09:18.525+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:09:18.525+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:09:18.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.154 seconds
[2024-12-30T18:09:48.915+0000] {processor.py:186} INFO - Started process (PID=8870) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:09:48.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:09:48.919+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:09:48.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:09:48.947+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:09:48.976+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:09:48.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:09:49.007+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:09:49.007+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:09:49.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.131 seconds
[2024-12-30T18:10:19.452+0000] {processor.py:186} INFO - Started process (PID=8897) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:10:19.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:10:19.458+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:10:19.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:10:19.487+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:10:19.550+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:10:19.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:10:19.587+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:10:19.587+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:10:19.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.174 seconds
[2024-12-30T18:10:49.969+0000] {processor.py:186} INFO - Started process (PID=8923) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:10:49.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:10:49.973+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:10:49.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:10:49.991+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:10:50.021+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:10:50.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:10:50.042+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:10:50.042+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:10:50.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-30T18:11:20.493+0000] {processor.py:186} INFO - Started process (PID=8950) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:11:20.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:11:20.499+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:11:20.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:11:20.520+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:11:20.551+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:11:20.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:11:20.575+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:11:20.575+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:11:20.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.113 seconds
[2024-12-30T18:11:50.959+0000] {processor.py:186} INFO - Started process (PID=8976) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:11:50.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:11:50.965+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:11:50.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:11:50.997+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:11:51.027+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:11:51.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:11:51.051+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:11:51.051+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:11:51.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2024-12-30T18:12:21.498+0000] {processor.py:186} INFO - Started process (PID=9002) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:12:21.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:12:21.503+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:12:21.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:12:21.524+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:12:21.554+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:12:21.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:12:21.576+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:12:21.576+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:12:21.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2024-12-30T18:12:51.943+0000] {processor.py:186} INFO - Started process (PID=9029) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:12:51.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:12:51.948+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:12:51.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:12:51.968+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:12:51.995+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:12:51.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:12:52.019+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:12:52.019+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:12:52.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.100 seconds
[2024-12-30T18:13:22.359+0000] {processor.py:186} INFO - Started process (PID=9055) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:13:22.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:13:22.363+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:13:22.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:13:22.383+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:13:22.410+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:13:22.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:13:22.434+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:13:22.434+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:13:22.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2024-12-30T18:13:52.777+0000] {processor.py:186} INFO - Started process (PID=9080) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:13:52.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:13:52.780+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:13:52.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:13:52.801+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:13:52.841+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:13:52.841+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:13:52.863+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:13:52.863+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:13:52.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2024-12-30T18:14:23.239+0000] {processor.py:186} INFO - Started process (PID=9106) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:14:23.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:14:23.244+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:14:23.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:14:23.270+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:14:23.320+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:14:23.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:14:23.356+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:14:23.355+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:14:23.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.147 seconds
[2024-12-30T18:14:53.781+0000] {processor.py:186} INFO - Started process (PID=9137) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:14:53.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:14:53.786+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:14:53.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:14:53.805+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:14:53.835+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:14:53.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:14:53.861+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:14:53.860+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:14:53.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2024-12-30T18:15:24.211+0000] {processor.py:186} INFO - Started process (PID=9163) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:15:24.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:15:24.216+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:15:24.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:15:24.241+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:15:24.273+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:15:24.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:15:24.297+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:15:24.297+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:15:24.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2024-12-30T18:15:54.767+0000] {processor.py:186} INFO - Started process (PID=9190) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:15:54.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:15:54.772+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:15:54.771+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:15:54.795+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:15:54.821+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:15:54.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:15:54.843+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:15:54.843+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:15:54.866+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-30T18:16:25.163+0000] {processor.py:186} INFO - Started process (PID=9216) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:16:25.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:16:25.168+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:16:25.168+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:16:25.192+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:16:25.222+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:16:25.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:16:25.247+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:16:25.246+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:16:25.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.113 seconds
[2024-12-30T18:16:55.633+0000] {processor.py:186} INFO - Started process (PID=9242) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:16:55.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:16:55.638+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:16:55.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:16:55.664+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:16:55.697+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:16:55.697+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:16:55.727+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:16:55.726+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:16:55.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2024-12-30T18:17:26.028+0000] {processor.py:186} INFO - Started process (PID=9268) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:17:26.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:17:26.032+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:17:26.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:17:26.050+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:17:26.075+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:17:26.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:17:26.097+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:17:26.097+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:17:26.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-30T18:17:56.435+0000] {processor.py:186} INFO - Started process (PID=9294) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:17:56.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:17:56.441+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:17:56.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:17:56.463+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:17:56.487+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:17:56.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:17:56.508+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:17:56.508+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:17:56.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-30T18:18:26.840+0000] {processor.py:186} INFO - Started process (PID=9320) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:18:26.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:18:26.844+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:18:26.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:18:26.862+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:18:26.886+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:18:26.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:18:26.908+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:18:26.907+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:18:26.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-30T18:18:57.240+0000] {processor.py:186} INFO - Started process (PID=9346) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:18:57.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:18:57.244+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:18:57.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:18:57.262+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:18:57.289+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:18:57.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:18:57.310+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:18:57.310+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:18:57.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-30T18:19:27.649+0000] {processor.py:186} INFO - Started process (PID=9372) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:19:27.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:19:27.654+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:19:27.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:19:27.674+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:19:27.703+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:19:27.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:19:27.725+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:19:27.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:19:27.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.107 seconds
[2024-12-30T18:19:58.096+0000] {processor.py:186} INFO - Started process (PID=9398) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:19:58.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:19:58.100+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:19:58.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:19:58.120+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:19:58.164+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:19:58.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:19:58.184+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:19:58.184+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:19:58.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2024-12-30T18:20:28.718+0000] {processor.py:186} INFO - Started process (PID=9424) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:20:28.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:20:28.722+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:20:28.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:20:28.744+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:20:28.770+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:20:28.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:20:28.793+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:20:28.793+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:20:28.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-30T18:20:59.145+0000] {processor.py:186} INFO - Started process (PID=9450) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:20:59.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:20:59.149+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:20:59.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:20:59.169+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:20:59.194+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:20:59.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:20:59.215+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:20:59.214+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:20:59.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-30T18:21:29.550+0000] {processor.py:186} INFO - Started process (PID=9476) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:21:29.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:21:29.554+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:21:29.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:21:29.573+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:21:29.598+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:21:29.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:21:29.618+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:21:29.618+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:21:29.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-30T18:22:00.008+0000] {processor.py:186} INFO - Started process (PID=9503) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:22:00.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:22:00.012+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:22:00.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:22:00.036+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:22:00.063+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:22:00.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:22:00.084+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:22:00.084+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:22:00.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T18:22:30.400+0000] {processor.py:186} INFO - Started process (PID=9528) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:22:30.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:22:30.404+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:22:30.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:22:30.423+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:22:30.450+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:22:30.450+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:22:30.471+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:22:30.471+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:22:30.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-30T18:23:00.792+0000] {processor.py:186} INFO - Started process (PID=9555) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:23:00.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:23:00.795+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:23:00.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:23:00.813+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:23:00.838+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:23:00.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:23:00.858+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:23:00.858+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:23:00.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-30T18:23:31.171+0000] {processor.py:186} INFO - Started process (PID=9582) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:23:31.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:23:31.175+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:23:31.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:23:31.196+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:23:31.223+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:23:31.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:23:31.247+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:23:31.247+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:23:31.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2024-12-30T18:24:01.573+0000] {processor.py:186} INFO - Started process (PID=9608) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:24:01.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:24:01.577+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:24:01.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:24:01.594+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:24:01.627+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:24:01.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:24:01.649+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:24:01.649+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:24:01.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-30T18:24:31.973+0000] {processor.py:186} INFO - Started process (PID=9634) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:24:31.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:24:31.978+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:24:31.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:24:31.998+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:24:32.027+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:24:32.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:24:32.048+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:24:32.048+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:24:32.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T18:25:02.385+0000] {processor.py:186} INFO - Started process (PID=9660) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:25:02.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:25:02.389+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:25:02.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:25:02.406+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:25:02.431+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:25:02.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:25:02.450+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:25:02.450+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:25:02.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2024-12-30T18:25:32.831+0000] {processor.py:186} INFO - Started process (PID=9686) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:25:32.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:25:32.835+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:25:32.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:25:32.855+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:25:32.884+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:25:32.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:25:32.905+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:25:32.904+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:25:32.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T18:26:03.230+0000] {processor.py:186} INFO - Started process (PID=9713) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:26:03.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:26:03.234+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:26:03.234+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:26:03.252+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:26:03.280+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:26:03.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:26:03.301+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:26:03.301+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:26:03.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-30T18:26:33.692+0000] {processor.py:186} INFO - Started process (PID=9739) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:26:33.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:26:33.696+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:26:33.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:26:33.721+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:26:33.748+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:26:33.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:26:33.770+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:26:33.770+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:26:33.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2024-12-30T18:27:04.102+0000] {processor.py:186} INFO - Started process (PID=9764) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:27:04.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:27:04.106+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:27:04.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:27:04.123+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:27:04.147+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:27:04.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:27:04.167+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:27:04.167+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:27:04.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-30T18:27:34.484+0000] {processor.py:186} INFO - Started process (PID=9790) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:27:34.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:27:34.490+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:27:34.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:27:34.508+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:27:34.533+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:27:34.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:27:34.555+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:27:34.555+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:27:34.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-30T18:28:04.897+0000] {processor.py:186} INFO - Started process (PID=9816) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:28:04.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:28:04.901+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:28:04.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:28:04.921+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:28:04.946+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:28:04.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:28:04.971+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:28:04.970+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:28:04.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-30T18:28:35.293+0000] {processor.py:186} INFO - Started process (PID=9843) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:28:35.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:28:35.297+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:28:35.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:28:35.318+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:28:35.345+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:28:35.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:28:35.366+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:28:35.366+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:28:35.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-30T18:29:05.698+0000] {processor.py:186} INFO - Started process (PID=9869) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:29:05.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:29:05.702+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:29:05.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:29:05.722+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:29:05.748+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:29:05.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:29:05.771+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:29:05.771+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:29:05.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-30T18:29:36.128+0000] {processor.py:186} INFO - Started process (PID=9895) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:29:36.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:29:36.132+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:29:36.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:29:36.151+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:29:36.178+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:29:36.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:29:36.199+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:29:36.199+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:29:36.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.100 seconds
[2024-12-30T18:30:06.589+0000] {processor.py:186} INFO - Started process (PID=9921) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:30:06.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:30:06.593+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:30:06.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:30:06.615+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:30:06.640+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:30:06.640+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:30:06.666+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:30:06.666+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:30:06.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-30T18:30:37.011+0000] {processor.py:186} INFO - Started process (PID=9947) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:30:37.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:30:37.015+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:30:37.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:30:37.035+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:30:37.062+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:30:37.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:30:37.082+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:30:37.082+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:30:37.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-30T18:31:07.446+0000] {processor.py:186} INFO - Started process (PID=9972) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:31:07.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:31:07.449+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:31:07.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:31:07.469+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:31:07.495+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:31:07.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:31:07.514+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:31:07.514+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:31:07.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-30T18:31:37.837+0000] {processor.py:186} INFO - Started process (PID=9997) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:31:37.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:31:37.841+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:31:37.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:31:37.861+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:31:37.887+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:31:37.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:31:37.911+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:31:37.910+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:31:37.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T18:32:08.456+0000] {processor.py:186} INFO - Started process (PID=10022) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:32:08.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:32:08.460+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:32:08.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:32:08.478+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:32:08.505+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:32:08.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:32:08.526+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:32:08.526+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:32:08.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-30T18:32:38.830+0000] {processor.py:186} INFO - Started process (PID=10048) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:32:38.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:32:38.834+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:32:38.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:32:38.853+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:32:38.883+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:32:38.882+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:32:38.902+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:32:38.902+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:32:38.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-30T18:33:09.253+0000] {processor.py:186} INFO - Started process (PID=10075) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:33:09.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:33:09.257+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:33:09.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:33:09.276+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:33:09.300+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:33:09.300+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:33:09.321+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:33:09.321+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:33:09.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-30T18:33:39.648+0000] {processor.py:186} INFO - Started process (PID=10101) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:33:39.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:33:39.652+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:33:39.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:33:39.669+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:33:39.694+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:33:39.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:33:39.715+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:33:39.715+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:33:39.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-30T18:34:10.031+0000] {processor.py:186} INFO - Started process (PID=10128) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:34:10.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:34:10.035+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:34:10.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:34:10.055+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:34:10.080+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:34:10.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:34:10.102+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:34:10.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:34:10.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.100 seconds
[2024-12-30T18:34:40.451+0000] {processor.py:186} INFO - Started process (PID=10154) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:34:40.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:34:40.455+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:34:40.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:34:40.475+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:34:40.511+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:34:40.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:34:40.533+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:34:40.532+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:34:40.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2024-12-30T18:35:10.896+0000] {processor.py:186} INFO - Started process (PID=10180) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:35:10.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:35:10.900+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:35:10.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:35:10.924+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:35:10.952+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:35:10.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:35:10.972+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:35:10.972+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:35:10.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-30T18:35:41.346+0000] {processor.py:186} INFO - Started process (PID=10206) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:35:41.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:35:41.350+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:35:41.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:35:41.375+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:35:41.400+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:35:41.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:35:41.422+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:35:41.421+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:35:41.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-30T18:36:11.748+0000] {processor.py:186} INFO - Started process (PID=10233) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:36:11.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:36:11.753+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:36:11.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:36:11.773+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:36:11.824+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:36:11.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:36:11.846+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:36:11.846+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:36:11.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2024-12-30T18:36:42.190+0000] {processor.py:186} INFO - Started process (PID=10259) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:36:42.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:36:42.195+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:36:42.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:36:42.214+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:36:42.244+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:36:42.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:36:42.271+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:36:42.271+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:36:42.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.112 seconds
[2024-12-30T18:37:12.602+0000] {processor.py:186} INFO - Started process (PID=10285) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:37:12.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:37:12.606+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:37:12.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:37:12.625+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:37:12.657+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:37:12.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:37:12.679+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:37:12.679+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:37:12.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-30T18:37:42.992+0000] {processor.py:186} INFO - Started process (PID=10311) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:37:42.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:37:42.997+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:37:42.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:37:43.015+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:37:43.040+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:37:43.040+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:37:43.062+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:37:43.062+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:37:43.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.100 seconds
[2024-12-30T18:38:13.420+0000] {processor.py:186} INFO - Started process (PID=10337) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:38:13.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:38:13.424+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:38:13.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:38:13.441+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:38:13.467+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:38:13.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:38:13.488+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:38:13.488+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:38:13.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-30T18:38:43.853+0000] {processor.py:186} INFO - Started process (PID=10362) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:38:43.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:38:43.856+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:38:43.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:38:43.875+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:38:43.903+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:38:43.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:38:43.926+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:38:43.926+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:38:43.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T18:39:14.227+0000] {processor.py:186} INFO - Started process (PID=10388) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:39:14.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:39:14.231+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:39:14.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:39:14.249+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:39:14.275+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:39:14.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:39:14.298+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:39:14.298+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:39:14.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.132 seconds
[2024-12-30T18:39:44.654+0000] {processor.py:186} INFO - Started process (PID=10414) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:39:44.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:39:44.658+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:39:44.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:39:44.678+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:39:44.745+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:39:44.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:39:44.826+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:39:44.826+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:39:44.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.209 seconds
[2024-12-30T18:40:15.015+0000] {processor.py:186} INFO - Started process (PID=10440) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:40:15.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:40:15.020+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:40:15.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:40:15.041+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:40:15.118+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:40:15.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:40:15.149+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:40:15.149+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:40:15.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.214 seconds
[2024-12-30T18:40:45.560+0000] {processor.py:186} INFO - Started process (PID=10466) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:40:45.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:40:45.565+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:40:45.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:40:45.617+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:40:45.715+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:40:45.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:40:45.746+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:40:45.746+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:40:45.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.299 seconds
[2024-12-30T18:41:16.030+0000] {processor.py:186} INFO - Started process (PID=10499) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:41:16.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:41:16.037+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:41:16.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:41:16.108+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:41:16.209+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:41:16.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:41:16.314+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:41:16.314+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:41:16.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.336 seconds
[2024-12-30T18:41:46.400+0000] {processor.py:186} INFO - Started process (PID=10525) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:41:46.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:41:46.405+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:41:46.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:41:46.426+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:41:46.455+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:41:46.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:41:46.509+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:41:46.509+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:41:46.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2024-12-30T18:42:16.793+0000] {processor.py:186} INFO - Started process (PID=10551) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:42:16.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:42:16.798+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:42:16.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:42:16.823+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:42:16.906+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:42:16.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:42:16.937+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:42:16.936+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:42:16.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.241 seconds
[2024-12-30T18:42:47.083+0000] {processor.py:186} INFO - Started process (PID=10577) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:42:47.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:42:47.087+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:42:47.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:42:47.105+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:42:47.132+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:42:47.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:42:47.156+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:42:47.156+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:42:47.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.107 seconds
[2024-12-30T18:43:17.530+0000] {processor.py:186} INFO - Started process (PID=10604) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:43:17.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:43:17.534+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:43:17.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:43:17.562+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:43:17.589+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:43:17.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:43:17.615+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:43:17.614+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:43:17.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2024-12-30T18:43:47.977+0000] {processor.py:186} INFO - Started process (PID=10630) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:43:47.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:43:47.982+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:43:47.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:43:48.001+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:43:48.034+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:43:48.034+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:43:48.063+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:43:48.063+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:43:48.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2024-12-30T18:44:18.380+0000] {processor.py:186} INFO - Started process (PID=10656) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:44:18.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:44:18.397+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:44:18.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:44:18.424+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:44:18.459+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:44:18.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:44:18.493+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:44:18.493+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:44:18.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.140 seconds
[2024-12-30T18:44:48.814+0000] {processor.py:186} INFO - Started process (PID=10682) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:44:48.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:44:48.818+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:44:48.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:44:48.835+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:44:48.862+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:44:48.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:44:48.883+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:44:48.883+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:44:48.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-30T18:45:19.239+0000] {processor.py:186} INFO - Started process (PID=10709) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:45:19.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:45:19.247+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:45:19.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:45:19.274+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:45:19.311+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:45:19.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:45:19.341+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:45:19.340+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:45:19.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2024-12-30T18:45:49.668+0000] {processor.py:186} INFO - Started process (PID=10735) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:45:49.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:45:49.672+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:45:49.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:45:49.691+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:45:49.718+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:45:49.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:45:49.743+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:45:49.743+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:45:49.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.113 seconds
[2024-12-30T18:46:20.067+0000] {processor.py:186} INFO - Started process (PID=10760) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:46:20.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:46:20.071+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:46:20.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:46:20.093+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:46:20.123+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:46:20.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:46:20.153+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:46:20.153+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:46:20.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2024-12-30T18:46:50.506+0000] {processor.py:186} INFO - Started process (PID=10786) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:46:50.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:46:50.513+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:46:50.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:46:50.540+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:46:50.582+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:46:50.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:46:50.608+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:46:50.608+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:46:50.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2024-12-30T18:47:20.991+0000] {processor.py:186} INFO - Started process (PID=10813) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:47:20.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:47:20.995+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:47:20.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:47:21.017+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:47:21.044+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:47:21.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:47:21.065+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:47:21.064+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:47:21.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T18:47:51.792+0000] {processor.py:186} INFO - Started process (PID=10838) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:47:51.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:47:51.803+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:47:51.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:47:51.829+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:47:51.864+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:47:51.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:47:51.886+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:47:51.886+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:47:51.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2024-12-30T18:48:22.198+0000] {processor.py:186} INFO - Started process (PID=10864) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:48:22.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:48:22.202+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:48:22.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:48:22.220+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:48:22.246+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:48:22.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:48:22.267+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:48:22.266+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:48:22.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-30T18:48:52.585+0000] {processor.py:186} INFO - Started process (PID=10890) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:48:52.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:48:52.589+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:48:52.589+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:48:52.607+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:48:52.632+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:48:52.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:48:52.670+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:48:52.670+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:48:52.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2024-12-30T18:49:23.074+0000] {processor.py:186} INFO - Started process (PID=10916) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:49:23.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:49:23.090+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:49:23.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:49:23.140+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:49:23.214+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:49:23.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:49:23.318+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:49:23.317+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:49:23.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.318 seconds
[2024-12-30T18:49:53.477+0000] {processor.py:186} INFO - Started process (PID=10942) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:49:53.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:49:53.481+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:49:53.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:49:53.498+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:49:53.523+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:49:53.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:49:53.546+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:49:53.546+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:49:53.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-30T18:50:24.076+0000] {processor.py:186} INFO - Started process (PID=10967) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:50:24.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:50:24.094+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:50:24.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:50:24.137+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:50:24.173+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:50:24.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:50:24.195+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:50:24.195+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:50:24.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.156 seconds
[2024-12-30T18:50:54.577+0000] {processor.py:186} INFO - Started process (PID=10992) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:50:54.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:50:54.583+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:50:54.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:50:54.655+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:50:54.742+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:50:54.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:50:54.812+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:50:54.812+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:50:54.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.271 seconds
[2024-12-30T18:51:24.983+0000] {processor.py:186} INFO - Started process (PID=11018) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:51:24.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:51:24.987+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:51:24.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:51:25.006+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:51:25.032+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:51:25.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:51:25.053+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:51:25.053+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:51:25.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-30T18:51:55.552+0000] {processor.py:186} INFO - Started process (PID=11045) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:51:55.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:51:55.557+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:51:55.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:51:55.584+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:51:55.618+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:51:55.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:51:55.669+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:51:55.669+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:51:55.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.146 seconds
[2024-12-30T18:52:25.820+0000] {processor.py:186} INFO - Started process (PID=11071) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:52:25.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:52:25.824+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:52:25.823+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:52:25.842+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:52:25.868+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:52:25.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:52:25.890+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:52:25.889+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:52:25.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-30T18:52:56.290+0000] {processor.py:186} INFO - Started process (PID=11097) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:52:56.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:52:56.295+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:52:56.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:52:56.323+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:52:56.362+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:52:56.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:52:56.392+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:52:56.392+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:52:56.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2024-12-30T18:53:26.710+0000] {processor.py:186} INFO - Started process (PID=11122) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:53:26.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:53:26.714+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:53:26.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:53:26.734+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:53:26.759+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:53:26.758+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:53:26.779+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:53:26.779+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:53:26.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-30T18:53:57.137+0000] {processor.py:186} INFO - Started process (PID=11148) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:53:57.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:53:57.145+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:53:57.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:53:57.173+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:53:57.206+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:53:57.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:53:57.241+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:53:57.241+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:53:57.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.142 seconds
[2024-12-30T18:54:27.479+0000] {processor.py:186} INFO - Started process (PID=11174) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:54:27.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:54:27.483+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:54:27.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:54:27.506+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:54:27.533+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:54:27.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:54:27.553+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:54:27.553+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:54:27.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-30T18:54:57.913+0000] {processor.py:186} INFO - Started process (PID=11200) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:54:57.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:54:57.925+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:54:57.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:54:57.967+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:54:58.021+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:54:58.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:54:58.085+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:54:58.085+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:54:58.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.222 seconds
[2024-12-30T18:55:28.292+0000] {processor.py:186} INFO - Started process (PID=11226) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:55:28.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:55:28.297+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:55:28.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:55:28.316+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:55:28.344+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:55:28.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:55:28.368+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:55:28.367+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:55:28.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2024-12-30T18:55:58.706+0000] {processor.py:186} INFO - Started process (PID=11253) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:55:58.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:55:58.713+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:55:58.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:55:58.741+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:55:58.789+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:55:58.789+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:55:58.834+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:55:58.834+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:55:58.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.170 seconds
[2024-12-30T18:56:29.159+0000] {processor.py:186} INFO - Started process (PID=11279) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:56:29.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:56:29.162+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:56:29.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:56:29.179+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:56:29.203+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:56:29.203+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:56:29.225+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:56:29.225+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:56:29.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-30T18:56:59.588+0000] {processor.py:186} INFO - Started process (PID=11305) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:56:59.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:56:59.597+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:56:59.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:56:59.622+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:56:59.669+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:56:59.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:56:59.698+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:56:59.698+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:56:59.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.147 seconds
[2024-12-30T18:57:30.025+0000] {processor.py:186} INFO - Started process (PID=11331) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:57:30.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:57:30.028+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:57:30.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:57:30.046+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:57:30.072+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:57:30.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:57:30.092+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:57:30.092+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:57:30.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-30T18:58:00.452+0000] {processor.py:186} INFO - Started process (PID=11357) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:58:00.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:58:00.458+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:58:00.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:58:00.486+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:58:00.514+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:58:00.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:58:00.544+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:58:00.543+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:58:00.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.123 seconds
[2024-12-30T18:58:30.878+0000] {processor.py:186} INFO - Started process (PID=11383) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:58:30.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:58:30.883+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:58:30.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:58:30.909+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:58:30.938+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:58:30.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:58:30.963+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:58:30.963+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:58:30.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2024-12-30T18:59:01.304+0000] {processor.py:186} INFO - Started process (PID=11410) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:59:01.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:59:01.308+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:59:01.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:59:01.326+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:59:01.354+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:59:01.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:59:01.377+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:59:01.377+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:59:01.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T18:59:31.702+0000] {processor.py:186} INFO - Started process (PID=11437) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:59:31.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T18:59:31.706+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:59:31.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:59:31.724+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T18:59:31.749+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:59:31.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T18:59:31.769+0000] {logging_mixin.py:190} INFO - [2024-12-30T18:59:31.769+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 17:00:00+00:00, run_after=2024-12-30 18:00:00+00:00
[2024-12-30T18:59:31.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-30T19:00:02.095+0000] {processor.py:186} INFO - Started process (PID=11463) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:00:02.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:00:02.098+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:00:02.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:00:02.116+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:00:02.140+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:00:02.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:00:02.160+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:00:02.160+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:00:02.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-30T19:00:32.510+0000] {processor.py:186} INFO - Started process (PID=11489) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:00:32.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:00:32.515+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:00:32.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:00:32.535+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:00:32.563+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:00:32.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:00:32.617+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:00:32.617+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:00:32.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2024-12-30T19:01:03.004+0000] {processor.py:186} INFO - Started process (PID=11515) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:01:03.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:01:03.009+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:01:03.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:01:03.029+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:01:03.059+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:01:03.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:01:03.081+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:01:03.081+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:01:03.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2024-12-30T19:01:33.407+0000] {processor.py:186} INFO - Started process (PID=11541) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:01:33.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:01:33.411+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:01:33.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:01:33.432+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:01:33.461+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:01:33.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:01:33.482+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:01:33.481+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:01:33.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-30T19:02:03.946+0000] {processor.py:186} INFO - Started process (PID=11567) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:02:03.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:02:03.951+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:02:03.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:02:03.970+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:02:04.002+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:02:04.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:02:04.028+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:02:04.028+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:02:04.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.112 seconds
[2024-12-30T19:02:34.340+0000] {processor.py:186} INFO - Started process (PID=11594) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:02:34.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:02:34.344+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:02:34.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:02:34.364+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:02:34.389+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:02:34.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:02:34.412+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:02:34.412+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:02:34.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-30T19:03:04.826+0000] {processor.py:186} INFO - Started process (PID=11620) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:03:04.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:03:04.830+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:03:04.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:03:04.850+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:03:04.878+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:03:04.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:03:04.903+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:03:04.903+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:03:04.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2024-12-30T19:03:35.222+0000] {processor.py:186} INFO - Started process (PID=11646) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:03:35.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:03:35.226+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:03:35.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:03:35.244+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:03:35.271+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:03:35.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:03:35.291+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:03:35.291+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:03:35.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-30T19:04:05.644+0000] {processor.py:186} INFO - Started process (PID=11672) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:04:05.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:04:05.648+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:04:05.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:04:05.665+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:04:05.690+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:04:05.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:04:05.712+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:04:05.712+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:04:05.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-30T19:04:36.064+0000] {processor.py:186} INFO - Started process (PID=11698) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:04:36.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:04:36.068+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:04:36.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:04:36.099+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:04:36.123+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:04:36.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:04:36.166+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:04:36.166+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:04:36.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.131 seconds
[2024-12-30T19:05:06.633+0000] {processor.py:186} INFO - Started process (PID=11724) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:05:06.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:05:06.641+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:05:06.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:05:06.670+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:05:06.716+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:05:06.716+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:05:06.754+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:05:06.754+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:05:06.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.156 seconds
[2024-12-30T19:05:37.113+0000] {processor.py:186} INFO - Started process (PID=11757) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:05:37.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:05:37.117+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:05:37.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:05:37.134+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:05:37.159+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:05:37.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:05:37.182+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:05:37.182+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:05:37.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-30T19:06:07.564+0000] {processor.py:186} INFO - Started process (PID=11782) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:06:07.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:06:07.568+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:06:07.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:06:07.593+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:06:07.627+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:06:07.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:06:07.664+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:06:07.664+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:06:07.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2024-12-30T19:06:38.005+0000] {processor.py:186} INFO - Started process (PID=11808) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:06:38.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:06:38.009+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:06:38.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:06:38.033+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:06:38.061+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:06:38.061+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:06:38.085+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:06:38.085+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:06:38.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2024-12-30T19:07:08.334+0000] {processor.py:186} INFO - Started process (PID=11834) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:07:08.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:07:08.340+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:07:08.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:07:08.366+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:07:08.396+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:07:08.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:07:08.421+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:07:08.421+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:07:08.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2024-12-30T19:07:38.745+0000] {processor.py:186} INFO - Started process (PID=11862) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:07:38.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:07:38.751+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:07:38.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:07:38.772+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:07:38.808+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:07:38.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:07:38.841+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:07:38.841+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:07:38.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2024-12-30T19:08:09.136+0000] {processor.py:186} INFO - Started process (PID=11888) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:08:09.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:08:09.140+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:08:09.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:08:09.158+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:08:09.184+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:08:09.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:08:09.206+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:08:09.206+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:08:09.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-30T19:08:39.490+0000] {processor.py:186} INFO - Started process (PID=11914) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:08:39.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:08:39.494+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:08:39.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:08:39.514+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:08:39.539+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:08:39.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:08:39.560+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:08:39.560+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:08:39.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-30T19:09:09.869+0000] {processor.py:186} INFO - Started process (PID=11940) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:09:09.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:09:09.874+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:09:09.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:09:09.893+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:09:09.919+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:09:09.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:09:09.941+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:09:09.941+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:09:09.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T19:09:40.301+0000] {processor.py:186} INFO - Started process (PID=11966) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:09:40.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:09:40.305+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:09:40.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:09:40.324+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:09:40.351+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:09:40.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:09:40.371+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:09:40.371+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:09:40.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-30T19:10:10.719+0000] {processor.py:186} INFO - Started process (PID=11992) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:10:10.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:10:10.722+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:10:10.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:10:10.740+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:10:10.767+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:10:10.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:10:10.790+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:10:10.790+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:10:10.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.100 seconds
[2024-12-30T19:10:41.107+0000] {processor.py:186} INFO - Started process (PID=12018) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:10:41.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:10:41.113+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:10:41.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:10:41.140+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:10:41.172+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:10:41.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:10:41.212+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:10:41.212+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:10:41.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.141 seconds
[2024-12-30T19:11:11.505+0000] {processor.py:186} INFO - Started process (PID=12044) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:11:11.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:11:11.509+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:11:11.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:11:11.532+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:11:11.559+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:11:11.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:11:11.581+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:11:11.580+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:11:11.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T19:11:41.881+0000] {processor.py:186} INFO - Started process (PID=12071) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:11:41.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:11:41.887+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:11:41.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:11:41.908+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:11:41.946+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:11:41.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:11:41.975+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:11:41.975+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:11:41.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2024-12-30T19:12:12.270+0000] {processor.py:186} INFO - Started process (PID=12098) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:12:12.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:12:12.274+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:12:12.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:12:12.293+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:12:12.321+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:12:12.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:12:12.344+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:12:12.343+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:12:12.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2024-12-30T19:12:42.666+0000] {processor.py:186} INFO - Started process (PID=12124) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:12:42.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:12:42.670+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:12:42.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:12:42.688+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:12:42.714+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:12:42.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:12:42.735+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:12:42.735+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:12:42.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-30T19:13:13.089+0000] {processor.py:186} INFO - Started process (PID=12150) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:13:13.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:13:13.093+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:13:13.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:13:13.113+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:13:13.141+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:13:13.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:13:13.165+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:13:13.165+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:13:13.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-30T19:13:43.497+0000] {processor.py:186} INFO - Started process (PID=12175) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:13:43.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:13:43.501+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:13:43.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:13:43.518+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:13:43.545+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:13:43.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:13:43.565+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:13:43.565+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:13:43.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-30T19:14:14.125+0000] {processor.py:186} INFO - Started process (PID=12201) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:14:14.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:14:14.132+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:14:14.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:14:14.164+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:14:14.202+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:14:14.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:14:14.232+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:14:14.232+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:14:14.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.141 seconds
[2024-12-30T19:14:44.394+0000] {processor.py:186} INFO - Started process (PID=12227) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:14:44.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:14:44.398+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:14:44.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:14:44.418+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:14:44.443+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:14:44.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:14:44.464+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:14:44.464+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:14:44.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-30T19:15:14.846+0000] {processor.py:186} INFO - Started process (PID=12253) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:15:14.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:15:14.851+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:15:14.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:15:14.875+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:15:14.904+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:15:14.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:15:14.937+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:15:14.936+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:15:14.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2024-12-30T19:15:45.304+0000] {processor.py:186} INFO - Started process (PID=12280) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:15:45.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:15:45.308+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:15:45.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:15:45.326+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:15:45.350+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:15:45.350+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:15:45.370+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:15:45.370+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:15:45.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-30T19:16:15.712+0000] {processor.py:186} INFO - Started process (PID=12306) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:16:15.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:16:15.717+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:16:15.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:16:15.737+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:16:15.762+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:16:15.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:16:15.784+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:16:15.784+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:16:15.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-30T19:16:46.063+0000] {processor.py:186} INFO - Started process (PID=12332) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:16:46.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T19:16:46.068+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:16:46.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:16:46.088+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T19:16:46.117+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:16:46.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T19:16:46.140+0000] {logging_mixin.py:190} INFO - [2024-12-30T19:16:46.140+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 18:00:00+00:00, run_after=2024-12-30 19:00:00+00:00
[2024-12-30T19:16:46.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-30T20:33:19.648+0000] {processor.py:186} INFO - Started process (PID=12361) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:33:19.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:33:19.664+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:33:19.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:33:19.843+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:33:19.961+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:33:19.961+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:33:20.187+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:33:20.187+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:33:20.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.745 seconds
[2024-12-30T20:33:51.224+0000] {processor.py:186} INFO - Started process (PID=12392) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:33:51.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:33:51.233+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:33:51.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:33:51.268+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:33:51.329+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:33:51.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:33:51.366+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:33:51.366+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:33:51.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.204 seconds
[2024-12-30T20:34:21.452+0000] {processor.py:186} INFO - Started process (PID=12417) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:34:21.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:34:21.467+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:34:21.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:34:21.486+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:34:21.513+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:34:21.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:34:21.538+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:34:21.538+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:34:21.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2024-12-30T20:34:51.929+0000] {processor.py:186} INFO - Started process (PID=12468) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:34:51.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:34:51.940+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:34:51.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:34:51.980+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:34:52.056+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:34:52.056+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:34:52.111+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:34:52.110+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:34:52.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.221 seconds
[2024-12-30T20:35:22.411+0000] {processor.py:186} INFO - Started process (PID=12494) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:35:22.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:35:22.418+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:35:22.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:35:22.448+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:35:22.484+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:35:22.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:35:22.508+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:35:22.508+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:35:22.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.138 seconds
[2024-12-30T20:35:52.886+0000] {processor.py:186} INFO - Started process (PID=12519) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:35:52.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:35:52.889+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:35:52.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:35:52.909+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:35:52.937+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:35:52.937+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:35:52.958+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:35:52.958+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:35:52.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-30T20:36:23.309+0000] {processor.py:186} INFO - Started process (PID=12545) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:36:23.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:36:23.313+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:36:23.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:36:23.334+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:36:23.361+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:36:23.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:36:23.383+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:36:23.383+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:36:23.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2024-12-30T20:36:53.782+0000] {processor.py:186} INFO - Started process (PID=12571) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:36:53.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:36:53.799+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:36:53.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:36:53.868+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:36:53.944+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:36:53.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:36:53.994+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:36:53.993+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:36:54.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.286 seconds
[2024-12-30T20:37:24.157+0000] {processor.py:186} INFO - Started process (PID=12596) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:37:24.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:37:24.161+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:37:24.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:37:24.186+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:37:24.213+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:37:24.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:37:24.235+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:37:24.235+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:37:24.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.107 seconds
[2024-12-30T20:37:54.500+0000] {processor.py:186} INFO - Started process (PID=12622) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:37:54.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:37:54.504+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:37:54.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:37:54.523+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:37:54.551+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:37:54.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:37:54.572+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:37:54.572+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:37:54.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-30T20:38:24.920+0000] {processor.py:186} INFO - Started process (PID=12648) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:38:24.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:38:24.924+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:38:24.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:38:24.942+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:38:24.966+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:38:24.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:38:24.988+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:38:24.988+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:38:25.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-30T20:38:55.326+0000] {processor.py:186} INFO - Started process (PID=12674) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:38:55.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:38:55.331+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:38:55.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:38:55.359+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:38:55.396+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:38:55.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:38:55.427+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:38:55.427+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:38:55.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2024-12-30T20:39:25.785+0000] {processor.py:186} INFO - Started process (PID=12700) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:39:25.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:39:25.789+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:39:25.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:39:25.808+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:39:25.834+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:39:25.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:39:25.855+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:39:25.855+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:39:25.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-30T20:39:56.280+0000] {processor.py:186} INFO - Started process (PID=12726) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:39:56.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:39:56.284+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:39:56.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:39:56.305+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:39:56.334+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:39:56.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:39:56.356+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:39:56.356+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:39:56.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-30T20:40:26.965+0000] {processor.py:186} INFO - Started process (PID=12752) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:40:26.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:40:26.969+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:40:26.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:40:27.015+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:40:27.047+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:40:27.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:40:27.080+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:40:27.080+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:40:27.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.151 seconds
[2024-12-30T20:40:57.719+0000] {processor.py:186} INFO - Started process (PID=12778) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:40:57.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:40:57.729+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:40:57.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:40:57.801+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:40:57.856+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:40:57.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:40:57.904+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:40:57.904+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:40:57.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.246 seconds
[2024-12-30T20:41:28.451+0000] {processor.py:186} INFO - Started process (PID=12804) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:41:28.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:41:28.463+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:41:28.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:41:28.541+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:41:28.691+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:41:28.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:41:28.807+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:41:28.807+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:41:28.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.433 seconds
[2024-12-30T20:41:59.128+0000] {processor.py:186} INFO - Started process (PID=12830) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:41:59.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:41:59.140+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:41:59.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:41:59.220+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:41:59.301+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:41:59.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:41:59.371+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:41:59.371+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:41:59.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.319 seconds
[2024-12-30T20:42:29.642+0000] {processor.py:186} INFO - Started process (PID=12855) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:42:29.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:42:29.654+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:42:29.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:42:29.727+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:42:29.797+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:42:29.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:42:29.858+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:42:29.857+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:42:29.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.290 seconds
[2024-12-30T20:43:00.036+0000] {processor.py:186} INFO - Started process (PID=12880) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:43:00.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:43:00.043+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:43:00.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:43:00.086+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:43:00.134+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:43:00.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:43:00.181+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:43:00.180+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:43:00.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.213 seconds
[2024-12-30T20:43:30.452+0000] {processor.py:186} INFO - Started process (PID=12906) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:43:30.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:43:30.457+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:43:30.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:43:30.493+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:43:30.525+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:43:30.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:43:30.553+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:43:30.553+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:43:30.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.148 seconds
[2024-12-30T20:44:01.056+0000] {processor.py:186} INFO - Started process (PID=12932) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:44:01.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:44:01.072+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:44:01.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:44:01.116+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:44:01.162+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:44:01.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:44:01.203+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:44:01.203+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:44:01.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.183 seconds
[2024-12-30T20:44:31.634+0000] {processor.py:186} INFO - Started process (PID=12958) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:44:31.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:44:31.638+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:44:31.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:44:31.666+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:44:31.698+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:44:31.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:44:31.725+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:44:31.724+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:44:31.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.131 seconds
[2024-12-30T20:45:02.310+0000] {processor.py:186} INFO - Started process (PID=12982) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:45:02.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:45:02.321+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:45:02.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:45:02.387+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:45:02.467+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:45:02.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:45:02.535+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:45:02.534+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:45:02.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.292 seconds
[2024-12-30T20:45:33.248+0000] {processor.py:186} INFO - Started process (PID=13008) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:45:33.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:45:33.257+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:45:33.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:45:33.293+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:45:33.333+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:45:33.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:45:33.377+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:45:33.377+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:45:33.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.183 seconds
[2024-12-30T20:46:03.770+0000] {processor.py:186} INFO - Started process (PID=13034) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:46:03.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:46:03.781+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:46:03.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:46:03.856+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:46:04.021+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:46:04.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:46:04.096+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:46:04.096+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:46:04.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.413 seconds
[2024-12-30T20:46:34.678+0000] {processor.py:186} INFO - Started process (PID=13060) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:46:34.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:46:34.684+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:46:34.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:46:34.717+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:46:34.757+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:46:34.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:46:34.787+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:46:34.787+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:46:34.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.144 seconds
[2024-12-30T20:47:05.046+0000] {processor.py:186} INFO - Started process (PID=13086) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:47:05.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:47:05.050+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:47:05.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:47:05.090+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:47:05.126+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:47:05.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:47:05.157+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:47:05.157+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:47:05.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2024-12-30T20:47:35.787+0000] {processor.py:186} INFO - Started process (PID=13112) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:47:35.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:47:35.796+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:47:35.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:47:35.852+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:47:35.918+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:47:35.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:47:35.958+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:47:35.958+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:47:35.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.214 seconds
[2024-12-30T20:48:06.290+0000] {processor.py:186} INFO - Started process (PID=13144) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:48:06.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:48:06.295+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:48:06.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:48:06.351+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:48:06.383+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:48:06.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:48:06.411+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:48:06.410+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:48:06.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.150 seconds
[2024-12-30T20:48:36.820+0000] {processor.py:186} INFO - Started process (PID=13170) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:48:36.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:48:36.832+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:48:36.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:48:36.891+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:48:36.964+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:48:36.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:48:37.016+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:48:37.015+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:48:37.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.259 seconds
[2024-12-30T20:49:07.598+0000] {processor.py:186} INFO - Started process (PID=13197) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:49:07.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:49:07.643+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:49:07.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:49:07.745+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:49:07.874+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:49:07.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:49:07.979+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:49:07.978+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:49:08.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.476 seconds
[2024-12-30T20:49:38.420+0000] {processor.py:186} INFO - Started process (PID=13223) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:49:38.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:49:38.425+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:49:38.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:49:38.456+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:49:38.488+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:49:38.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:49:38.515+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:49:38.514+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:49:38.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2024-12-30T20:50:08.979+0000] {processor.py:186} INFO - Started process (PID=13250) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:50:08.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:50:08.989+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:50:08.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:50:09.041+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:50:09.099+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:50:09.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:50:09.145+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:50:09.144+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:50:09.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.220 seconds
[2024-12-30T20:50:39.684+0000] {processor.py:186} INFO - Started process (PID=13276) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:50:39.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:50:39.691+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:50:39.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:50:39.748+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:50:39.804+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:50:39.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:50:39.853+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:50:39.853+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:50:39.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.220 seconds
[2024-12-30T20:51:10.103+0000] {processor.py:186} INFO - Started process (PID=13302) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:51:10.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:51:10.110+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:51:10.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:51:10.161+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:51:10.216+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:51:10.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:51:10.251+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:51:10.251+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:51:10.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.185 seconds
[2024-12-30T20:51:40.680+0000] {processor.py:186} INFO - Started process (PID=13328) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:51:40.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:51:40.685+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:51:40.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:51:40.714+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:51:40.744+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:51:40.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:51:40.767+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:51:40.767+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:51:40.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2024-12-30T20:52:11.301+0000] {processor.py:186} INFO - Started process (PID=13355) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:52:11.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:52:11.310+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:52:11.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:52:11.373+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:52:11.452+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:52:11.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:52:11.524+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:52:11.523+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:52:11.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.299 seconds
[2024-12-30T20:52:42.148+0000] {processor.py:186} INFO - Started process (PID=13381) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:52:42.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:52:42.158+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:52:42.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:52:42.242+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:52:42.291+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:52:42.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:52:42.333+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:52:42.333+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:52:42.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.241 seconds
[2024-12-30T20:53:12.881+0000] {processor.py:186} INFO - Started process (PID=13407) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:53:12.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:53:12.887+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:53:12.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:53:12.936+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:53:12.965+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:53:12.964+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:53:12.994+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:53:12.994+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:53:13.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.172 seconds
[2024-12-30T20:53:43.498+0000] {processor.py:186} INFO - Started process (PID=13433) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:53:43.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:53:43.511+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:53:43.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:53:43.568+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:53:43.620+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:53:43.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:53:43.660+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:53:43.660+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:53:43.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.219 seconds
[2024-12-30T20:54:13.876+0000] {processor.py:186} INFO - Started process (PID=13460) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:54:13.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:54:13.886+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:54:13.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:54:13.935+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:54:13.998+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:54:13.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:54:14.024+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:54:14.023+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:54:14.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.188 seconds
[2024-12-30T20:54:44.503+0000] {processor.py:186} INFO - Started process (PID=13486) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:54:44.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:54:44.511+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:54:44.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:54:44.564+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:54:44.627+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:54:44.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:54:44.675+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:54:44.674+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:54:44.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.230 seconds
[2024-12-30T20:55:14.838+0000] {processor.py:186} INFO - Started process (PID=13512) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:55:14.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:55:14.848+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:55:14.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:55:14.901+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:55:14.952+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:55:14.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:55:14.979+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:55:14.979+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:55:15.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.180 seconds
[2024-12-30T20:55:45.144+0000] {processor.py:186} INFO - Started process (PID=13538) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:55:45.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:55:45.156+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:55:45.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:55:45.236+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:55:45.363+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:55:45.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:55:45.462+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:55:45.462+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:55:45.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.390 seconds
[2024-12-30T20:56:16.426+0000] {processor.py:186} INFO - Started process (PID=13563) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:56:16.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:56:16.432+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:56:16.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:56:16.480+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:56:16.533+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:56:16.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:56:16.576+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:56:16.576+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:56:16.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.194 seconds
[2024-12-30T20:56:46.945+0000] {processor.py:186} INFO - Started process (PID=13588) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:56:46.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:56:46.956+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:56:46.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:56:47.045+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:56:47.184+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:56:47.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:56:47.279+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:56:47.278+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:56:47.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.393 seconds
[2024-12-30T20:57:17.486+0000] {processor.py:186} INFO - Started process (PID=13614) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:57:17.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:57:17.492+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:57:17.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:57:17.534+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:57:17.583+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:57:17.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:57:17.628+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:57:17.628+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:57:17.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.192 seconds
[2024-12-30T20:57:47.996+0000] {processor.py:186} INFO - Started process (PID=13640) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:57:48.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:57:48.030+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:57:48.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:57:48.126+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:57:48.250+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:57:48.250+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:57:48.390+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:57:48.389+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:57:48.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.509 seconds
[2024-12-30T20:58:18.944+0000] {processor.py:186} INFO - Started process (PID=13666) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:58:18.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:58:18.954+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:58:18.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:58:19.019+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:58:19.111+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:58:19.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:58:19.168+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:58:19.168+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:58:19.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.281 seconds
[2024-12-30T20:58:49.731+0000] {processor.py:186} INFO - Started process (PID=13692) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:58:49.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:58:49.745+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:58:49.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:58:49.823+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:58:49.902+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:58:49.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:58:49.952+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:58:49.952+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:58:49.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.283 seconds
[2024-12-30T20:59:20.535+0000] {processor.py:186} INFO - Started process (PID=13718) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:59:20.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:59:20.540+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:59:20.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:59:20.579+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:59:20.618+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:59:20.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:59:20.658+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:59:20.657+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:59:20.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.158 seconds
[2024-12-30T20:59:51.143+0000] {processor.py:186} INFO - Started process (PID=13745) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:59:51.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T20:59:51.148+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:59:51.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:59:51.176+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T20:59:51.214+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:59:51.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T20:59:51.244+0000] {logging_mixin.py:190} INFO - [2024-12-30T20:59:51.244+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 19:00:00+00:00, run_after=2024-12-30 20:00:00+00:00
[2024-12-30T20:59:51.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.137 seconds
[2024-12-30T21:00:21.458+0000] {processor.py:186} INFO - Started process (PID=13770) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:00:21.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:00:21.469+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:00:21.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:00:21.590+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:00:21.672+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:00:21.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:00:21.744+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:00:21.744+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:00:21.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.366 seconds
[2024-12-30T21:00:52.430+0000] {processor.py:186} INFO - Started process (PID=13797) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:00:52.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:00:52.443+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:00:52.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:00:52.519+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:00:52.631+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:00:52.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:00:52.752+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:00:52.751+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:00:52.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.449 seconds
[2024-12-30T21:01:23.136+0000] {processor.py:186} INFO - Started process (PID=13823) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:01:23.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:01:23.146+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:01:23.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:01:23.235+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:01:23.332+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:01:23.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:01:23.378+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:01:23.377+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:01:23.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.311 seconds
[2024-12-30T21:01:53.937+0000] {processor.py:186} INFO - Started process (PID=13849) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:01:53.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:01:53.945+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:01:53.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:01:54.041+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:01:54.141+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:01:54.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:01:54.234+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:01:54.234+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:01:54.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.417 seconds
[2024-12-30T21:02:24.511+0000] {processor.py:186} INFO - Started process (PID=13875) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:02:24.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:02:24.523+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:02:24.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:02:24.613+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:02:24.746+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:02:24.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:02:24.846+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:02:24.846+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:02:24.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.450 seconds
[2024-12-30T21:02:55.412+0000] {processor.py:186} INFO - Started process (PID=13901) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:02:55.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:02:55.416+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:02:55.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:02:55.486+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:02:55.521+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:02:55.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:02:55.553+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:02:55.552+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:02:55.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.185 seconds
[2024-12-30T21:03:25.930+0000] {processor.py:186} INFO - Started process (PID=13927) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:03:25.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:03:25.934+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:03:25.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:03:25.963+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:03:25.991+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:03:25.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:03:26.019+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:03:26.019+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:03:26.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2024-12-30T21:03:56.459+0000] {processor.py:186} INFO - Started process (PID=13959) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:03:56.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:03:56.463+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:03:56.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:03:56.492+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:03:56.524+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:03:56.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:03:56.552+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:03:56.552+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:03:56.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2024-12-30T21:04:27.062+0000] {processor.py:186} INFO - Started process (PID=13985) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:04:27.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:04:27.071+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:04:27.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:04:27.162+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:04:27.208+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:04:27.208+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:04:27.248+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:04:27.247+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:04:27.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.246 seconds
[2024-12-30T21:04:57.983+0000] {processor.py:186} INFO - Started process (PID=14011) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:04:58.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:04:58.029+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:04:58.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:04:58.137+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:04:58.254+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:04:58.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:04:58.284+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:04:58.284+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:04:58.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.376 seconds
[2024-12-30T21:05:28.843+0000] {processor.py:186} INFO - Started process (PID=14037) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:05:28.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:05:28.854+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:05:28.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:05:28.893+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:05:28.940+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:05:28.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:05:28.981+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:05:28.981+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:05:29.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.191 seconds
[2024-12-30T21:05:59.522+0000] {processor.py:186} INFO - Started process (PID=14063) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:05:59.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:05:59.533+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:05:59.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:05:59.607+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:05:59.712+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:05:59.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:05:59.754+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:05:59.754+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:05:59.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.296 seconds
[2024-12-30T21:06:30.410+0000] {processor.py:186} INFO - Started process (PID=14089) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:06:30.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:06:30.415+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:06:30.414+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:06:30.439+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:06:30.476+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:06:30.476+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:06:30.503+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:06:30.503+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:06:30.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2024-12-30T21:07:00.959+0000] {processor.py:186} INFO - Started process (PID=14115) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:07:00.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:07:00.970+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:07:00.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:07:01.032+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:07:01.117+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:07:01.116+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:07:01.205+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:07:01.205+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:07:01.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.352 seconds
[2024-12-30T21:07:31.845+0000] {processor.py:186} INFO - Started process (PID=14141) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:07:31.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:07:31.861+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:07:31.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:07:31.953+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:07:32.031+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:07:32.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:07:32.094+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:07:32.094+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:07:32.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.334 seconds
[2024-12-30T21:08:02.280+0000] {processor.py:186} INFO - Started process (PID=14167) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:08:02.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:08:02.288+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:08:02.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:08:02.334+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:08:02.372+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:08:02.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:08:02.397+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:08:02.397+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:08:02.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.155 seconds
[2024-12-30T21:08:33.080+0000] {processor.py:186} INFO - Started process (PID=14193) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:08:33.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:08:33.090+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:08:33.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:08:33.165+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:08:33.261+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:08:33.260+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:08:33.349+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:08:33.347+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:08:33.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.342 seconds
[2024-12-30T21:09:03.871+0000] {processor.py:186} INFO - Started process (PID=14219) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:09:03.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:09:03.882+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:09:03.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:09:03.945+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:09:04.023+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:09:04.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:09:04.065+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:09:04.065+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:09:04.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.251 seconds
[2024-12-30T21:09:34.302+0000] {processor.py:186} INFO - Started process (PID=14245) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:09:34.304+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:09:34.308+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:09:34.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:09:34.340+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:09:34.379+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:09:34.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:09:34.435+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:09:34.434+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:09:34.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.169 seconds
[2024-12-30T21:10:05.125+0000] {processor.py:186} INFO - Started process (PID=14271) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:10:05.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:10:05.133+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:10:05.132+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:10:05.191+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:10:05.251+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:10:05.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:10:05.301+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:10:05.301+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:10:05.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.245 seconds
[2024-12-30T21:10:35.871+0000] {processor.py:186} INFO - Started process (PID=14297) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:10:35.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:10:35.876+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:10:35.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:10:35.905+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:10:35.941+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:10:35.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:10:36.004+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:10:36.004+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:10:36.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.166 seconds
[2024-12-30T21:11:06.483+0000] {processor.py:186} INFO - Started process (PID=14323) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:11:06.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:11:06.486+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:11:06.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:11:06.511+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:11:06.538+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:11:06.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:11:06.561+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:11:06.561+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:11:06.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2024-12-30T21:11:37.069+0000] {processor.py:186} INFO - Started process (PID=14349) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:11:37.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:11:37.078+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:11:37.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:11:37.121+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:11:37.195+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:11:37.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:11:37.241+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:11:37.241+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:11:37.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.246 seconds
[2024-12-30T21:12:07.894+0000] {processor.py:186} INFO - Started process (PID=14375) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:12:07.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:12:07.953+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:12:07.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:12:08.006+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:12:08.132+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:12:08.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:12:08.209+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:12:08.208+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:12:08.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.405 seconds
[2024-12-30T21:12:38.418+0000] {processor.py:186} INFO - Started process (PID=14401) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:12:38.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:12:38.424+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:12:38.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:12:38.469+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:12:38.499+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:12:38.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:12:38.520+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:12:38.520+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:12:38.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2024-12-30T21:13:09.289+0000] {processor.py:186} INFO - Started process (PID=14427) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:13:09.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:13:09.349+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:13:09.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:13:09.459+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:13:09.548+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:13:09.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:13:09.618+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:13:09.617+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:13:09.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.417 seconds
[2024-12-30T21:13:39.939+0000] {processor.py:186} INFO - Started process (PID=14453) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:13:39.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:13:39.951+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:13:39.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:13:40.028+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:13:40.110+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:13:40.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:13:40.181+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:13:40.180+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:13:40.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.317 seconds
[2024-12-30T21:14:10.769+0000] {processor.py:186} INFO - Started process (PID=14479) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:14:10.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:14:10.780+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:14:10.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:14:10.860+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:14:10.941+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:14:10.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:14:11.010+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:14:11.010+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:14:11.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.329 seconds
[2024-12-30T21:14:41.714+0000] {processor.py:186} INFO - Started process (PID=14506) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:14:41.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:14:41.742+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:14:41.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:14:41.853+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:14:41.979+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:14:41.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:14:42.090+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:14:42.090+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:14:42.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.446 seconds
[2024-12-30T21:15:12.663+0000] {processor.py:186} INFO - Started process (PID=14532) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:15:12.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:15:12.669+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:15:12.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:15:12.713+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:15:12.755+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:15:12.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:15:12.793+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:15:12.793+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:15:12.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.176 seconds
[2024-12-30T21:15:43.346+0000] {processor.py:186} INFO - Started process (PID=14558) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:15:43.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:15:43.356+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:15:43.355+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:15:43.403+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:15:43.459+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:15:43.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:15:43.509+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:15:43.509+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:15:43.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.269 seconds
[2024-12-30T21:16:14.080+0000] {processor.py:186} INFO - Started process (PID=14583) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:16:14.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:16:14.087+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:16:14.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:16:14.143+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:16:14.206+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:16:14.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:16:14.301+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:16:14.301+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:16:14.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.272 seconds
[2024-12-30T21:16:44.564+0000] {processor.py:186} INFO - Started process (PID=14609) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:16:44.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:16:44.574+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:16:44.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:16:44.648+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:16:44.736+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:16:44.735+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:16:44.797+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:16:44.797+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:16:44.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.293 seconds
[2024-12-30T21:17:15.580+0000] {processor.py:186} INFO - Started process (PID=14635) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:17:15.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:17:15.596+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:17:15.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:17:15.671+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:17:15.799+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:17:15.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:17:15.851+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:17:15.850+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:17:15.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.336 seconds
[2024-12-30T21:17:46.038+0000] {processor.py:186} INFO - Started process (PID=14661) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:17:46.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:17:46.049+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:17:46.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:17:46.116+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:17:46.205+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:17:46.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:17:46.245+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:17:46.245+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:17:46.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.267 seconds
[2024-12-30T21:18:16.746+0000] {processor.py:186} INFO - Started process (PID=14686) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:18:16.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:18:16.750+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:18:16.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:18:16.776+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:18:16.820+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:18:16.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:18:16.854+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:18:16.854+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:18:16.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.146 seconds
[2024-12-30T21:18:47.454+0000] {processor.py:186} INFO - Started process (PID=14712) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:18:47.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:18:47.463+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:18:47.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:18:47.531+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:18:47.600+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:18:47.599+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:18:47.695+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:18:47.695+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:18:47.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.309 seconds
[2024-12-30T21:19:18.230+0000] {processor.py:186} INFO - Started process (PID=14739) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:19:18.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:19:18.235+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:19:18.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:19:18.277+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:19:18.313+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:19:18.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:19:18.339+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:19:18.339+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:19:18.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.145 seconds
[2024-12-30T21:19:48.949+0000] {processor.py:186} INFO - Started process (PID=14766) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:19:48.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:19:48.959+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:19:48.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:19:49.024+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:19:49.103+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:19:49.102+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:19:49.269+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:19:49.269+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:19:49.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.462 seconds
[2024-12-30T21:20:19.547+0000] {processor.py:186} INFO - Started process (PID=14799) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:20:19.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:20:19.557+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:20:19.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:20:19.607+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:20:19.689+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:20:19.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:20:19.756+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:20:19.756+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:20:19.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.281 seconds
[2024-12-30T21:20:50.072+0000] {processor.py:186} INFO - Started process (PID=14825) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:20:50.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:20:50.103+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:20:50.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:20:50.155+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:20:50.207+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:20:50.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:20:50.244+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:20:50.244+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:20:50.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.229 seconds
[2024-12-30T21:21:20.773+0000] {processor.py:186} INFO - Started process (PID=14850) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:21:20.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:21:20.779+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:21:20.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:21:20.823+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:21:20.855+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:21:20.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:21:20.886+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:21:20.886+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:21:20.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.146 seconds
[2024-12-30T21:21:51.543+0000] {processor.py:186} INFO - Started process (PID=14876) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:21:51.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:21:51.558+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:21:51.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:21:51.829+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:21:52.043+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:21:52.042+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:21:52.171+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:21:52.170+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:21:52.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.718 seconds
[2024-12-30T21:22:22.708+0000] {processor.py:186} INFO - Started process (PID=14902) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:22:22.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:22:22.725+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:22:22.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:22:22.861+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:22:22.954+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:22:22.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:22:23.041+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:22:23.041+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:22:23.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.445 seconds
[2024-12-30T21:22:53.755+0000] {processor.py:186} INFO - Started process (PID=14927) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:22:53.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:22:53.786+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:22:53.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:22:53.921+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:22:54.057+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:22:54.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:22:54.165+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:22:54.164+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:22:54.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.514 seconds
[2024-12-30T21:23:24.498+0000] {processor.py:186} INFO - Started process (PID=14953) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:23:24.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:23:24.510+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:23:24.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:23:24.565+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:23:24.615+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:23:24.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:23:24.665+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:23:24.664+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:23:24.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.233 seconds
[2024-12-30T21:23:55.353+0000] {processor.py:186} INFO - Started process (PID=14979) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:23:55.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:23:55.362+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:23:55.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:23:55.435+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:23:55.463+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:23:55.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:23:55.489+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:23:55.488+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:23:55.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.173 seconds
[2024-12-30T21:24:26.009+0000] {processor.py:186} INFO - Started process (PID=15005) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:24:26.011+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:24:26.019+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:24:26.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:24:26.074+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:24:26.143+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:24:26.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:24:26.206+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:24:26.206+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:24:26.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.255 seconds
[2024-12-30T21:24:57.015+0000] {processor.py:186} INFO - Started process (PID=15031) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:24:57.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:24:57.025+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:24:57.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:24:57.109+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:24:57.201+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:24:57.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:24:57.266+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:24:57.266+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:24:57.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.323 seconds
[2024-12-30T21:25:27.863+0000] {processor.py:186} INFO - Started process (PID=15057) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:25:27.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:25:27.874+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:25:27.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:25:27.951+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:25:28.071+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:25:28.070+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:25:28.249+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:25:28.248+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:25:28.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.492 seconds
[2024-12-30T21:25:58.771+0000] {processor.py:186} INFO - Started process (PID=15082) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:25:58.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:25:58.782+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:25:58.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:25:58.859+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:25:58.955+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:25:58.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:25:59.121+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:25:59.120+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:25:59.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.409 seconds
[2024-12-30T21:26:29.331+0000] {processor.py:186} INFO - Started process (PID=15108) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:26:29.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:26:29.346+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:26:29.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:26:29.467+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:26:29.588+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:26:29.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:26:29.710+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:26:29.710+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:26:29.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.494 seconds
[2024-12-30T21:27:00.344+0000] {processor.py:186} INFO - Started process (PID=15134) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:27:00.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:27:00.348+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:27:00.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:27:00.379+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:27:00.407+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:27:00.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:27:00.437+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:27:00.437+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:27:00.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2024-12-30T21:27:30.977+0000] {processor.py:186} INFO - Started process (PID=15160) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:27:30.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:27:30.984+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:27:30.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:27:31.039+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:27:31.098+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:27:31.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:27:31.120+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:27:31.119+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:27:31.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.185 seconds
[2024-12-30T21:28:01.674+0000] {processor.py:186} INFO - Started process (PID=15186) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:28:01.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:28:01.685+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:28:01.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:28:01.747+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:28:01.827+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:28:01.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:28:01.925+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:28:01.925+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:28:02.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.352 seconds
[2024-12-30T21:28:32.290+0000] {processor.py:186} INFO - Started process (PID=15212) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:28:32.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:28:32.309+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:28:32.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:28:32.373+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:28:32.442+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:28:32.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:28:32.526+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:28:32.526+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:28:32.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.309 seconds
[2024-12-30T21:29:03.104+0000] {processor.py:186} INFO - Started process (PID=15238) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:29:03.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:29:03.114+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:29:03.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:29:03.179+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:29:03.227+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:29:03.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:29:03.268+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:29:03.268+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:29:03.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.217 seconds
[2024-12-30T21:29:33.865+0000] {processor.py:186} INFO - Started process (PID=15264) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:29:33.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:29:33.878+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:29:33.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:29:33.972+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:29:34.074+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:29:34.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:29:34.147+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:29:34.147+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:29:34.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.382 seconds
[2024-12-30T21:30:04.571+0000] {processor.py:186} INFO - Started process (PID=15290) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:30:04.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:30:04.581+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:30:04.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:30:04.648+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:30:04.714+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:30:04.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:30:04.772+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:30:04.772+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:30:04.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.260 seconds
[2024-12-30T21:30:35.656+0000] {processor.py:186} INFO - Started process (PID=15315) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:30:35.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:30:35.660+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:30:35.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:30:35.690+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:30:35.724+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:30:35.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:30:35.751+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:30:35.750+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:30:35.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2024-12-30T21:31:05.991+0000] {processor.py:186} INFO - Started process (PID=15342) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:31:05.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:31:06.002+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:31:06.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:31:06.047+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:31:06.117+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:31:06.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:31:06.155+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:31:06.154+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:31:06.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.243 seconds
[2024-12-30T21:31:36.877+0000] {processor.py:186} INFO - Started process (PID=15368) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:31:36.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:31:36.887+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:31:36.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:31:36.961+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:31:37.050+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:31:37.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:31:37.099+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:31:37.098+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:31:37.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.289 seconds
[2024-12-30T21:32:07.703+0000] {processor.py:186} INFO - Started process (PID=15394) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:32:07.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:32:07.711+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:32:07.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:32:07.763+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:32:07.852+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:32:07.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:32:07.949+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:32:07.949+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:32:07.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.304 seconds
[2024-12-30T21:32:38.603+0000] {processor.py:186} INFO - Started process (PID=15421) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:32:38.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:32:38.613+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:32:38.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:32:38.673+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:32:38.751+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:32:38.750+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:32:38.794+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:32:38.794+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:32:38.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.248 seconds
[2024-12-30T21:33:09.074+0000] {processor.py:186} INFO - Started process (PID=15447) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:33:09.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:33:09.087+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:33:09.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:33:09.155+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:33:09.231+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:33:09.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:33:09.294+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:33:09.293+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:33:09.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.291 seconds
[2024-12-30T21:33:39.942+0000] {processor.py:186} INFO - Started process (PID=15479) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:33:39.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:33:39.948+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:33:39.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:33:40.031+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:33:40.143+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:33:40.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:33:40.179+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:33:40.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:33:40.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.277 seconds
[2024-12-30T21:34:10.346+0000] {processor.py:186} INFO - Started process (PID=15505) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:34:10.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:34:10.350+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:34:10.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:34:10.370+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:34:10.399+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:34:10.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:34:10.423+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:34:10.423+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:34:10.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2024-12-30T21:34:41.084+0000] {processor.py:186} INFO - Started process (PID=15530) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:34:41.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:34:41.094+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:34:41.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:34:41.164+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:34:41.253+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:34:41.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:34:41.308+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:34:41.307+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:34:41.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.383 seconds
[2024-12-30T21:35:11.991+0000] {processor.py:186} INFO - Started process (PID=15556) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:35:11.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:35:12.001+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:35:12.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:35:12.040+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:35:12.074+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:35:12.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:35:12.104+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:35:12.104+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:35:12.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.156 seconds
[2024-12-30T21:35:42.633+0000] {processor.py:186} INFO - Started process (PID=15582) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:35:42.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:35:42.645+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:35:42.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:35:42.704+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:35:42.757+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:35:42.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:35:42.800+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:35:42.800+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:35:42.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.225 seconds
[2024-12-30T21:36:13.911+0000] {processor.py:186} INFO - Started process (PID=15609) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:36:13.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:36:13.921+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:36:13.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:36:13.990+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:36:14.068+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:36:14.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:36:14.109+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:36:14.108+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:36:14.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.250 seconds
[2024-12-30T21:36:44.591+0000] {processor.py:186} INFO - Started process (PID=15636) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:36:44.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:36:44.606+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:36:44.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:36:44.700+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:36:44.834+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:36:44.833+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:36:44.891+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:36:44.891+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:36:44.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.354 seconds
[2024-12-30T21:37:15.512+0000] {processor.py:186} INFO - Started process (PID=15665) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:37:15.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:37:15.517+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:37:15.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:37:15.544+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:37:15.627+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:37:15.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:37:15.740+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:37:15.740+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:37:15.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.342 seconds
[2024-12-30T21:37:46.135+0000] {processor.py:186} INFO - Started process (PID=15692) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:37:46.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:37:46.142+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:37:46.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:37:46.218+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:37:46.310+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:37:46.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:37:46.420+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:37:46.419+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:37:46.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.315 seconds
[2024-12-30T21:38:16.918+0000] {processor.py:186} INFO - Started process (PID=15718) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:38:16.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:38:16.923+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:38:16.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:38:16.981+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:38:17.013+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:38:17.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:38:17.086+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:38:17.086+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:38:17.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.202 seconds
[2024-12-30T21:38:47.395+0000] {processor.py:186} INFO - Started process (PID=15745) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:38:47.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:38:47.452+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:38:47.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:38:47.554+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:38:47.590+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:38:47.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:38:47.852+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:38:47.852+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:38:48.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.676 seconds
[2024-12-30T21:39:18.509+0000] {processor.py:186} INFO - Started process (PID=15772) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:39:18.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:39:18.516+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:39:18.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:39:18.554+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:39:18.843+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:39:18.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:39:18.987+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:39:18.986+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:39:19.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.555 seconds
[2024-12-30T21:39:49.677+0000] {processor.py:186} INFO - Started process (PID=15798) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:39:49.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:39:49.688+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:39:49.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:39:49.774+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:39:49.952+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:39:49.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:39:49.982+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:39:49.982+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:39:50.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.415 seconds
[2024-12-30T21:40:20.515+0000] {processor.py:186} INFO - Started process (PID=15824) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:40:20.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:40:20.520+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:40:20.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:40:20.546+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:40:20.574+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:40:20.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:40:20.629+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:40:20.629+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:40:20.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.147 seconds
[2024-12-30T21:40:51.392+0000] {processor.py:186} INFO - Started process (PID=15849) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:40:51.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:40:51.402+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:40:51.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:40:51.484+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:40:51.601+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:40:51.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:40:51.728+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:40:51.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:40:51.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.489 seconds
[2024-12-30T21:41:22.378+0000] {processor.py:186} INFO - Started process (PID=15875) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:41:22.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:41:22.390+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:41:22.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:41:22.457+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:41:22.656+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:41:22.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:41:22.858+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:41:22.858+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:41:22.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.615 seconds
[2024-12-30T21:41:53.263+0000] {processor.py:186} INFO - Started process (PID=15901) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:41:53.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:41:53.274+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:41:53.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:41:53.350+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:41:53.512+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:41:53.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:41:53.633+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:41:53.632+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:41:53.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.498 seconds
[2024-12-30T21:42:24.187+0000] {processor.py:186} INFO - Started process (PID=15927) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:42:24.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:42:24.200+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:42:24.199+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:42:24.397+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:42:24.606+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:42:24.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:42:24.701+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:42:24.701+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:42:24.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.691 seconds
[2024-12-30T21:42:55.409+0000] {processor.py:186} INFO - Started process (PID=15953) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:42:55.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:42:55.413+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:42:55.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:42:55.435+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:42:55.489+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:42:55.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:42:55.569+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:42:55.568+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:42:55.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.190 seconds
[2024-12-30T21:43:25.930+0000] {processor.py:186} INFO - Started process (PID=15979) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:43:25.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:43:25.940+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:43:25.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:43:26.034+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:43:26.132+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:43:26.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:43:26.185+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:43:26.185+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:43:26.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.369 seconds
[2024-12-30T21:43:57.101+0000] {processor.py:186} INFO - Started process (PID=16006) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:43:57.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:43:57.107+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:43:57.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:43:57.160+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:43:57.236+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:43:57.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:43:57.280+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:43:57.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:43:57.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.280 seconds
[2024-12-30T21:44:27.633+0000] {processor.py:186} INFO - Started process (PID=16032) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:44:27.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:44:27.638+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:44:27.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:44:27.667+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:44:27.724+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:44:27.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:44:27.755+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:44:27.755+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:44:27.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.231 seconds
[2024-12-30T21:44:58.363+0000] {processor.py:186} INFO - Started process (PID=16058) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:44:58.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:44:58.374+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:44:58.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:44:58.476+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:44:58.757+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:44:58.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:44:58.872+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:44:58.871+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:44:59.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.823 seconds
[2024-12-30T21:45:30.101+0000] {processor.py:186} INFO - Started process (PID=16091) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:45:30.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:45:30.113+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:45:30.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:45:30.216+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:45:30.377+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:45:30.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:45:30.573+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:45:30.573+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:45:30.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.604 seconds
[2024-12-30T21:46:01.072+0000] {processor.py:186} INFO - Started process (PID=16117) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:46:01.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:46:01.111+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:46:01.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:46:01.198+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:46:01.481+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:46:01.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:46:01.601+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:46:01.600+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:46:01.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.692 seconds
[2024-12-30T21:46:32.207+0000] {processor.py:186} INFO - Started process (PID=16143) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:46:32.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:46:32.218+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:46:32.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:46:32.306+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:46:32.429+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:46:32.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:46:32.607+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:46:32.606+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:46:32.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.537 seconds
[2024-12-30T21:47:03.202+0000] {processor.py:186} INFO - Started process (PID=16169) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:47:03.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:47:03.206+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:47:03.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:47:03.230+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:47:03.258+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:47:03.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:47:03.280+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:47:03.280+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:47:03.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.180 seconds
[2024-12-30T21:47:33.639+0000] {processor.py:186} INFO - Started process (PID=16196) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:47:33.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:47:33.646+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:47:33.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:47:33.698+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:47:33.901+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:47:33.900+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:47:34.015+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:47:34.015+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:47:34.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.493 seconds
[2024-12-30T21:48:04.676+0000] {processor.py:186} INFO - Started process (PID=16222) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:48:04.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:48:04.682+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:48:04.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:48:04.747+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:48:04.788+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:48:04.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:48:04.852+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:48:04.852+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:48:04.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.219 seconds
[2024-12-30T21:48:35.250+0000] {processor.py:186} INFO - Started process (PID=16248) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:48:35.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:48:35.290+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:48:35.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:48:35.384+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:48:35.511+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:48:35.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:48:35.718+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:48:35.717+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:48:35.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.660 seconds
[2024-12-30T21:49:06.547+0000] {processor.py:186} INFO - Started process (PID=16274) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:49:06.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:49:06.573+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:49:06.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:49:06.664+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:49:06.851+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:49:06.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:49:06.961+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:49:06.960+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:49:07.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.512 seconds
[2024-12-30T21:49:37.576+0000] {processor.py:186} INFO - Started process (PID=16300) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:49:37.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:49:37.581+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:49:37.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:49:37.604+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:49:37.772+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:49:37.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:49:37.886+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:49:37.886+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:49:37.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.374 seconds
[2024-12-30T21:50:08.129+0000] {processor.py:186} INFO - Started process (PID=16326) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:50:08.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:50:08.144+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:50:08.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:50:08.261+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:50:08.455+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:50:08.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:50:08.567+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:50:08.567+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:50:08.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.608 seconds
[2024-12-30T21:50:39.341+0000] {processor.py:186} INFO - Started process (PID=16351) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:50:39.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:50:39.347+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:50:39.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:50:39.395+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:50:39.482+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:50:39.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:50:39.556+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:50:39.556+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:50:39.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.297 seconds
[2024-12-30T21:51:09.805+0000] {processor.py:186} INFO - Started process (PID=16377) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:51:09.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:51:09.814+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:51:09.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:51:09.857+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:51:09.996+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:51:09.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:51:10.036+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:51:10.036+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:51:10.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.349 seconds
[2024-12-30T21:51:40.636+0000] {processor.py:186} INFO - Started process (PID=16403) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:51:40.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:51:40.670+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:51:40.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:51:40.785+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:51:40.894+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:51:40.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:51:41.021+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:51:41.020+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:51:41.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.508 seconds
[2024-12-30T21:52:11.863+0000] {processor.py:186} INFO - Started process (PID=16429) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:52:11.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:52:11.874+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:52:11.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:52:11.954+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:52:12.119+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:52:12.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:52:12.255+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:52:12.255+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:52:12.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.527 seconds
[2024-12-30T21:52:42.740+0000] {processor.py:186} INFO - Started process (PID=16455) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:52:42.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:52:42.752+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:52:42.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:52:42.852+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:52:42.931+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:52:42.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:52:42.964+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:52:42.964+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:52:43.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.355 seconds
[2024-12-30T21:53:13.432+0000] {processor.py:186} INFO - Started process (PID=16482) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:53:13.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:53:13.439+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:53:13.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:53:13.503+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:53:13.604+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:53:13.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:53:13.776+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:53:13.776+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:53:13.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.397 seconds
[2024-12-30T21:53:44.032+0000] {processor.py:186} INFO - Started process (PID=16508) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:53:44.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:53:44.041+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:53:44.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:53:44.090+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:53:44.240+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:53:44.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:53:44.369+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:53:44.368+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:53:44.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.449 seconds
[2024-12-30T21:54:14.777+0000] {processor.py:186} INFO - Started process (PID=16534) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:54:14.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:54:14.785+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:54:14.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:54:14.881+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:54:14.986+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:54:14.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:54:15.072+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:54:15.071+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:54:15.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.400 seconds
[2024-12-30T21:54:45.839+0000] {processor.py:186} INFO - Started process (PID=16560) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:54:45.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:54:45.851+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:54:45.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:54:45.947+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:54:46.076+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:54:46.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:54:46.277+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:54:46.277+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:54:46.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.702 seconds
[2024-12-30T21:55:17.119+0000] {processor.py:186} INFO - Started process (PID=16586) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:55:17.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:55:17.123+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:55:17.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:55:17.152+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:55:17.238+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:55:17.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:55:17.271+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:55:17.271+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:55:17.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.265 seconds
[2024-12-30T21:55:47.720+0000] {processor.py:186} INFO - Started process (PID=16612) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:55:47.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:55:47.728+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:55:47.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:55:47.818+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:55:47.853+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:55:47.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:55:47.979+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:55:47.979+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:55:48.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.498 seconds
[2024-12-30T21:56:18.611+0000] {processor.py:186} INFO - Started process (PID=16644) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:56:18.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:56:18.622+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:56:18.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:56:18.671+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:56:18.728+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:56:18.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:56:18.803+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:56:18.803+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:56:18.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.235 seconds
[2024-12-30T21:56:49.107+0000] {processor.py:186} INFO - Started process (PID=16670) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:56:49.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:56:49.116+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:56:49.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:56:49.219+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:56:49.390+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:56:49.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:56:49.604+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:56:49.603+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:56:49.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.684 seconds
[2024-12-30T21:57:20.301+0000] {processor.py:186} INFO - Started process (PID=16696) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:57:20.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:57:20.312+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:57:20.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:57:20.406+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:57:20.577+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:57:20.576+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:57:20.687+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:57:20.687+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:57:20.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.438 seconds
[2024-12-30T21:57:51.264+0000] {processor.py:186} INFO - Started process (PID=16722) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:57:51.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:57:51.270+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:57:51.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:57:51.317+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:57:51.419+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:57:51.419+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:57:51.466+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:57:51.465+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:57:51.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.303 seconds
[2024-12-30T21:58:21.688+0000] {processor.py:186} INFO - Started process (PID=16748) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:58:21.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:58:21.698+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:58:21.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:58:21.795+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:58:21.924+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:58:21.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:58:22.096+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:58:22.095+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:58:22.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.517 seconds
[2024-12-30T21:58:52.496+0000] {processor.py:186} INFO - Started process (PID=16774) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:58:52.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:58:52.527+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:58:52.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:58:52.582+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:58:52.662+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:58:52.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:58:52.769+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:58:52.769+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:58:52.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.388 seconds
[2024-12-30T21:59:23.086+0000] {processor.py:186} INFO - Started process (PID=16800) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:59:23.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:59:23.096+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:59:23.096+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:59:23.198+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:59:23.472+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:59:23.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:59:23.678+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:59:23.677+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:59:23.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.725 seconds
[2024-12-30T21:59:54.319+0000] {processor.py:186} INFO - Started process (PID=16826) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:59:54.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T21:59:54.326+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:59:54.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:59:54.431+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T21:59:54.704+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:59:54.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T21:59:54.936+0000] {logging_mixin.py:190} INFO - [2024-12-30T21:59:54.935+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 20:00:00+00:00, run_after=2024-12-30 21:00:00+00:00
[2024-12-30T21:59:55.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.728 seconds
[2024-12-30T22:00:25.866+0000] {processor.py:186} INFO - Started process (PID=16852) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:00:25.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:00:25.871+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:00:25.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:00:25.899+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:00:25.974+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:00:25.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:00:26.045+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:00:26.044+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:00:26.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.215 seconds
[2024-12-30T22:00:56.473+0000] {processor.py:186} INFO - Started process (PID=16877) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:00:56.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:00:56.478+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:00:56.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:00:56.504+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:00:56.574+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:00:56.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:00:56.643+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:00:56.643+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:00:56.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.206 seconds
[2024-12-30T22:01:27.131+0000] {processor.py:186} INFO - Started process (PID=16903) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:01:27.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:01:27.135+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:01:27.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:01:27.162+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:01:27.232+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:01:27.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:01:27.264+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:01:27.264+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:01:27.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.211 seconds
[2024-12-30T22:01:57.743+0000] {processor.py:186} INFO - Started process (PID=16928) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:01:57.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:01:57.747+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:01:57.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:01:57.769+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:01:57.829+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:01:57.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:01:58.023+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:01:58.022+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:01:58.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.390 seconds
[2024-12-30T22:02:28.644+0000] {processor.py:186} INFO - Started process (PID=16954) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:02:28.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:02:28.649+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:02:28.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:02:28.678+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:02:28.712+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:02:28.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:02:28.789+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:02:28.789+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:02:28.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.187 seconds
[2024-12-30T22:02:59.104+0000] {processor.py:186} INFO - Started process (PID=16980) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:02:59.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:02:59.109+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:02:59.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:02:59.134+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:02:59.168+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:02:59.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:02:59.241+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:02:59.241+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:02:59.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.172 seconds
[2024-12-30T22:03:29.831+0000] {processor.py:186} INFO - Started process (PID=17007) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:03:29.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:03:29.836+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:03:29.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:03:29.863+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:03:29.913+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:03:29.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:03:29.939+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:03:29.939+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:03:29.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2024-12-30T22:04:00.281+0000] {processor.py:186} INFO - Started process (PID=17033) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:04:00.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:04:00.285+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:04:00.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:04:00.310+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:04:00.377+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:04:00.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:04:00.411+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:04:00.411+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:04:00.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.206 seconds
[2024-12-30T22:04:30.912+0000] {processor.py:186} INFO - Started process (PID=17059) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:04:30.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:04:30.916+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:04:30.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:04:30.939+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:04:30.982+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:04:30.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:04:31.052+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:04:31.052+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:04:31.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.167 seconds
[2024-12-30T22:05:01.555+0000] {processor.py:186} INFO - Started process (PID=17085) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:05:01.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:05:01.561+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:05:01.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:05:01.632+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:05:01.718+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:05:01.717+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:05:01.754+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:05:01.754+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:05:01.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.270 seconds
[2024-12-30T22:05:32.196+0000] {processor.py:186} INFO - Started process (PID=17111) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:05:32.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:05:32.201+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:05:32.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:05:32.228+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:05:32.304+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:05:32.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:05:32.333+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:05:32.333+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:05:32.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.218 seconds
[2024-12-30T22:06:02.746+0000] {processor.py:186} INFO - Started process (PID=17138) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:06:02.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:06:02.757+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:06:02.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:06:02.871+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:06:02.976+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:06:02.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:06:03.051+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:06:03.050+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:06:03.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.346 seconds
[2024-12-30T22:06:33.570+0000] {processor.py:186} INFO - Started process (PID=17164) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:06:33.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:06:33.574+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:06:33.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:06:33.599+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:06:33.657+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:06:33.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:06:33.728+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:06:33.728+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:06:33.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.186 seconds
[2024-12-30T22:07:04.374+0000] {processor.py:186} INFO - Started process (PID=17190) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:07:04.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:07:04.377+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:07:04.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:07:04.426+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:07:04.511+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:07:04.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:07:04.548+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:07:04.547+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:07:04.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.282 seconds
[2024-12-30T22:07:34.981+0000] {processor.py:186} INFO - Started process (PID=17215) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:07:34.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:07:34.993+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:07:34.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:07:35.081+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:07:35.269+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:07:35.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:07:35.297+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:07:35.297+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:07:35.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.389 seconds
[2024-12-30T22:08:05.573+0000] {processor.py:186} INFO - Started process (PID=17243) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:08:05.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:08:05.578+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:08:05.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:08:05.659+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:08:05.741+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:08:05.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:08:05.865+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:08:05.865+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:08:05.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.391 seconds
[2024-12-30T22:08:36.627+0000] {processor.py:186} INFO - Started process (PID=17269) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:08:36.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:08:36.639+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:08:36.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:08:36.728+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:08:36.932+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:08:36.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:08:37.053+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:08:37.053+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:08:37.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.577 seconds
[2024-12-30T22:09:07.766+0000] {processor.py:186} INFO - Started process (PID=17296) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:09:07.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:09:07.771+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:09:07.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:09:07.799+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:09:07.879+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:09:07.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:09:08.004+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:09:08.004+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:09:08.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.397 seconds
[2024-12-30T22:09:38.611+0000] {processor.py:186} INFO - Started process (PID=17326) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:09:38.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:09:38.622+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:09:38.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:09:38.717+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:09:38.909+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:09:38.909+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:09:39.022+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:09:39.021+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:09:39.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.498 seconds
[2024-12-30T22:10:09.527+0000] {processor.py:186} INFO - Started process (PID=17353) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:10:09.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:10:09.534+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:10:09.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:10:09.572+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:10:09.697+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:10:09.697+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:10:09.806+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:10:09.805+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:10:09.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.382 seconds
[2024-12-30T22:10:40.431+0000] {processor.py:186} INFO - Started process (PID=17379) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:10:40.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:10:40.438+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:10:40.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:10:40.483+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:10:40.620+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:10:40.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:10:40.731+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:10:40.731+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:10:40.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.408 seconds
[2024-12-30T22:11:11.010+0000] {processor.py:186} INFO - Started process (PID=17405) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:11:11.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-30T22:11:11.017+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:11:11.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:11:11.068+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-30T22:11:11.158+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:11:11.158+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-30T22:11:11.235+0000] {logging_mixin.py:190} INFO - [2024-12-30T22:11:11.234+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-30 21:00:00+00:00, run_after=2024-12-30 22:00:00+00:00
[2024-12-30T22:11:11.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.351 seconds
