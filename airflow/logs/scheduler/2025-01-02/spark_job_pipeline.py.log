[2025-01-02T15:47:30.753+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:47:30.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:47:30.760+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:47:30.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:47:30.957+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:47:32.655+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:47:32.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:47:32.851+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:47:32.851+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:47:32.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 2.296 seconds
[2025-01-02T15:48:03.022+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:48:03.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:48:03.025+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:48:03.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:48:03.170+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:48:03.197+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:48:03.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:48:03.273+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:48:03.273+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:48:03.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.283 seconds
[2025-01-02T15:48:34.059+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:48:34.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:48:34.095+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:48:34.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:48:34.116+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:48:34.207+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:48:34.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:48:34.231+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:48:34.231+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:48:34.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.258 seconds
[2025-01-02T15:49:04.346+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:49:04.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:49:04.349+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:49:04.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:49:04.366+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:49:04.392+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:49:04.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:49:04.420+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:49:04.419+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:49:04.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2025-01-02T15:49:35.187+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:49:35.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:49:35.190+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:49:35.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:49:35.207+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:49:35.230+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:49:35.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:49:35.254+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:49:35.254+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:49:35.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.090 seconds
[2025-01-02T15:50:06.078+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:50:06.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:50:06.080+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:50:06.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:50:06.096+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:50:06.118+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:50:06.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:50:06.137+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:50:06.137+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:50:06.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.083 seconds
[2025-01-02T15:50:37.099+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:50:37.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:50:37.102+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:50:37.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:50:37.119+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:50:37.142+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:50:37.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:50:37.161+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:50:37.161+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:50:37.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.087 seconds
[2025-01-02T15:51:07.287+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:51:07.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:51:07.291+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:51:07.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:51:07.310+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:51:07.361+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:51:07.361+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:51:07.383+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:51:07.382+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:51:07.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T15:51:40.132+0000] {processor.py:186} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:51:40.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:51:40.135+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:51:40.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:51:40.149+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:51:40.174+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:51:40.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:51:40.192+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:51:40.192+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:51:40.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.086 seconds
[2025-01-02T15:52:12.955+0000] {processor.py:186} INFO - Started process (PID=403) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:52:12.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:52:12.957+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:52:12.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:52:12.972+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:52:12.994+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:52:12.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:52:13.014+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:52:13.013+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:52:13.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.081 seconds
[2025-01-02T15:52:45.072+0000] {processor.py:186} INFO - Started process (PID=423) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:52:45.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:52:45.075+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:52:45.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:52:45.090+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:52:45.117+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:52:45.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:52:45.136+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:52:45.136+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:52:45.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.088 seconds
[2025-01-02T15:53:18.009+0000] {processor.py:186} INFO - Started process (PID=450) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:53:18.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:53:18.012+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:53:18.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:53:18.028+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:53:18.105+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:53:18.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:53:18.129+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:53:18.129+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:53:18.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.209 seconds
[2025-01-02T15:53:51.039+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:53:51.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:53:51.042+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:53:51.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:53:51.058+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:53:51.083+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:53:51.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:53:51.175+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:53:51.175+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:53:51.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.238 seconds
[2025-01-02T15:54:23.264+0000] {processor.py:186} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:54:23.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:54:23.267+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:54:23.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:54:23.314+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:54:23.339+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:54:23.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:54:23.420+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:54:23.419+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:54:23.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.181 seconds
[2025-01-02T15:54:56.408+0000] {processor.py:186} INFO - Started process (PID=529) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:54:56.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:54:56.410+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:54:56.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:54:56.425+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:54:56.445+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:54:56.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:54:56.464+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:54:56.463+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:54:56.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2025-01-02T15:55:28.579+0000] {processor.py:186} INFO - Started process (PID=555) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:55:28.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:55:28.583+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:55:28.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:55:28.598+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:55:28.620+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:55:28.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:55:28.643+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:55:28.643+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:55:28.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T15:56:01.730+0000] {processor.py:186} INFO - Started process (PID=581) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:56:01.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:56:01.732+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:56:01.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:56:01.746+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:56:01.767+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:56:01.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:56:01.807+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:56:01.807+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:56:01.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2025-01-02T15:56:34.712+0000] {processor.py:186} INFO - Started process (PID=607) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:56:34.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:56:34.714+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:56:34.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:56:34.731+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:56:34.776+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:56:34.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:56:34.800+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:56:34.800+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:56:34.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.177 seconds
[2025-01-02T15:57:06.780+0000] {processor.py:186} INFO - Started process (PID=633) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:57:06.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:57:06.828+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:57:06.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:57:06.854+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:57:06.930+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:57:06.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:57:06.959+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:57:06.959+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:57:06.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.208 seconds
[2025-01-02T15:57:39.719+0000] {processor.py:186} INFO - Started process (PID=659) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:57:39.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:57:39.722+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:57:39.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:57:39.743+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:57:39.831+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:57:39.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:57:39.933+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:57:39.933+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:57:39.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.243 seconds
[2025-01-02T15:58:12.725+0000] {processor.py:186} INFO - Started process (PID=685) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:58:12.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:58:12.727+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:58:12.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:58:12.744+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:58:12.786+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:58:12.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:58:12.804+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:58:12.804+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:58:12.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2025-01-02T15:58:45.657+0000] {processor.py:186} INFO - Started process (PID=710) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:58:45.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:58:45.669+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:58:45.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:58:45.752+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:58:45.989+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:58:45.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:58:46.092+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:58:46.092+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:58:46.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.496 seconds
[2025-01-02T15:59:17.728+0000] {processor.py:186} INFO - Started process (PID=735) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:59:17.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:59:17.737+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:59:17.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:59:17.792+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:59:17.867+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:59:17.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:59:18.006+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:59:18.006+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:59:18.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.322 seconds
[2025-01-02T15:59:50.989+0000] {processor.py:186} INFO - Started process (PID=761) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:59:50.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T15:59:50.991+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:59:50.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:59:51.006+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T15:59:51.061+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:59:51.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T15:59:51.082+0000] {logging_mixin.py:190} INFO - [2025-01-02T15:59:51.081+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 14:00:00+00:00, run_after=2025-01-02 15:00:00+00:00
[2025-01-02T15:59:51.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2025-01-02T16:00:23.077+0000] {processor.py:186} INFO - Started process (PID=786) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:00:23.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:00:23.080+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:00:23.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:00:23.095+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:00:23.162+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:00:23.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:00:23.183+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:00:23.183+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:00:23.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2025-01-02T16:00:56.034+0000] {processor.py:186} INFO - Started process (PID=812) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:00:56.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:00:56.038+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:00:56.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:00:56.069+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:00:56.145+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:00:56.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:00:56.234+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:00:56.234+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:00:56.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.233 seconds
[2025-01-02T16:01:29.111+0000] {processor.py:186} INFO - Started process (PID=838) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:01:29.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:01:29.113+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:01:29.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:01:29.133+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:01:29.158+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:01:29.158+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:01:29.186+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:01:29.186+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:01:29.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.144 seconds
[2025-01-02T16:02:01.162+0000] {processor.py:186} INFO - Started process (PID=864) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:02:01.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:02:01.164+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:02:01.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:02:01.181+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:02:01.208+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:02:01.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:02:01.230+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:02:01.230+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:02:01.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2025-01-02T16:02:34.253+0000] {processor.py:186} INFO - Started process (PID=890) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:02:34.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:02:34.255+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:02:34.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:02:34.270+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:02:34.314+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:02:34.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:02:34.333+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:02:34.333+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:02:34.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2025-01-02T16:03:07.137+0000] {processor.py:186} INFO - Started process (PID=916) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:03:07.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:03:07.140+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:03:07.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:03:07.161+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:03:07.194+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:03:07.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:03:07.269+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:03:07.269+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:03:07.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.170 seconds
[2025-01-02T16:03:39.266+0000] {processor.py:186} INFO - Started process (PID=942) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:03:39.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:03:39.269+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:03:39.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:03:39.284+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:03:39.307+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:03:39.307+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:03:39.367+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:03:39.366+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:03:39.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2025-01-02T16:04:12.322+0000] {processor.py:186} INFO - Started process (PID=968) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:04:12.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:04:12.324+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:04:12.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:04:12.339+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:04:12.361+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:04:12.361+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:04:12.381+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:04:12.381+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:04:12.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T16:04:45.465+0000] {processor.py:186} INFO - Started process (PID=994) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:04:45.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:04:45.468+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:04:45.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:04:45.496+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:04:45.532+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:04:45.531+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:04:45.557+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:04:45.557+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:04:45.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.169 seconds
[2025-01-02T16:05:17.566+0000] {processor.py:186} INFO - Started process (PID=1019) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:05:17.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:05:17.573+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:05:17.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:05:17.591+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:05:17.614+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:05:17.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:05:17.636+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:05:17.636+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:05:17.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.137 seconds
[2025-01-02T16:05:50.574+0000] {processor.py:186} INFO - Started process (PID=1045) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:05:50.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:05:50.576+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:05:50.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:05:50.594+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:05:50.642+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:05:50.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:05:50.664+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:05:50.664+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:05:50.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.117 seconds
[2025-01-02T16:06:23.734+0000] {processor.py:186} INFO - Started process (PID=1071) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:06:23.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:06:23.737+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:06:23.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:06:23.752+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:06:23.776+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:06:23.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:06:23.796+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:06:23.796+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:06:23.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.089 seconds
[2025-01-02T16:06:55.950+0000] {processor.py:186} INFO - Started process (PID=1097) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:06:55.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:06:55.953+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:06:55.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:06:55.993+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:06:56.017+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:06:56.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:06:56.036+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:06:56.036+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:06:56.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.159 seconds
[2025-01-02T16:07:28.926+0000] {processor.py:186} INFO - Started process (PID=1123) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:07:28.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:07:28.929+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:07:28.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:07:28.945+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:07:28.994+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:07:28.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:07:29.026+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:07:29.026+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:07:29.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.177 seconds
[2025-01-02T16:08:02.092+0000] {processor.py:186} INFO - Started process (PID=1149) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:08:02.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:08:02.095+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:08:02.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:08:02.112+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:08:02.136+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:08:02.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:08:02.185+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:08:02.185+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:08:02.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.184 seconds
[2025-01-02T16:08:34.053+0000] {processor.py:186} INFO - Started process (PID=1175) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:08:34.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:08:34.091+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:08:34.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:08:34.110+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:08:34.133+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:08:34.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:08:34.199+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:08:34.199+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:08:34.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.171 seconds
[2025-01-02T16:09:07.031+0000] {processor.py:186} INFO - Started process (PID=1201) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:09:07.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:09:07.034+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:09:07.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:09:07.049+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:09:07.071+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:09:07.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:09:07.134+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:09:07.133+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:09:07.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T16:09:40.017+0000] {processor.py:186} INFO - Started process (PID=1227) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:09:40.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:09:40.019+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:09:40.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:09:40.038+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:09:40.096+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:09:40.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:09:40.117+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:09:40.117+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:09:40.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T16:10:12.130+0000] {processor.py:186} INFO - Started process (PID=1254) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:10:12.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:10:12.134+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:10:12.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:10:12.206+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:10:12.234+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:10:12.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:10:12.319+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:10:12.319+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:10:12.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.213 seconds
[2025-01-02T16:10:45.267+0000] {processor.py:186} INFO - Started process (PID=1279) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:10:45.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:10:45.269+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:10:45.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:10:45.284+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:10:45.306+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:10:45.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:10:45.365+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:10:45.364+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:10:45.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.120 seconds
[2025-01-02T16:11:18.507+0000] {processor.py:186} INFO - Started process (PID=1304) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:11:18.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:11:18.509+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:11:18.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:11:18.524+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:11:18.578+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:11:18.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:11:18.601+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:11:18.601+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:11:18.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2025-01-02T16:11:50.336+0000] {processor.py:186} INFO - Started process (PID=1330) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:11:50.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:11:50.339+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:11:50.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:11:50.360+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:11:50.382+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:11:50.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:11:50.463+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:11:50.463+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:11:50.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.205 seconds
[2025-01-02T16:12:23.464+0000] {processor.py:186} INFO - Started process (PID=1356) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:12:23.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:12:23.466+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:12:23.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:12:23.482+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:12:23.505+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:12:23.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:12:23.567+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:12:23.567+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:12:23.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T16:12:55.586+0000] {processor.py:186} INFO - Started process (PID=1381) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:12:55.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:12:55.588+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:12:55.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:12:55.604+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:12:55.628+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:12:55.628+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:12:55.706+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:12:55.706+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:12:55.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.198 seconds
[2025-01-02T16:13:28.806+0000] {processor.py:186} INFO - Started process (PID=1408) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:13:28.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:13:28.810+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:13:28.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:13:28.833+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:13:28.906+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:13:28.905+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:13:28.937+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:13:28.937+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:13:29.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.217 seconds
[2025-01-02T16:14:01.973+0000] {processor.py:186} INFO - Started process (PID=1434) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:14:01.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:14:01.985+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:14:01.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:14:02.009+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:14:02.096+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:14:02.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:14:02.187+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:14:02.187+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:14:02.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.249 seconds
[2025-01-02T16:16:07.598+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:16:07.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:16:07.688+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:16:07.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:16:08.005+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:16:08.297+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:16:08.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:16:08.496+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:16:08.495+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:16:08.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.183 seconds
[2025-01-02T16:16:39.038+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:16:39.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:16:39.042+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:16:39.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:16:39.066+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:16:39.097+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:16:39.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:16:39.120+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:16:39.120+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:16:39.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2025-01-02T16:17:09.306+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:17:09.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:17:09.311+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:17:09.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:17:09.562+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:17:09.618+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:17:09.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:17:09.711+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:17:09.711+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:17:09.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.488 seconds
[2025-01-02T16:17:40.490+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:17:40.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:17:40.496+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:17:40.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:17:40.528+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:17:40.572+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:17:40.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:17:40.621+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:17:40.621+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:17:40.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.168 seconds
[2025-01-02T16:18:10.750+0000] {processor.py:186} INFO - Started process (PID=277) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:18:10.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:18:10.754+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:18:10.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:18:10.775+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:18:10.808+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:18:10.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:18:10.836+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:18:10.835+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:18:10.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2025-01-02T16:18:40.912+0000] {processor.py:186} INFO - Started process (PID=303) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:18:40.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:18:40.915+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:18:40.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:18:40.933+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:18:40.960+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:18:40.960+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:18:40.983+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:18:40.983+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:18:41.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.142 seconds
[2025-01-02T16:19:11.172+0000] {processor.py:186} INFO - Started process (PID=329) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:19:11.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:19:11.174+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:19:11.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:19:11.189+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:19:11.211+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:19:11.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:19:11.231+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:19:11.231+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:19:11.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.082 seconds
[2025-01-02T16:19:41.359+0000] {processor.py:186} INFO - Started process (PID=350) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:19:41.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:19:41.362+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:19:41.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:19:41.377+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:19:41.430+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:19:41.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:19:41.450+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:19:41.450+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:19:41.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2025-01-02T16:20:12.415+0000] {processor.py:186} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:20:12.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:20:12.417+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:20:12.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:20:12.433+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:20:12.454+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:20:12.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:20:12.506+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:20:12.506+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:20:12.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2025-01-02T16:20:42.666+0000] {processor.py:186} INFO - Started process (PID=397) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:20:42.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:20:42.670+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:20:42.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:20:42.693+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:20:42.775+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:20:42.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:20:42.800+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:20:42.800+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:20:42.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.158 seconds
[2025-01-02T16:21:13.822+0000] {processor.py:186} INFO - Started process (PID=423) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:21:13.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:21:13.825+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:21:13.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:21:13.841+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:21:13.864+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:21:13.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:21:13.884+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:21:13.884+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:21:13.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2025-01-02T16:21:44.445+0000] {processor.py:186} INFO - Started process (PID=449) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:21:44.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:21:44.449+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:21:44.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:21:44.470+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:21:44.497+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:21:44.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:21:44.565+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:21:44.565+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:21:44.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.147 seconds
[2025-01-02T16:22:14.880+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:22:14.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:22:14.884+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:22:14.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:22:14.910+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:22:14.986+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:22:14.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:22:15.077+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:22:15.077+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:22:15.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.296 seconds
[2025-01-02T16:22:46.278+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:22:46.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:22:46.281+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:22:46.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:22:46.296+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:22:46.318+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:22:46.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:22:46.339+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:22:46.338+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:22:46.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.086 seconds
[2025-01-02T16:23:19.140+0000] {processor.py:186} INFO - Started process (PID=526) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:23:19.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:23:19.142+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:23:19.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:23:19.156+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:23:19.212+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:23:19.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:23:19.232+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:23:19.232+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:23:19.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.171 seconds
[2025-01-02T16:23:52.359+0000] {processor.py:186} INFO - Started process (PID=551) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:23:52.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:23:52.361+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:23:52.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:23:52.376+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:23:52.412+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:23:52.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:23:52.432+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:23:52.432+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:23:52.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2025-01-02T16:24:24.514+0000] {processor.py:186} INFO - Started process (PID=577) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:24:24.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:24:24.517+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:24:24.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:24:24.608+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:24:24.705+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:24:24.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:24:24.728+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:24:24.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:24:24.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.308 seconds
[2025-01-02T16:24:57.936+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:24:57.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:24:57.940+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:24:57.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:24:58.000+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:24:58.024+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:24:58.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:24:58.042+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:24:58.042+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:24:58.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.179 seconds
[2025-01-02T16:25:29.955+0000] {processor.py:186} INFO - Started process (PID=629) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:25:29.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:25:29.959+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:25:29.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:25:29.977+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:25:30.152+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:25:30.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:25:30.253+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:25:30.253+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:25:30.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.328 seconds
[2025-01-02T16:26:03.071+0000] {processor.py:186} INFO - Started process (PID=655) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:26:03.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:26:03.106+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:26:03.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:26:03.128+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:26:03.225+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:26:03.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:26:03.321+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:26:03.321+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:26:03.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.361 seconds
[2025-01-02T16:26:35.452+0000] {processor.py:186} INFO - Started process (PID=681) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:26:35.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:26:35.455+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:26:35.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:26:35.469+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:26:35.490+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:26:35.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:26:35.508+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:26:35.508+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:26:35.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.081 seconds
[2025-01-02T16:27:08.524+0000] {processor.py:186} INFO - Started process (PID=707) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:27:08.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:27:08.527+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:27:08.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:27:08.542+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:27:08.570+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:27:08.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:27:08.594+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:27:08.594+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:27:08.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.145 seconds
[2025-01-02T16:27:41.700+0000] {processor.py:186} INFO - Started process (PID=733) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:27:41.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:27:41.704+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:27:41.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:27:41.787+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:27:41.891+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:27:41.890+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:27:41.998+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:27:41.998+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:27:42.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.400 seconds
[2025-01-02T16:28:14.078+0000] {processor.py:186} INFO - Started process (PID=759) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:28:14.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:28:14.081+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:28:14.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:28:14.096+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:28:14.128+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:28:14.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:28:14.148+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:28:14.148+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:28:14.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2025-01-02T16:28:47.176+0000] {processor.py:186} INFO - Started process (PID=785) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:28:47.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:28:47.179+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:28:47.179+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:28:47.194+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:28:47.215+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:28:47.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:28:47.235+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:28:47.235+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:28:47.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T16:29:19.359+0000] {processor.py:186} INFO - Started process (PID=810) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:29:19.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:29:19.362+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:29:19.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:29:19.378+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:29:19.405+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:29:19.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:29:19.457+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:29:19.457+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:29:19.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.132 seconds
[2025-01-02T16:29:52.548+0000] {processor.py:186} INFO - Started process (PID=836) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:29:52.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:29:52.551+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:29:52.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:29:52.566+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:29:52.598+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:29:52.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:29:52.618+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:29:52.618+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:29:52.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2025-01-02T16:30:24.692+0000] {processor.py:186} INFO - Started process (PID=861) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:30:24.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:30:24.695+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:30:24.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:30:24.740+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:30:24.769+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:30:24.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:30:24.842+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:30:24.842+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:30:24.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.175 seconds
[2025-01-02T16:30:57.853+0000] {processor.py:186} INFO - Started process (PID=887) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:30:57.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:30:57.855+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:30:57.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:30:57.873+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:30:57.905+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:30:57.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:30:57.930+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:30:57.929+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:30:57.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2025-01-02T16:31:31.002+0000] {processor.py:186} INFO - Started process (PID=910) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:31:31.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:31:31.004+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:31:31.003+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:31:31.027+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:31:31.385+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:31:31.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:31:31.397+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:31:31.397+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_job_pipeline
[2025-01-02T16:31:31.407+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:31:31.407+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:31:31.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.436 seconds
[2025-01-02T16:33:09.550+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:33:09.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:33:09.634+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:33:09.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:33:09.682+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:33:09.850+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:33:09.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:33:09.950+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:33:09.950+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:33:10.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.507 seconds
[2025-01-02T16:33:42.294+0000] {processor.py:186} INFO - Started process (PID=164) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:33:42.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:33:42.297+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:33:42.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:33:42.314+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:33:42.338+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:33:42.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:33:42.359+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:33:42.359+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:33:42.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2025-01-02T16:34:14.549+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:34:14.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:34:14.553+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:34:14.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:34:14.566+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:34:14.590+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:34:14.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:34:14.642+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:34:14.642+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:34:14.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.222 seconds
[2025-01-02T16:34:47.721+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:34:47.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:34:47.725+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:34:47.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:34:47.742+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:34:47.763+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:34:47.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:34:47.834+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:34:47.834+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:34:47.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T16:35:19.888+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:35:19.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:35:19.892+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:35:19.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:35:19.978+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:35:20.083+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:35:20.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:35:20.180+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:35:20.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:35:20.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.386 seconds
[2025-01-02T16:35:53.358+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:35:53.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:35:53.361+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:35:53.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:35:53.449+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:35:53.548+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:35:53.548+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:35:53.567+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:35:53.567+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:35:53.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.283 seconds
[2025-01-02T16:36:25.671+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:36:25.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:36:25.674+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:36:25.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:36:25.755+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:36:25.855+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:36:25.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:36:25.950+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:36:25.950+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:36:25.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.311 seconds
[2025-01-02T16:36:59.078+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:36:59.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:36:59.081+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:36:59.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:36:59.162+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:36:59.254+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:36:59.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:36:59.279+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:36:59.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:36:59.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.298 seconds
[2025-01-02T16:37:31.082+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:37:31.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:37:31.085+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:37:31.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:37:31.100+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:37:31.122+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:37:31.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:37:31.152+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:37:31.151+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:37:31.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2025-01-02T16:38:04.132+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:38:04.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:38:04.135+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:38:04.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:38:04.150+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:38:04.209+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:38:04.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:38:04.233+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:38:04.233+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:38:04.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2025-01-02T16:38:37.250+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:38:37.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:38:37.253+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:38:37.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:38:37.269+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:38:37.295+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:38:37.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:38:37.317+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:38:37.316+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:38:37.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2025-01-02T16:39:09.485+0000] {processor.py:186} INFO - Started process (PID=421) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:39:09.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:39:09.490+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:39:09.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:39:09.508+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:39:09.580+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:39:09.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:39:09.606+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:39:09.605+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:39:09.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.211 seconds
[2025-01-02T16:39:42.461+0000] {processor.py:186} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:39:42.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:39:42.463+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:39:42.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:39:42.478+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:39:42.544+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:39:42.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:39:42.562+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:39:42.562+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:39:42.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.172 seconds
[2025-01-02T16:40:15.535+0000] {processor.py:186} INFO - Started process (PID=473) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:40:15.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:40:15.538+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:40:15.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:40:15.553+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:40:15.574+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:40:15.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:40:15.639+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:40:15.639+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:40:15.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T16:40:48.604+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:40:48.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:40:48.607+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:40:48.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:40:48.628+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:40:48.690+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:40:48.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:40:48.718+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:40:48.718+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:40:48.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.206 seconds
[2025-01-02T16:41:20.828+0000] {processor.py:186} INFO - Started process (PID=526) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:41:20.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:41:20.830+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:41:20.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:41:20.846+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:41:20.868+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:41:20.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:41:20.888+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:41:20.887+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:41:20.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.083 seconds
[2025-01-02T16:41:53.834+0000] {processor.py:186} INFO - Started process (PID=552) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:41:53.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:41:53.836+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:41:53.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:41:53.853+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:41:53.905+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:41:53.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:41:53.926+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:41:53.926+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:41:53.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.117 seconds
[2025-01-02T16:42:26.979+0000] {processor.py:186} INFO - Started process (PID=578) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:42:26.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:42:26.982+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:42:26.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:42:26.999+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:42:27.023+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:42:27.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:42:27.043+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:42:27.043+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:42:27.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2025-01-02T16:42:59.018+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:42:59.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:42:59.021+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:42:59.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:42:59.037+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:42:59.060+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:42:59.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:42:59.081+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:42:59.081+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:42:59.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2025-01-02T16:43:32.156+0000] {processor.py:186} INFO - Started process (PID=632) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:43:32.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:43:32.159+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:43:32.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:43:32.175+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:43:32.199+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:43:32.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:43:32.257+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:43:32.257+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:43:32.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T16:44:03.572+0000] {processor.py:186} INFO - Started process (PID=658) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:44:03.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:44:03.576+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:44:03.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:44:03.594+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:44:03.658+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:44:03.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:44:03.678+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:44:03.678+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:44:03.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.185 seconds
[2025-01-02T16:44:34.095+0000] {processor.py:186} INFO - Started process (PID=683) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:44:34.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:44:34.098+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:44:34.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:44:34.117+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:44:34.183+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:44:34.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:44:34.203+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:44:34.203+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:44:34.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.178 seconds
[2025-01-02T16:45:04.833+0000] {processor.py:186} INFO - Started process (PID=709) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:45:04.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:45:04.836+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:45:04.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:45:04.854+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:45:04.910+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:45:04.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:45:04.929+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:45:04.928+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:45:04.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.162 seconds
[2025-01-02T16:45:35.174+0000] {processor.py:186} INFO - Started process (PID=735) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:45:35.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:45:35.176+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:45:35.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:45:35.190+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:45:35.245+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:45:35.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:45:35.268+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:45:35.267+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:45:35.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2025-01-02T16:46:05.442+0000] {processor.py:186} INFO - Started process (PID=755) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:46:05.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:46:05.445+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:46:05.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:46:05.460+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:46:05.489+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:46:05.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:46:05.546+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:46:05.546+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:46:05.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T16:46:35.720+0000] {processor.py:186} INFO - Started process (PID=787) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:46:35.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:46:35.723+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:46:35.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:46:35.737+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:46:35.759+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:46:35.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:46:35.777+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:46:35.777+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:46:35.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.083 seconds
[2025-01-02T16:47:05.905+0000] {processor.py:186} INFO - Started process (PID=812) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:47:05.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:47:05.908+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:47:05.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:47:05.928+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:47:05.994+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:47:05.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:47:06.012+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:47:06.012+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:47:06.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T16:47:36.084+0000] {processor.py:186} INFO - Started process (PID=835) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:47:36.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:47:36.087+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:47:36.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:47:36.105+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:47:36.139+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:47:36.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:47:36.158+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:47:36.158+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:47:36.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.146 seconds
[2025-01-02T16:48:06.267+0000] {processor.py:186} INFO - Started process (PID=861) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:48:06.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:48:06.269+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:48:06.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:48:06.286+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:48:06.334+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:48:06.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:48:06.362+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:48:06.362+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:48:06.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.172 seconds
[2025-01-02T16:48:37.451+0000] {processor.py:186} INFO - Started process (PID=887) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:48:37.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:48:37.454+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:48:37.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:48:37.469+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:48:37.495+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:48:37.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:48:37.552+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:48:37.551+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:48:37.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2025-01-02T16:49:07.711+0000] {processor.py:186} INFO - Started process (PID=907) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:49:07.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:49:07.715+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:49:07.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:49:07.734+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:49:07.758+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:49:07.758+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:49:07.810+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:49:07.810+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:49:07.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T16:49:37.935+0000] {processor.py:186} INFO - Started process (PID=933) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:49:37.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:49:37.937+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:49:37.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:49:37.953+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:49:37.977+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:49:37.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:49:38.042+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:49:38.042+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:49:38.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2025-01-02T16:50:08.147+0000] {processor.py:186} INFO - Started process (PID=957) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:50:08.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:50:08.149+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:50:08.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:50:08.164+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:50:08.189+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:50:08.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:50:08.213+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:50:08.213+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:50:08.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2025-01-02T16:50:39.122+0000] {processor.py:186} INFO - Started process (PID=983) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:50:39.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:50:39.124+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:50:39.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:50:39.140+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:50:39.205+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:50:39.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:50:39.233+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:50:39.233+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:50:39.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T16:51:09.666+0000] {processor.py:186} INFO - Started process (PID=1009) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:51:09.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:51:09.669+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:51:09.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:51:11.384+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:51:11.418+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:51:11.417+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:51:11.482+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:51:11.482+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:51:11.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.140 seconds
[2025-01-02T16:51:44.661+0000] {processor.py:186} INFO - Started process (PID=1036) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:51:44.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:51:44.664+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:51:44.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:51:44.685+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:51:44.749+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:51:44.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:51:44.777+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:51:44.777+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:51:44.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2025-01-02T16:52:17.816+0000] {processor.py:186} INFO - Started process (PID=1063) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:52:17.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:52:17.820+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:52:17.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:52:17.836+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:52:17.901+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:52:17.900+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:52:17.936+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:52:17.936+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:52:18.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.192 seconds
[2025-01-02T16:52:50.109+0000] {processor.py:186} INFO - Started process (PID=1089) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:52:50.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:52:50.112+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:52:50.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:52:50.127+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:52:50.150+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:52:50.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:52:50.169+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:52:50.168+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:52:50.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T16:53:23.269+0000] {processor.py:186} INFO - Started process (PID=1115) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:53:23.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:53:23.272+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:53:23.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:53:23.286+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:53:23.308+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:53:23.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:53:23.329+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:53:23.329+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:53:23.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T16:53:56.483+0000] {processor.py:186} INFO - Started process (PID=1142) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:53:56.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:53:56.485+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:53:56.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:53:56.502+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:53:56.552+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:53:56.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:53:56.584+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:53:56.584+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:53:56.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.184 seconds
[2025-01-02T16:54:28.645+0000] {processor.py:186} INFO - Started process (PID=1168) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:54:28.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:54:28.648+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:54:28.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:54:28.664+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:54:28.696+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:54:28.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:54:28.761+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:54:28.760+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:54:28.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2025-01-02T16:55:01.706+0000] {processor.py:186} INFO - Started process (PID=1194) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:55:01.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:55:01.709+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:55:01.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:55:01.723+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:55:01.756+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:55:01.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:55:01.775+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:55:01.775+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:55:01.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2025-01-02T16:55:34.972+0000] {processor.py:186} INFO - Started process (PID=1220) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:55:34.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:55:34.977+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:55:34.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:55:34.993+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:55:35.031+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:55:35.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:55:35.057+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:55:35.057+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:55:35.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.157 seconds
[2025-01-02T16:56:07.115+0000] {processor.py:186} INFO - Started process (PID=1246) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:56:07.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:56:07.118+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:56:07.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:56:07.136+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:56:07.188+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:56:07.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:56:07.219+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:56:07.219+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:56:07.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T16:56:40.461+0000] {processor.py:186} INFO - Started process (PID=1272) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:56:40.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:56:40.463+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:56:40.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:56:40.478+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:56:40.500+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:56:40.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:56:40.550+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:56:40.549+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:56:40.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2025-01-02T16:57:12.131+0000] {processor.py:186} INFO - Started process (PID=1297) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:57:12.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:57:12.135+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:57:12.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:57:12.156+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:57:12.225+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:57:12.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:57:12.249+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:57:12.248+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:57:12.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.194 seconds
[2025-01-02T16:57:42.441+0000] {processor.py:186} INFO - Started process (PID=1324) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:57:42.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:57:42.445+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:57:42.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:57:42.472+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:57:42.542+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:57:42.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:57:42.622+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:57:42.622+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:57:46.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 2.302 seconds
[2025-01-02T16:58:18.393+0000] {processor.py:186} INFO - Started process (PID=1349) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:58:18.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:58:18.397+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:58:18.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:58:18.433+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:58:18.555+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:58:18.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:58:18.667+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:58:18.666+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:58:18.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.357 seconds
[2025-01-02T16:58:51.780+0000] {processor.py:186} INFO - Started process (PID=1375) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:58:51.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:58:51.782+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:58:51.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:58:51.799+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:58:51.835+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:58:51.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:58:51.859+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:58:51.859+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:58:51.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2025-01-02T16:59:22.377+0000] {processor.py:186} INFO - Started process (PID=1401) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:59:22.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:59:22.379+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:59:22.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:59:24.095+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:59:24.140+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:59:24.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:59:24.165+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:59:24.164+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:59:24.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2025-01-02T16:59:55.620+0000] {processor.py:186} INFO - Started process (PID=1427) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:59:55.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T16:59:55.623+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:59:55.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:59:55.638+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T16:59:55.680+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:59:55.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T16:59:55.699+0000] {logging_mixin.py:190} INFO - [2025-01-02T16:59:55.699+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 15:00:00+00:00, run_after=2025-01-02 16:00:00+00:00
[2025-01-02T16:59:56.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.398 seconds
[2025-01-02T17:00:26.373+0000] {processor.py:186} INFO - Started process (PID=1453) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:00:26.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:00:26.375+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:00:26.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:00:26.389+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:00:26.410+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:00:26.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:00:26.428+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:00:26.428+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:00:26.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.079 seconds
[2025-01-02T17:00:57.098+0000] {processor.py:186} INFO - Started process (PID=1479) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:00:57.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:00:57.101+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:00:57.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:00:57.121+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:00:57.146+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:00:57.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:00:57.217+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:00:57.216+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:00:57.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.145 seconds
[2025-01-02T17:01:27.360+0000] {processor.py:186} INFO - Started process (PID=1499) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:01:27.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:01:27.364+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:01:27.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:01:27.381+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:01:27.410+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:01:27.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:01:27.473+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:01:27.473+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:01:27.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.137 seconds
[2025-01-02T17:01:57.579+0000] {processor.py:186} INFO - Started process (PID=1524) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:01:57.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:01:57.582+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:01:57.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:01:57.602+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:01:57.627+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:01:57.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:01:57.690+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:01:57.690+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:01:57.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.142 seconds
[2025-01-02T17:02:27.902+0000] {processor.py:186} INFO - Started process (PID=1550) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:02:27.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:02:27.906+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:02:27.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:02:27.920+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:02:27.941+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:02:27.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:02:27.959+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:02:27.959+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:02:28.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2025-01-02T17:02:58.105+0000] {processor.py:186} INFO - Started process (PID=1576) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:02:58.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:02:58.108+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:02:58.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:02:58.123+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:02:58.144+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:02:58.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:02:58.169+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:02:58.169+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:02:58.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.363 seconds
[2025-01-02T17:03:28.654+0000] {processor.py:186} INFO - Started process (PID=1602) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:03:28.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:03:28.656+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:03:28.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:03:28.671+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:03:28.696+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:03:28.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:03:28.717+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:03:28.716+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:03:28.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.087 seconds
[2025-01-02T17:03:58.780+0000] {processor.py:186} INFO - Started process (PID=1619) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:03:58.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:03:58.782+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:03:58.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:03:58.812+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:03:58.839+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:03:58.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:03:58.858+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:03:58.858+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:03:58.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2025-01-02T17:04:29.083+0000] {processor.py:186} INFO - Started process (PID=1647) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:04:29.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:04:29.085+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:04:29.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:04:29.100+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:04:29.123+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:04:29.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:04:29.144+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:04:29.144+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:04:29.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T17:04:59.277+0000] {processor.py:186} INFO - Started process (PID=1674) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:04:59.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:04:59.280+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:04:59.279+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:04:59.295+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:04:59.331+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:04:59.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:04:59.352+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:04:59.351+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:04:59.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2025-01-02T17:05:29.473+0000] {processor.py:186} INFO - Started process (PID=1700) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:05:29.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:05:29.476+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:05:29.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:05:29.491+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:05:29.515+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:05:29.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:05:29.535+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:05:29.535+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:05:29.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.354 seconds
[2025-01-02T17:06:00.086+0000] {processor.py:186} INFO - Started process (PID=1726) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:06:00.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:06:00.089+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:06:00.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:06:00.105+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:06:00.131+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:06:00.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:06:00.499+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:06:00.498+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:06:00.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.440 seconds
[2025-01-02T17:06:31.732+0000] {processor.py:186} INFO - Started process (PID=1754) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:06:31.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:06:31.734+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:06:31.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:06:31.748+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:06:31.771+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:06:31.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:06:31.792+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:06:31.792+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:06:31.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T17:07:04.789+0000] {processor.py:186} INFO - Started process (PID=1780) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:07:04.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:07:04.792+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:07:04.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:07:04.806+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:07:04.829+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:07:04.828+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:07:04.890+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:07:04.890+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:07:04.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T17:07:38.062+0000] {processor.py:186} INFO - Started process (PID=1806) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:07:38.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:07:38.065+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:07:38.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:07:38.085+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:07:38.111+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:07:38.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:07:38.183+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:07:38.183+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:07:38.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.148 seconds
[2025-01-02T17:08:10.473+0000] {processor.py:186} INFO - Started process (PID=1833) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:08:10.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:08:10.476+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:08:10.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:08:10.492+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:08:10.538+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:08:10.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:08:10.931+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:08:10.931+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:08:10.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.484 seconds
[2025-01-02T17:08:43.257+0000] {processor.py:186} INFO - Started process (PID=1859) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:08:43.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:08:43.260+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:08:43.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:08:43.275+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:08:43.297+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:08:43.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:08:43.316+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:08:43.316+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:08:43.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T17:09:16.397+0000] {processor.py:186} INFO - Started process (PID=1885) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:09:16.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:09:16.399+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:09:16.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:09:16.414+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:09:16.437+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:09:16.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:09:16.507+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:09:16.507+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:09:16.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.137 seconds
[2025-01-02T17:09:49.663+0000] {processor.py:186} INFO - Started process (PID=1911) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:09:49.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:09:49.666+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:09:49.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:09:49.684+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:09:49.738+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:09:49.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:09:49.760+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:09:49.759+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:09:49.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2025-01-02T17:10:21.811+0000] {processor.py:186} INFO - Started process (PID=1936) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:10:21.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:10:21.814+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:10:21.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:10:21.830+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:10:21.851+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:10:21.851+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:10:22.155+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:10:22.155+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:10:22.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.422 seconds
[2025-01-02T17:10:55.117+0000] {processor.py:186} INFO - Started process (PID=1963) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:10:55.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:10:55.119+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:10:55.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:10:55.134+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:10:55.157+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:10:55.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:10:55.459+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:10:55.459+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:10:55.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.424 seconds
[2025-01-02T17:11:27.734+0000] {processor.py:186} INFO - Started process (PID=1989) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:11:27.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:11:27.736+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:11:27.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:11:27.751+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:11:27.775+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:11:27.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:11:27.837+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:11:27.837+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:11:27.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T17:12:00.974+0000] {processor.py:186} INFO - Started process (PID=2015) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:12:00.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:12:00.976+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:12:00.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:12:00.990+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:12:01.044+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:12:01.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:12:01.065+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:12:01.064+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:12:01.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.117 seconds
[2025-01-02T17:12:33.223+0000] {processor.py:186} INFO - Started process (PID=2041) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:12:33.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:12:33.226+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:12:33.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:12:33.240+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:12:33.262+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:12:33.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:12:33.551+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:12:33.551+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:12:33.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.353 seconds
[2025-01-02T17:13:06.835+0000] {processor.py:186} INFO - Started process (PID=2067) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:13:06.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:13:06.839+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:13:06.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:13:06.861+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:13:06.883+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:13:06.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:13:07.166+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:13:07.166+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:13:07.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.358 seconds
[2025-01-02T17:13:38.974+0000] {processor.py:186} INFO - Started process (PID=2093) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:13:38.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:13:38.977+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:13:38.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:13:39.176+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:13:39.250+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:13:39.250+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:13:39.269+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:13:39.269+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:13:39.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.364 seconds
[2025-01-02T17:14:12.565+0000] {processor.py:186} INFO - Started process (PID=2118) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:14:12.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:14:12.568+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:14:12.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:14:12.584+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:14:12.651+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:14:12.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:14:12.674+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:14:12.673+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:14:12.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.186 seconds
[2025-01-02T17:14:44.879+0000] {processor.py:186} INFO - Started process (PID=2144) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:14:44.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:14:44.881+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:14:44.881+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:14:44.896+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:14:44.929+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:14:44.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:14:44.948+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:14:44.948+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:14:44.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2025-01-02T17:15:18.146+0000] {processor.py:186} INFO - Started process (PID=2170) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:15:18.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:15:18.149+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:15:18.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:15:18.164+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:15:18.187+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:15:18.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:15:18.251+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:15:18.251+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:15:18.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T17:15:51.244+0000] {processor.py:186} INFO - Started process (PID=2196) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:15:51.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:15:51.247+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:15:51.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:15:51.300+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:15:51.325+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:15:51.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:15:51.389+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:15:51.388+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:15:51.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.183 seconds
[2025-01-02T17:16:23.489+0000] {processor.py:186} INFO - Started process (PID=2222) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:16:23.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:16:23.492+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:16:23.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:16:23.509+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:16:23.534+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:16:23.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:16:23.555+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:16:23.555+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:16:23.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2025-01-02T17:16:56.671+0000] {processor.py:186} INFO - Started process (PID=2248) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:16:56.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:16:56.676+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:16:56.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:16:56.703+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:16:56.803+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:16:56.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:16:56.835+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:16:56.835+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:16:56.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.248 seconds
[2025-01-02T17:17:29.091+0000] {processor.py:186} INFO - Started process (PID=2274) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:17:29.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:17:29.093+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:17:29.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:17:29.108+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:17:29.132+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:17:29.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:17:29.156+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:17:29.155+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:17:29.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.131 seconds
[2025-01-02T17:18:02.375+0000] {processor.py:186} INFO - Started process (PID=2300) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:18:02.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:18:02.378+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:18:02.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:18:02.395+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:18:02.421+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:18:02.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:18:02.485+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:18:02.485+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:18:02.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.137 seconds
[2025-01-02T17:18:35.496+0000] {processor.py:186} INFO - Started process (PID=2326) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:18:35.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:18:35.500+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:18:35.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:18:35.518+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:18:35.565+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:18:35.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:18:35.635+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:18:35.635+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:18:35.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.166 seconds
[2025-01-02T17:19:07.751+0000] {processor.py:186} INFO - Started process (PID=2352) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:19:07.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:19:07.756+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:19:07.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:19:07.772+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:19:07.837+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:19:07.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:19:07.857+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:19:07.856+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:19:07.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T17:19:41.173+0000] {processor.py:186} INFO - Started process (PID=2379) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:19:41.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:19:41.176+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:19:41.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:19:41.190+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:19:41.225+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:19:41.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:19:41.245+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:19:41.244+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:19:41.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2025-01-02T17:20:11.855+0000] {processor.py:186} INFO - Started process (PID=2405) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:20:11.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:20:11.858+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:20:11.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:20:13.570+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:20:13.614+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:20:13.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:20:13.640+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:20:13.640+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:20:13.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.161 seconds
[2025-01-02T17:20:46.590+0000] {processor.py:186} INFO - Started process (PID=2431) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:20:46.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:20:46.593+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:20:46.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:20:46.610+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:20:46.667+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:20:46.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:20:46.689+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:20:46.689+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:20:46.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T17:21:19.788+0000] {processor.py:186} INFO - Started process (PID=2457) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:21:19.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:21:19.791+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:21:19.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:21:19.812+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:21:19.872+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:21:19.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:21:19.896+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:21:19.895+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:21:19.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.185 seconds
[2025-01-02T17:21:53.080+0000] {processor.py:186} INFO - Started process (PID=2483) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:21:53.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:21:53.083+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:21:53.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:21:53.101+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:21:53.129+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:21:53.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:21:53.182+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:21:53.182+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:21:53.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T17:22:25.368+0000] {processor.py:186} INFO - Started process (PID=2503) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:22:25.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:22:25.371+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:22:25.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:22:25.395+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:22:25.476+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:22:25.476+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:22:25.573+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:22:25.572+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:22:25.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.231 seconds
[2025-01-02T17:22:58.523+0000] {processor.py:186} INFO - Started process (PID=2535) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:22:58.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:22:58.525+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:22:58.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:22:58.541+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:22:58.562+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:22:58.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:22:58.581+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:22:58.581+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:22:58.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2025-01-02T17:23:30.872+0000] {processor.py:186} INFO - Started process (PID=2556) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:23:30.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:23:30.875+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:23:30.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:23:30.890+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:23:30.962+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:23:30.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:23:30.981+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:23:30.981+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:23:31.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2025-01-02T17:24:04.194+0000] {processor.py:186} INFO - Started process (PID=2583) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:24:04.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:24:04.198+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:24:04.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:24:04.251+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:24:04.279+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:24:04.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:24:04.361+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:24:04.361+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:24:04.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.200 seconds
[2025-01-02T17:24:36.745+0000] {processor.py:186} INFO - Started process (PID=2609) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:24:36.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:24:36.748+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:24:36.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:24:36.763+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:24:36.788+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:24:36.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:24:36.848+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:24:36.847+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:24:36.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T17:25:08.080+0000] {processor.py:186} INFO - Started process (PID=2636) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:25:08.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:25:08.083+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:25:08.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:25:08.099+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:25:08.125+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:25:08.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:25:08.146+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:25:08.146+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:25:08.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.091 seconds
[2025-01-02T17:25:38.341+0000] {processor.py:186} INFO - Started process (PID=2662) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:25:38.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:25:38.343+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:25:38.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:25:38.360+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:25:38.414+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:25:38.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:25:38.435+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:25:38.435+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:25:38.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.123 seconds
[2025-01-02T17:26:09.107+0000] {processor.py:186} INFO - Started process (PID=2688) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:26:09.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:26:09.110+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:26:09.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:26:09.128+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:26:09.151+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:26:09.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:26:09.169+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:26:09.169+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:26:09.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.091 seconds
[2025-01-02T17:26:39.478+0000] {processor.py:186} INFO - Started process (PID=2714) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:26:39.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:26:39.480+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:26:39.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:26:39.497+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:26:39.551+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:26:39.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:26:39.572+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:26:39.572+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:26:39.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2025-01-02T17:27:09.755+0000] {processor.py:186} INFO - Started process (PID=2740) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:27:09.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:27:09.757+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:27:09.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:27:09.772+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:27:09.804+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:27:09.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:27:09.822+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:27:09.822+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:27:09.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.090 seconds
[2025-01-02T17:27:40.075+0000] {processor.py:186} INFO - Started process (PID=2766) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:27:40.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:27:40.079+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:27:40.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:27:40.098+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:27:40.128+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:27:40.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:27:40.197+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:27:40.197+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:27:40.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2025-01-02T17:28:10.361+0000] {processor.py:186} INFO - Started process (PID=2786) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:28:10.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:28:10.364+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:28:10.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:28:10.382+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:28:10.439+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:28:10.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:28:10.524+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:28:10.524+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:28:10.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.192 seconds
[2025-01-02T17:28:40.688+0000] {processor.py:186} INFO - Started process (PID=2812) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:28:40.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:28:40.693+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:28:40.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:28:40.716+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:28:40.787+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:28:40.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:28:40.810+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:28:40.810+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:28:40.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2025-01-02T17:29:10.978+0000] {processor.py:186} INFO - Started process (PID=2838) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:29:10.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:29:10.981+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:29:10.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:29:10.997+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:29:11.064+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:29:11.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:29:11.086+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:29:11.086+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:29:11.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.195 seconds
[2025-01-02T17:29:41.349+0000] {processor.py:186} INFO - Started process (PID=2865) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:29:41.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:29:41.352+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:29:41.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:29:41.371+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:29:41.431+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:29:41.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:29:41.455+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:29:41.455+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:29:41.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.179 seconds
[2025-01-02T17:30:11.690+0000] {processor.py:186} INFO - Started process (PID=2891) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:30:11.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:30:11.692+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:30:11.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:30:11.710+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:30:11.767+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:30:11.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:30:11.788+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:30:11.788+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:30:11.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.168 seconds
[2025-01-02T17:30:41.957+0000] {processor.py:186} INFO - Started process (PID=2917) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:30:41.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:30:41.960+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:30:41.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:30:41.981+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:30:42.052+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:30:42.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:30:42.077+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:30:42.077+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:30:42.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.193 seconds
[2025-01-02T17:31:12.288+0000] {processor.py:186} INFO - Started process (PID=2937) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:31:12.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:31:12.291+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:31:12.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:31:12.306+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:31:12.329+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:31:12.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:31:12.347+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:31:12.347+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:31:12.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.087 seconds
[2025-01-02T17:31:44.513+0000] {processor.py:186} INFO - Started process (PID=2963) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:31:44.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:31:44.516+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:31:44.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:31:44.534+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:31:44.598+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:31:44.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:31:44.620+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:31:44.619+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:31:44.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.182 seconds
[2025-01-02T17:32:17.929+0000] {processor.py:186} INFO - Started process (PID=2989) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:32:17.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:32:17.932+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:32:17.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:32:17.946+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:32:17.969+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:32:17.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:32:18.037+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:32:18.037+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:32:18.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2025-01-02T17:32:51.186+0000] {processor.py:186} INFO - Started process (PID=3015) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:32:51.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:32:51.189+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:32:51.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:32:51.204+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:32:51.228+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:32:51.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:32:51.249+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:32:51.248+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:32:51.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T17:33:23.335+0000] {processor.py:186} INFO - Started process (PID=3041) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:33:23.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:33:23.337+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:33:23.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:33:23.411+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:33:23.519+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:33:23.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:33:23.539+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:33:23.538+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:33:23.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.274 seconds
[2025-01-02T17:33:56.868+0000] {processor.py:186} INFO - Started process (PID=3067) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:33:56.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:33:56.871+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:33:56.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:33:56.888+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:33:56.959+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:33:56.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:33:56.981+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:33:56.981+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:33:57.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.182 seconds
[2025-01-02T17:34:29.039+0000] {processor.py:186} INFO - Started process (PID=3093) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:34:29.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:34:29.042+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:34:29.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:34:29.060+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:34:29.094+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:34:29.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:34:29.114+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:34:29.114+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:34:29.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2025-01-02T17:35:00.440+0000] {processor.py:186} INFO - Started process (PID=3119) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:35:00.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:35:00.442+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:35:00.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:35:00.457+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:35:00.490+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:35:00.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:35:00.550+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:35:00.550+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:35:00.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T17:35:30.949+0000] {processor.py:186} INFO - Started process (PID=3145) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:35:30.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:35:30.952+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:35:30.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:35:30.971+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:35:30.997+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:35:30.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:35:31.073+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:35:31.072+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:35:31.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.151 seconds
[2025-01-02T17:36:01.771+0000] {processor.py:186} INFO - Started process (PID=3171) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:36:01.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:36:01.775+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:36:01.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:36:01.957+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:36:02.077+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:36:02.077+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:36:02.253+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:36:02.253+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:36:02.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.519 seconds
[2025-01-02T17:36:32.523+0000] {processor.py:186} INFO - Started process (PID=3196) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:36:32.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:36:32.527+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:36:32.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:36:32.544+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:36:32.579+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:36:32.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:36:32.601+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:36:32.601+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:36:32.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2025-01-02T17:37:02.851+0000] {processor.py:186} INFO - Started process (PID=3221) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:37:02.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:37:02.857+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:37:02.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:37:02.874+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:37:02.902+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:37:02.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:37:02.923+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:37:02.923+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:37:02.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2025-01-02T17:37:33.122+0000] {processor.py:186} INFO - Started process (PID=3247) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:37:33.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:37:33.125+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:37:33.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:37:33.143+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:37:33.176+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:37:33.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:37:33.196+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:37:33.196+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:37:33.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2025-01-02T17:38:03.335+0000] {processor.py:186} INFO - Started process (PID=3267) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:38:03.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:38:03.339+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:38:03.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:38:03.358+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:38:03.388+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:38:03.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:38:03.415+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:38:03.415+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:38:03.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.150 seconds
[2025-01-02T17:38:33.593+0000] {processor.py:186} INFO - Started process (PID=3293) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:38:33.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:38:33.595+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:38:33.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:38:33.611+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:38:33.636+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:38:33.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:38:33.660+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:38:33.660+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:38:33.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T17:39:03.941+0000] {processor.py:186} INFO - Started process (PID=3319) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:39:03.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:39:03.943+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:39:03.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:39:03.960+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:39:03.990+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:39:03.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:39:04.061+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:39:04.061+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:39:04.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.148 seconds
[2025-01-02T17:39:34.306+0000] {processor.py:186} INFO - Started process (PID=3345) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:39:34.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:39:34.309+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:39:34.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:39:34.325+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:39:34.406+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:39:34.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:39:34.469+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:39:34.469+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:39:34.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.192 seconds
[2025-01-02T17:40:04.761+0000] {processor.py:186} INFO - Started process (PID=3370) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:40:04.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:40:04.765+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:40:04.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:40:04.802+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:40:04.832+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:40:04.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:40:04.901+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:40:04.901+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:40:04.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.169 seconds
[2025-01-02T17:40:35.086+0000] {processor.py:186} INFO - Started process (PID=3401) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:40:35.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:40:35.090+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:40:35.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:40:35.104+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:40:35.132+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:40:35.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:40:35.150+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:40:35.150+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:40:35.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.090 seconds
[2025-01-02T17:41:05.351+0000] {processor.py:186} INFO - Started process (PID=3416) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:41:05.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:41:05.354+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:41:05.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:41:05.368+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:41:05.398+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:41:05.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:41:05.419+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:41:05.419+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:41:05.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2025-01-02T17:41:37.616+0000] {processor.py:186} INFO - Started process (PID=3443) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:41:37.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:41:37.619+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:41:37.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:41:37.635+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:41:37.676+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:41:37.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:41:37.696+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:41:37.696+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:41:37.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.141 seconds
[2025-01-02T17:42:09.957+0000] {processor.py:186} INFO - Started process (PID=3469) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:42:10.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:42:10.005+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:42:10.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:42:10.026+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:42:10.054+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:42:10.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:42:10.116+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:42:10.116+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:42:10.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.183 seconds
[2025-01-02T17:42:43.375+0000] {processor.py:186} INFO - Started process (PID=3495) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:42:43.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:42:43.378+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:42:43.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:42:43.392+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:42:43.434+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:42:43.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:42:43.453+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:42:43.453+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:42:43.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2025-01-02T17:43:15.815+0000] {processor.py:186} INFO - Started process (PID=3521) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:43:15.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:43:15.818+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:43:15.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:43:15.900+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:43:16.006+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:43:16.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:43:16.105+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:43:16.105+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:43:16.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.390 seconds
[2025-01-02T17:43:48.415+0000] {processor.py:186} INFO - Started process (PID=3547) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:43:48.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:43:48.418+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:43:48.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:43:48.433+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:43:48.512+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:43:48.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:43:48.607+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:43:48.607+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:43:48.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.285 seconds
[2025-01-02T17:44:21.863+0000] {processor.py:186} INFO - Started process (PID=3573) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:44:21.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:44:21.933+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:44:21.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:44:21.955+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:44:22.136+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:44:22.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:44:22.235+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:44:22.234+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:44:22.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.402 seconds
[2025-01-02T17:44:54.488+0000] {processor.py:186} INFO - Started process (PID=3598) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:44:54.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:44:54.491+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:44:54.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:44:54.509+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:44:54.542+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:44:54.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:44:54.607+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:44:54.607+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:44:54.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.145 seconds
[2025-01-02T17:45:27.784+0000] {processor.py:186} INFO - Started process (PID=3624) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:45:27.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:45:27.787+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:45:27.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:45:27.808+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:45:27.864+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:45:27.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:45:27.964+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:45:27.963+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:45:27.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.209 seconds
[2025-01-02T17:46:00.200+0000] {processor.py:186} INFO - Started process (PID=3650) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:46:00.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:46:00.202+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:46:00.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:46:00.224+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:46:00.279+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:46:00.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:46:00.300+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:46:00.300+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:46:00.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2025-01-02T17:46:33.337+0000] {processor.py:186} INFO - Started process (PID=3676) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:46:33.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:46:33.340+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:46:33.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:46:33.362+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:46:33.385+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:46:33.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:46:33.446+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:46:33.446+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:46:33.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T17:47:05.659+0000] {processor.py:186} INFO - Started process (PID=3701) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:47:05.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:47:05.662+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:47:05.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:47:05.684+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:47:05.745+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:47:05.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:47:05.766+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:47:05.766+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:47:05.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T17:47:38.851+0000] {processor.py:186} INFO - Started process (PID=3727) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:47:38.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:47:38.854+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:47:38.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:47:38.879+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:47:38.902+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:47:38.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:47:38.963+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:47:38.963+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:47:38.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2025-01-02T17:48:12.225+0000] {processor.py:186} INFO - Started process (PID=3753) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:48:12.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:48:12.229+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:48:12.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:48:12.262+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:48:12.325+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:48:12.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:48:12.352+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:48:12.352+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:48:12.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.207 seconds
[2025-01-02T17:48:44.510+0000] {processor.py:186} INFO - Started process (PID=3779) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:48:44.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:48:44.514+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:48:44.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:48:44.546+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:48:44.643+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:48:44.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:48:44.737+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:48:44.737+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:48:44.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.255 seconds
[2025-01-02T17:49:18.004+0000] {processor.py:186} INFO - Started process (PID=3806) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:49:18.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:49:18.008+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:49:18.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:49:18.039+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:49:18.065+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:49:18.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:49:18.141+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:49:18.141+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:49:18.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.166 seconds
[2025-01-02T17:49:50.175+0000] {processor.py:186} INFO - Started process (PID=3832) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:49:50.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:49:50.178+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:49:50.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:49:50.200+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:49:50.253+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:49:50.252+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:49:50.274+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:49:50.274+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:49:50.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.172 seconds
[2025-01-02T17:50:23.621+0000] {processor.py:186} INFO - Started process (PID=3858) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:50:23.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:50:23.624+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:50:23.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:50:23.640+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:50:23.665+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:50:23.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:50:23.729+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:50:23.728+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:50:23.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2025-01-02T17:50:56.849+0000] {processor.py:186} INFO - Started process (PID=3884) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:50:56.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:50:56.851+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:50:56.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:50:56.865+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:50:56.916+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:50:56.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:50:56.936+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:50:56.936+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:50:56.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2025-01-02T17:51:29.256+0000] {processor.py:186} INFO - Started process (PID=3910) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:51:29.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:51:29.259+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:51:29.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:51:29.275+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:51:29.343+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:51:29.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:51:29.365+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:51:29.365+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:51:29.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.187 seconds
[2025-01-02T17:52:02.646+0000] {processor.py:186} INFO - Started process (PID=3937) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:52:02.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:52:02.648+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:52:02.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:52:02.662+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:52:02.684+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:52:02.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:52:02.742+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:52:02.702+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:52:02.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2025-01-02T17:52:34.978+0000] {processor.py:186} INFO - Started process (PID=3963) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:52:34.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:52:34.981+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:52:34.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:52:34.998+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:52:35.056+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:52:35.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:52:35.074+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:52:35.074+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:52:35.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T17:53:08.069+0000] {processor.py:186} INFO - Started process (PID=3990) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:53:08.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:53:08.072+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:53:08.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:53:08.086+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:53:08.139+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:53:08.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:53:08.162+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:53:08.162+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:53:08.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.181 seconds
[2025-01-02T17:53:38.767+0000] {processor.py:186} INFO - Started process (PID=4016) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:53:38.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:53:38.769+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:53:38.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:53:40.485+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:53:40.510+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:53:40.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:53:40.573+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:53:40.573+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:53:40.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T17:54:13.812+0000] {processor.py:186} INFO - Started process (PID=4043) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:54:13.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:54:13.816+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:54:13.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:54:13.886+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:54:13.911+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:54:13.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:54:13.977+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:54:13.977+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:54:13.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.197 seconds
[2025-01-02T17:54:47.140+0000] {processor.py:186} INFO - Started process (PID=4069) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:54:47.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:54:47.142+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:54:47.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:54:47.157+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:54:47.180+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:54:47.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:54:47.200+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:54:47.200+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:54:47.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.088 seconds
[2025-01-02T17:55:17.479+0000] {processor.py:186} INFO - Started process (PID=4095) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:55:17.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:55:17.481+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:55:17.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:55:19.194+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:55:19.215+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:55:19.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:55:19.277+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:55:19.277+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:55:19.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.123 seconds
[2025-01-02T17:55:52.508+0000] {processor.py:186} INFO - Started process (PID=4121) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:55:52.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:55:52.510+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:55:52.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:55:52.524+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:55:52.579+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:55:52.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:55:52.597+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:55:52.597+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:55:52.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2025-01-02T17:56:25.713+0000] {processor.py:186} INFO - Started process (PID=4147) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:56:25.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:56:25.715+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:56:25.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:56:25.731+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:56:25.759+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:56:25.758+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:56:25.825+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:56:25.825+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:56:25.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2025-01-02T17:56:58.013+0000] {processor.py:186} INFO - Started process (PID=4173) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:56:58.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:56:58.015+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:56:58.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:56:58.029+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:56:58.055+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:56:58.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:56:58.121+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:56:58.121+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:56:58.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T17:57:31.145+0000] {processor.py:186} INFO - Started process (PID=4199) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:57:31.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:57:31.147+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:57:31.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:57:31.162+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:57:31.185+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:57:31.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:57:31.205+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:57:31.205+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:57:31.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.086 seconds
[2025-01-02T17:58:04.339+0000] {processor.py:186} INFO - Started process (PID=4226) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:58:04.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:58:04.342+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:58:04.342+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:58:04.357+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:58:04.401+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:58:04.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:58:04.422+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:58:04.422+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:58:04.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2025-01-02T17:58:36.732+0000] {processor.py:186} INFO - Started process (PID=4253) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:58:36.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:58:36.735+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:58:36.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:58:36.751+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:58:36.830+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:58:36.828+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:58:36.871+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:58:36.871+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:58:36.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.219 seconds
[2025-01-02T17:59:10.131+0000] {processor.py:186} INFO - Started process (PID=4279) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:59:10.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:59:10.134+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:59:10.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:59:10.148+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:59:10.177+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:59:10.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:59:10.247+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:59:10.247+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:59:10.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2025-01-02T17:59:42.446+0000] {processor.py:186} INFO - Started process (PID=4313) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:59:42.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T17:59:42.449+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:59:42.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:59:42.464+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T17:59:42.506+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:59:42.506+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T17:59:42.525+0000] {logging_mixin.py:190} INFO - [2025-01-02T17:59:42.525+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 16:00:00+00:00, run_after=2025-01-02 17:00:00+00:00
[2025-01-02T17:59:42.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2025-01-02T18:00:15.753+0000] {processor.py:186} INFO - Started process (PID=4339) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:00:15.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:00:15.758+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:00:15.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:00:15.779+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:00:15.849+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:00:15.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:00:15.887+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:00:15.887+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:00:15.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.210 seconds
[2025-01-02T18:00:49.006+0000] {processor.py:186} INFO - Started process (PID=4365) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:00:49.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:00:49.010+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:00:49.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:00:49.031+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:00:49.077+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:00:49.077+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:00:49.154+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:00:49.154+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:00:49.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.181 seconds
[2025-01-02T18:01:21.437+0000] {processor.py:186} INFO - Started process (PID=4391) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:01:21.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:01:21.440+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:01:21.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:01:21.455+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:01:21.477+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:01:21.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:01:21.537+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:01:21.497+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:01:21.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.131 seconds
[2025-01-02T18:01:54.817+0000] {processor.py:186} INFO - Started process (PID=4417) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:01:54.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:01:54.819+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:01:54.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:01:54.835+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:01:54.857+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:01:54.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:01:54.880+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:01:54.880+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:01:54.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T18:02:27.198+0000] {processor.py:186} INFO - Started process (PID=4443) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:02:27.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:02:27.200+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:02:27.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:02:27.216+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:02:27.271+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:02:27.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:02:27.301+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:02:27.301+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:02:27.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.178 seconds
[2025-01-02T18:03:00.603+0000] {processor.py:186} INFO - Started process (PID=4469) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:03:00.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:03:00.606+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:03:00.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:03:00.621+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:03:00.664+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:03:00.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:03:00.683+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:03:00.683+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:03:00.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2025-01-02T18:03:33.825+0000] {processor.py:186} INFO - Started process (PID=4495) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:03:33.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:03:33.828+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:03:33.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:03:33.848+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:03:33.881+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:03:33.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:03:33.903+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:03:33.903+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:03:33.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.153 seconds
[2025-01-02T18:04:06.308+0000] {processor.py:186} INFO - Started process (PID=4520) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:04:06.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:04:06.312+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:04:06.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:04:06.326+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:04:06.347+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:04:06.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:04:06.366+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:04:06.366+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:04:06.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T18:04:39.724+0000] {processor.py:186} INFO - Started process (PID=4546) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:04:39.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:04:39.726+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:04:39.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:04:39.741+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:04:39.775+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:04:39.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:04:39.795+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:04:39.795+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:04:39.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2025-01-02T18:05:11.938+0000] {processor.py:186} INFO - Started process (PID=4572) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:05:11.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:05:11.940+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:05:11.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:05:11.954+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:05:11.981+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:05:11.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:05:12.004+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:05:12.003+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:05:12.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2025-01-02T18:05:45.268+0000] {processor.py:186} INFO - Started process (PID=4598) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:05:45.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:05:45.271+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:05:45.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:05:45.286+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:05:45.311+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:05:45.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:05:45.372+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:05:45.372+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:05:45.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.132 seconds
[2025-01-02T18:06:15.902+0000] {processor.py:186} INFO - Started process (PID=4624) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:06:15.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:06:15.905+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:06:15.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:06:17.614+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:06:17.638+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:06:17.638+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:06:17.657+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:06:17.657+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:06:17.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.089 seconds
[2025-01-02T18:06:50.822+0000] {processor.py:186} INFO - Started process (PID=4650) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:06:50.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:06:50.825+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:06:50.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:06:50.846+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:06:50.896+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:06:50.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:06:50.915+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:06:50.915+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:06:50.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2025-01-02T18:07:24.048+0000] {processor.py:186} INFO - Started process (PID=4676) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:07:24.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:07:24.051+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:07:24.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:07:24.067+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:07:24.093+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:07:24.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:07:24.114+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:07:24.114+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:07:24.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T18:07:57.285+0000] {processor.py:186} INFO - Started process (PID=4703) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:07:57.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:07:57.288+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:07:57.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:07:57.304+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:07:57.326+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:07:57.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:07:57.381+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:07:57.381+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:07:57.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2025-01-02T18:08:29.617+0000] {processor.py:186} INFO - Started process (PID=4729) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:08:29.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:08:29.620+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:08:29.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:08:29.638+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:08:29.668+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:08:29.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:08:29.734+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:08:29.734+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:08:29.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2025-01-02T18:09:02.853+0000] {processor.py:186} INFO - Started process (PID=4755) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:09:02.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:09:02.856+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:09:02.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:09:02.872+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:09:02.894+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:09:02.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:09:02.914+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:09:02.914+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:09:02.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2025-01-02T18:09:36.083+0000] {processor.py:186} INFO - Started process (PID=4793) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:09:36.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:09:36.086+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:09:36.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:09:36.104+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:09:36.176+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:09:36.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:09:36.200+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:09:36.200+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:09:36.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.187 seconds
[2025-01-02T18:10:08.286+0000] {processor.py:186} INFO - Started process (PID=4819) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:10:08.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:10:08.288+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:10:08.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:10:08.303+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:10:08.353+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:10:08.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:10:08.374+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:10:08.374+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:10:08.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2025-01-02T18:10:41.691+0000] {processor.py:186} INFO - Started process (PID=4845) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:10:41.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:10:41.693+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:10:41.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:10:41.711+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:10:41.750+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:10:41.750+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:10:41.826+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:10:41.826+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:10:41.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.161 seconds
[2025-01-02T18:11:14.138+0000] {processor.py:186} INFO - Started process (PID=4871) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:11:14.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:11:14.140+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:11:14.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:11:14.156+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:11:14.179+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:11:14.179+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:11:14.261+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:11:14.261+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:11:14.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.148 seconds
[2025-01-02T18:11:47.320+0000] {processor.py:186} INFO - Started process (PID=4897) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:11:47.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:11:47.323+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:11:47.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:11:47.339+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:11:47.381+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:11:47.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:11:47.403+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:11:47.402+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:11:47.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.165 seconds
[2025-01-02T18:12:20.543+0000] {processor.py:186} INFO - Started process (PID=4922) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:12:20.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:12:20.546+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:12:20.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:12:20.562+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:12:20.637+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:12:20.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:12:20.657+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:12:20.657+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:12:20.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.138 seconds
[2025-01-02T18:12:52.786+0000] {processor.py:186} INFO - Started process (PID=4948) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:12:52.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:12:52.789+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:12:52.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:12:52.806+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:12:52.832+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:12:52.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:12:52.881+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:12:52.881+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:12:52.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2025-01-02T18:13:26.184+0000] {processor.py:186} INFO - Started process (PID=4974) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:13:26.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:13:26.187+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:13:26.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:13:26.204+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:13:26.248+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:13:26.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:13:26.269+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:13:26.269+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:13:26.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2025-01-02T18:13:59.369+0000] {processor.py:186} INFO - Started process (PID=5000) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:13:59.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:13:59.371+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:13:59.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:13:59.387+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:13:59.409+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:13:59.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:13:59.448+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:13:59.448+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:13:59.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2025-01-02T18:14:31.633+0000] {processor.py:186} INFO - Started process (PID=5026) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:14:31.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:14:31.635+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:14:31.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:14:31.650+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:14:31.703+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:14:31.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:14:31.727+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:14:31.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:14:31.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.120 seconds
[2025-01-02T18:15:05.011+0000] {processor.py:186} INFO - Started process (PID=5052) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:15:05.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:15:05.014+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:15:05.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:15:05.033+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:15:05.057+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:15:05.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:15:05.076+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:15:05.076+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:15:05.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T18:15:37.336+0000] {processor.py:186} INFO - Started process (PID=5078) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:15:37.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:15:37.339+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:15:37.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:15:37.357+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:15:37.410+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:15:37.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:15:37.435+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:15:37.435+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:15:37.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.179 seconds
[2025-01-02T18:16:10.901+0000] {processor.py:186} INFO - Started process (PID=5104) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:16:10.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:16:10.989+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:16:10.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:16:11.021+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:16:11.086+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:16:11.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:16:11.191+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:16:11.191+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:16:11.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.499 seconds
[2025-01-02T18:16:43.329+0000] {processor.py:186} INFO - Started process (PID=5130) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:16:43.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:16:43.331+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:16:43.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:16:43.347+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:16:43.370+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:16:43.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:16:43.444+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:16:43.444+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:16:43.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.138 seconds
[2025-01-02T18:17:16.520+0000] {processor.py:186} INFO - Started process (PID=5156) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:17:16.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:17:16.523+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:17:16.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:17:16.538+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:17:16.570+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:17:16.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:17:16.589+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:17:16.589+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:17:16.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2025-01-02T18:17:49.844+0000] {processor.py:186} INFO - Started process (PID=5182) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:17:49.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:17:49.846+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:17:49.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:17:49.865+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:17:49.944+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:17:49.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:17:49.963+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:17:49.963+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:17:50.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.198 seconds
[2025-01-02T18:18:22.207+0000] {processor.py:186} INFO - Started process (PID=5208) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:18:22.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:18:22.210+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:18:22.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:18:22.228+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:18:22.252+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:18:22.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:18:22.319+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:18:22.319+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:18:22.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.148 seconds
[2025-01-02T18:18:55.402+0000] {processor.py:186} INFO - Started process (PID=5234) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:18:55.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:18:55.405+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:18:55.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:18:55.420+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:18:55.463+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:18:55.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:18:55.485+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:18:55.484+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:18:55.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2025-01-02T18:19:27.742+0000] {processor.py:186} INFO - Started process (PID=5260) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:19:27.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:19:27.746+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:19:27.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:19:27.763+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:19:27.808+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:19:27.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:19:27.885+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:19:27.885+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:19:27.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.176 seconds
[2025-01-02T18:20:01.184+0000] {processor.py:186} INFO - Started process (PID=5286) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:20:01.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:20:01.186+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:20:01.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:20:01.201+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:20:01.244+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:20:01.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:20:01.264+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:20:01.264+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:20:01.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2025-01-02T18:20:33.460+0000] {processor.py:186} INFO - Started process (PID=5312) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:20:33.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:20:33.463+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:20:33.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:20:33.480+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:20:33.527+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:20:33.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:20:33.549+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:20:33.549+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:20:33.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2025-01-02T18:21:06.587+0000] {processor.py:186} INFO - Started process (PID=5338) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:21:06.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:21:06.590+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:21:06.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:21:06.605+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:21:06.658+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:21:06.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:21:06.678+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:21:06.678+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:21:06.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2025-01-02T18:21:39.907+0000] {processor.py:186} INFO - Started process (PID=5364) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:21:39.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:21:39.910+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:21:39.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:21:39.924+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:21:39.967+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:21:39.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:21:39.986+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:21:39.986+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:21:40.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2025-01-02T18:22:12.200+0000] {processor.py:186} INFO - Started process (PID=5389) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:22:12.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:22:12.202+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:22:12.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:22:12.218+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:22:12.290+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:22:12.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:22:12.317+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:22:12.316+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:22:12.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.201 seconds
[2025-01-02T18:22:45.610+0000] {processor.py:186} INFO - Started process (PID=5415) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:22:45.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:22:45.613+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:22:45.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:22:45.632+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:22:45.678+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:22:45.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:22:45.697+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:22:45.697+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:22:45.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.111 seconds
[2025-01-02T18:23:18.802+0000] {processor.py:186} INFO - Started process (PID=5442) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:23:18.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:23:18.805+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:23:18.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:23:18.863+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:23:18.901+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:23:18.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:23:18.968+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:23:18.968+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:23:18.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.189 seconds
[2025-01-02T18:23:51.206+0000] {processor.py:186} INFO - Started process (PID=5468) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:23:51.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:23:51.209+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:23:51.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:23:51.223+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:23:51.276+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:23:51.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:23:51.295+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:23:51.295+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:23:51.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2025-01-02T18:24:24.524+0000] {processor.py:186} INFO - Started process (PID=5495) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:24:24.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:24:24.527+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:24:24.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:24:24.541+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:24:24.586+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:24:24.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:24:24.606+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:24:24.606+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:24:24.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2025-01-02T18:24:56.780+0000] {processor.py:186} INFO - Started process (PID=5522) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:24:56.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:24:56.784+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:24:56.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:24:56.799+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:24:56.823+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:24:56.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:24:56.845+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:24:56.845+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:24:56.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T18:25:29.945+0000] {processor.py:186} INFO - Started process (PID=5548) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:25:29.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:25:29.948+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:25:29.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:25:29.963+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:25:29.984+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:25:29.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:25:30.005+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:25:30.005+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:25:30.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2025-01-02T18:26:03.206+0000] {processor.py:186} INFO - Started process (PID=5574) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:26:03.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:26:03.209+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:26:03.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:26:03.224+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:26:03.247+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:26:03.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:26:03.309+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:26:03.309+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:26:03.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T18:26:35.541+0000] {processor.py:186} INFO - Started process (PID=5600) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:26:35.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:26:35.544+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:26:35.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:26:35.563+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:26:35.626+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:26:35.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:26:35.645+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:26:35.645+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:26:35.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.131 seconds
[2025-01-02T18:27:08.813+0000] {processor.py:186} INFO - Started process (PID=5626) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:27:08.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:27:08.815+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:27:08.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:27:08.830+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:27:08.853+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:27:08.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:27:08.876+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:27:08.876+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:27:08.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T18:27:42.001+0000] {processor.py:186} INFO - Started process (PID=5652) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:27:42.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:27:42.004+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:27:42.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:27:42.017+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:27:42.040+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:27:42.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:27:42.059+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:27:42.058+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:27:42.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T18:28:14.257+0000] {processor.py:186} INFO - Started process (PID=5678) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:28:14.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:28:14.259+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:28:14.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:28:14.274+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:28:14.296+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:28:14.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:28:14.357+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:28:14.356+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:28:14.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2025-01-02T18:28:47.523+0000] {processor.py:186} INFO - Started process (PID=5704) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:28:47.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:28:47.527+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:28:47.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:28:47.545+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:28:47.588+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:28:47.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:28:47.611+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:28:47.611+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:28:47.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.153 seconds
[2025-01-02T18:29:20.792+0000] {processor.py:186} INFO - Started process (PID=5730) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:29:20.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:29:20.794+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:29:20.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:29:20.809+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:29:20.835+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:29:20.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:29:20.898+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:29:20.898+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:29:20.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T18:29:52.995+0000] {processor.py:186} INFO - Started process (PID=5756) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:29:52.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:29:52.997+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:29:52.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:29:53.015+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:29:53.068+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:29:53.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:29:53.087+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:29:53.087+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:29:53.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2025-01-02T18:30:26.189+0000] {processor.py:186} INFO - Started process (PID=5783) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:30:26.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:30:26.192+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:30:26.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:30:26.207+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:30:26.228+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:30:26.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:30:26.292+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:30:26.292+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:30:26.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T18:30:59.509+0000] {processor.py:186} INFO - Started process (PID=5809) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:30:59.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:30:59.512+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:30:59.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:30:59.526+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:30:59.548+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:30:59.548+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:30:59.572+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:30:59.571+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:30:59.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T18:31:30.005+0000] {processor.py:186} INFO - Started process (PID=5835) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:31:30.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:31:30.008+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:31:30.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:31:31.721+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:31:31.770+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:31:31.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:31:31.791+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:31:31.791+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:31:31.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2025-01-02T18:32:04.883+0000] {processor.py:186} INFO - Started process (PID=5861) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:32:04.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:32:04.886+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:32:04.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:32:04.900+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:32:04.921+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:32:04.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:32:04.941+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:32:04.941+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:32:04.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2025-01-02T18:32:38.061+0000] {processor.py:186} INFO - Started process (PID=5887) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:32:38.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:32:38.064+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:32:38.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:32:38.085+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:32:38.140+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:32:38.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:32:38.168+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:32:38.167+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:32:38.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.185 seconds
[2025-01-02T18:33:10.409+0000] {processor.py:186} INFO - Started process (PID=5914) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:33:10.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:33:10.412+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:33:10.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:33:10.427+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:33:10.470+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:33:10.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:33:10.492+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:33:10.492+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:33:10.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2025-01-02T18:33:43.692+0000] {processor.py:186} INFO - Started process (PID=5940) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:33:43.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:33:43.695+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:33:43.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:33:43.716+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:33:43.784+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:33:43.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:33:43.862+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:33:43.862+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:33:43.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.203 seconds
[2025-01-02T18:34:16.841+0000] {processor.py:186} INFO - Started process (PID=5966) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:34:16.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:34:16.844+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:34:16.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:34:16.859+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:34:16.885+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:34:16.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:34:16.939+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:34:16.938+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:34:16.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T18:34:49.150+0000] {processor.py:186} INFO - Started process (PID=5992) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:34:49.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:34:49.156+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:34:49.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:34:49.187+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:34:49.348+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:34:49.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:34:49.369+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:34:49.368+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:34:49.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.246 seconds
[2025-01-02T18:35:22.591+0000] {processor.py:186} INFO - Started process (PID=6018) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:35:22.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:35:22.594+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:35:22.594+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:35:22.613+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:35:22.676+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:35:22.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:35:22.696+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:35:22.696+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:35:22.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2025-01-02T18:35:55.874+0000] {processor.py:186} INFO - Started process (PID=6045) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:35:55.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:35:55.877+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:35:55.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:35:55.893+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:35:55.917+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:35:55.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:35:55.979+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:35:55.979+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:35:56.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.131 seconds
[2025-01-02T18:36:27.993+0000] {processor.py:186} INFO - Started process (PID=6070) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:36:27.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:36:27.998+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:36:27.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:36:28.014+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:36:28.058+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:36:28.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:36:28.079+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:36:28.078+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:36:28.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.111 seconds
[2025-01-02T18:37:01.297+0000] {processor.py:186} INFO - Started process (PID=6096) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:37:01.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:37:01.301+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:37:01.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:37:01.317+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:37:01.340+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:37:01.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:37:01.400+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:37:01.400+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:37:01.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2025-01-02T18:37:34.471+0000] {processor.py:186} INFO - Started process (PID=6122) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:37:34.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:37:34.474+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:37:34.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:37:34.491+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:37:34.517+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:37:34.516+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:37:34.536+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:37:34.536+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:37:34.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2025-01-02T18:38:06.767+0000] {processor.py:186} INFO - Started process (PID=6148) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:38:06.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:38:06.770+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:38:06.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:38:06.786+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:38:06.810+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:38:06.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:38:06.832+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:38:06.832+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:38:06.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.140 seconds
[2025-01-02T18:38:40.026+0000] {processor.py:186} INFO - Started process (PID=6175) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:38:40.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:38:40.029+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:38:40.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:38:40.046+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:38:40.092+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:38:40.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:38:40.114+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:38:40.114+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:38:40.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2025-01-02T18:39:13.260+0000] {processor.py:186} INFO - Started process (PID=6202) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:39:13.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:39:13.266+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:39:13.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:39:13.286+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:39:13.339+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:39:13.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:39:13.360+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:39:13.359+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:39:13.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.173 seconds
[2025-01-02T18:39:45.512+0000] {processor.py:186} INFO - Started process (PID=6229) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:39:45.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:39:45.526+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:39:45.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:39:45.546+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:39:45.572+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:39:45.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:39:45.645+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:39:45.644+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:39:45.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.162 seconds
[2025-01-02T18:40:18.802+0000] {processor.py:186} INFO - Started process (PID=6256) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:40:18.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:40:18.805+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:40:18.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:40:18.824+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:40:18.846+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:40:18.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:40:18.866+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:40:18.866+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:40:18.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2025-01-02T18:40:52.183+0000] {processor.py:186} INFO - Started process (PID=6282) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:40:52.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:40:52.186+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:40:52.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:40:52.201+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:40:52.222+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:40:52.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:40:52.244+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:40:52.243+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:40:52.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2025-01-02T18:41:24.359+0000] {processor.py:186} INFO - Started process (PID=6302) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:41:24.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:41:24.362+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:41:24.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:41:24.382+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:41:24.448+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:41:24.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:41:24.472+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:41:24.471+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:41:24.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.186 seconds
[2025-01-02T18:41:57.636+0000] {processor.py:186} INFO - Started process (PID=6328) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:41:57.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:41:57.645+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:41:57.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:41:57.678+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:41:57.774+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:41:57.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:41:57.842+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:41:57.842+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:41:57.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.237 seconds
[2025-01-02T18:42:28.321+0000] {processor.py:186} INFO - Started process (PID=6354) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:42:28.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:42:28.324+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:42:28.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:42:30.036+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:42:30.065+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:42:30.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:42:30.155+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:42:30.154+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:42:30.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.168 seconds
[2025-01-02T18:43:03.428+0000] {processor.py:186} INFO - Started process (PID=6380) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:43:03.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:43:03.430+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:43:03.430+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:43:03.445+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:43:03.506+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:43:03.506+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:43:03.528+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:43:03.528+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:43:03.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.191 seconds
[2025-01-02T18:43:36.835+0000] {processor.py:186} INFO - Started process (PID=6406) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:43:36.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:43:36.853+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:43:36.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:43:36.874+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:43:36.973+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:43:36.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:43:36.994+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:43:36.994+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:43:37.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.252 seconds
[2025-01-02T18:44:09.219+0000] {processor.py:186} INFO - Started process (PID=6432) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:44:09.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:44:09.222+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:44:09.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:44:09.239+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:44:09.259+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:44:09.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:44:09.283+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:44:09.282+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:44:09.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2025-01-02T18:44:42.355+0000] {processor.py:186} INFO - Started process (PID=6459) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:44:42.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:44:42.358+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:44:42.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:44:42.373+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:44:42.395+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:44:42.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:44:42.449+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:44:42.449+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:44:42.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2025-01-02T18:45:13.005+0000] {processor.py:186} INFO - Started process (PID=6485) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:45:13.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:45:13.008+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:45:13.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:45:14.720+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:45:14.744+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:45:14.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:45:14.808+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:45:14.808+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:45:14.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T18:45:47.907+0000] {processor.py:186} INFO - Started process (PID=6511) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:45:47.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:45:47.910+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:45:47.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:45:47.925+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:45:47.959+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:45:47.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:45:47.978+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:45:47.977+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:45:48.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2025-01-02T18:46:21.133+0000] {processor.py:186} INFO - Started process (PID=6537) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:46:21.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:46:21.136+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:46:21.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:46:21.152+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:46:21.180+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:46:21.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:46:21.248+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:46:21.247+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:46:21.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.140 seconds
[2025-01-02T18:46:52.655+0000] {processor.py:186} INFO - Started process (PID=6563) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:46:52.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:46:52.658+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:46:52.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:46:52.675+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:46:52.699+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:46:52.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:46:52.756+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:46:52.755+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:46:52.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T18:47:23.108+0000] {processor.py:186} INFO - Started process (PID=6590) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:47:23.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:47:23.111+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:47:23.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:47:23.128+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:47:23.155+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:47:23.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:47:23.177+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:47:23.177+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:47:23.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.138 seconds
[2025-01-02T18:47:53.829+0000] {processor.py:186} INFO - Started process (PID=6615) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:47:53.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:47:53.832+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:47:53.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:47:53.848+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:47:53.872+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:47:53.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:47:53.933+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:47:53.932+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:47:53.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2025-01-02T18:48:24.241+0000] {processor.py:186} INFO - Started process (PID=6641) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:48:24.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:48:24.244+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:48:24.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:48:24.261+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:48:24.295+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:48:24.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:48:24.316+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:48:24.316+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:48:24.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2025-01-02T18:48:54.499+0000] {processor.py:186} INFO - Started process (PID=6670) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:48:54.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:48:54.506+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:48:54.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:48:54.533+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:48:54.633+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:48:54.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:48:54.705+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:48:54.704+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:48:54.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.237 seconds
[2025-01-02T18:49:24.823+0000] {processor.py:186} INFO - Started process (PID=6693) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:49:24.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:49:24.826+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:49:24.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:49:24.872+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:49:24.901+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:49:24.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:49:24.975+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:49:24.975+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:49:24.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.184 seconds
[2025-01-02T18:49:55.179+0000] {processor.py:186} INFO - Started process (PID=6713) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:49:55.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:49:55.182+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:49:55.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:49:55.207+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:49:55.231+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:49:55.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:49:55.255+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:49:55.254+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:49:55.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2025-01-02T18:50:25.509+0000] {processor.py:186} INFO - Started process (PID=6739) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:50:25.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:50:25.512+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:50:25.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:50:25.527+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:50:25.568+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:50:25.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:50:25.589+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:50:25.588+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:50:25.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2025-01-02T18:50:55.780+0000] {processor.py:186} INFO - Started process (PID=6765) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:50:55.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:50:55.783+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:50:55.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:50:55.799+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:50:55.823+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:50:55.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:50:55.844+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:50:55.843+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:50:55.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T18:51:26.015+0000] {processor.py:186} INFO - Started process (PID=6791) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:51:26.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:51:26.018+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:51:26.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:51:26.061+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:51:26.086+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:51:26.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:51:26.110+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:51:26.109+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:51:26.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.166 seconds
[2025-01-02T18:51:56.372+0000] {processor.py:186} INFO - Started process (PID=6817) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:51:56.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:51:56.380+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:51:56.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:51:56.408+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:51:56.430+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:51:56.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:51:56.450+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:51:56.450+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:51:56.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2025-01-02T18:52:26.567+0000] {processor.py:186} INFO - Started process (PID=6843) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:52:26.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:52:26.570+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:52:26.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:52:26.585+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:52:26.606+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:52:26.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:52:26.667+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:52:26.667+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:52:26.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T18:52:56.895+0000] {processor.py:186} INFO - Started process (PID=6864) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:52:56.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:52:56.899+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:52:56.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:52:56.984+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:52:57.082+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:52:57.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:52:57.104+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:52:57.104+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:52:57.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.307 seconds
[2025-01-02T18:53:29.348+0000] {processor.py:186} INFO - Started process (PID=6890) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:53:29.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:53:29.351+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:53:29.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:53:29.366+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:53:29.386+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:53:29.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:53:29.449+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:53:29.448+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:53:29.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T18:54:01.598+0000] {processor.py:186} INFO - Started process (PID=6915) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:54:01.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:54:01.601+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:54:01.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:54:01.617+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:54:01.670+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:54:01.670+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:54:01.692+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:54:01.692+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:54:01.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2025-01-02T18:54:34.826+0000] {processor.py:186} INFO - Started process (PID=6941) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:54:34.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:54:34.829+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:54:34.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:54:34.848+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:54:34.877+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:54:34.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:54:34.944+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:54:34.944+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:54:34.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.150 seconds
[2025-01-02T18:55:08.129+0000] {processor.py:186} INFO - Started process (PID=6967) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:55:08.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:55:08.132+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:55:08.132+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:55:08.148+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:55:08.170+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:55:08.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:55:08.190+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:55:08.190+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:55:08.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2025-01-02T18:55:38.532+0000] {processor.py:186} INFO - Started process (PID=6993) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:55:40.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:55:40.227+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:55:40.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:55:40.243+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:55:40.277+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:55:40.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:55:40.302+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:55:40.302+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:55:40.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2025-01-02T18:56:13.575+0000] {processor.py:186} INFO - Started process (PID=7019) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:56:13.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:56:13.578+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:56:13.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:56:13.593+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:56:13.614+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:56:13.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:56:13.632+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:56:13.632+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:56:13.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.083 seconds
[2025-01-02T18:56:46.785+0000] {processor.py:186} INFO - Started process (PID=7046) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:56:46.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:56:46.787+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:56:46.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:56:46.805+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:56:46.831+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:56:46.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:56:46.886+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:56:46.885+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:56:46.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T18:57:19.052+0000] {processor.py:186} INFO - Started process (PID=7072) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:57:19.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:57:19.055+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:57:19.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:57:19.076+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:57:19.101+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:57:19.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:57:19.165+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:57:19.165+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:57:19.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.141 seconds
[2025-01-02T18:57:52.361+0000] {processor.py:186} INFO - Started process (PID=7098) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:57:52.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:57:52.364+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:57:52.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:57:52.378+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:57:52.400+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:57:52.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:57:52.420+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:57:52.419+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:57:52.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.083 seconds
[2025-01-02T18:58:25.556+0000] {processor.py:186} INFO - Started process (PID=7124) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:58:25.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:58:25.558+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:58:25.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:58:25.572+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:58:25.594+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:58:25.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:58:25.616+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:58:25.615+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:58:25.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2025-01-02T18:58:57.852+0000] {processor.py:186} INFO - Started process (PID=7150) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:58:57.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:58:57.855+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:58:57.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:58:57.870+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:58:57.890+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:58:57.890+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:58:57.910+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:58:57.909+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:58:57.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.120 seconds
[2025-01-02T18:59:30.992+0000] {processor.py:186} INFO - Started process (PID=7175) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:59:30.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T18:59:30.995+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:59:30.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:59:31.011+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T18:59:31.033+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:59:31.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T18:59:31.060+0000] {logging_mixin.py:190} INFO - [2025-01-02T18:59:31.059+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 17:00:00+00:00, run_after=2025-01-02 18:00:00+00:00
[2025-01-02T18:59:31.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2025-01-02T19:00:04.170+0000] {processor.py:186} INFO - Started process (PID=7205) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:00:04.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:00:04.173+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:00:04.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:00:04.189+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:00:04.213+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:00:04.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:00:04.287+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:00:04.286+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:00:04.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2025-01-02T19:00:36.493+0000] {processor.py:186} INFO - Started process (PID=7233) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:00:36.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:00:36.496+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:00:36.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:00:36.513+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:00:36.583+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:00:36.583+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:00:36.603+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:00:36.603+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:00:36.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2025-01-02T19:01:09.891+0000] {processor.py:186} INFO - Started process (PID=7259) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:01:09.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:01:09.894+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:01:09.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:01:09.929+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:01:09.998+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:01:09.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:01:10.021+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:01:10.020+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:01:10.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.158 seconds
[2025-01-02T19:01:42.301+0000] {processor.py:186} INFO - Started process (PID=7285) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:01:42.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:01:42.303+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:01:42.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:01:42.319+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:01:42.362+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:01:42.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:01:42.384+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:01:42.384+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:01:42.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.111 seconds
[2025-01-02T19:02:15.377+0000] {processor.py:186} INFO - Started process (PID=7311) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:02:15.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:02:15.381+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:02:15.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:02:15.398+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:02:15.467+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:02:15.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:02:15.575+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:02:15.575+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:02:15.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.229 seconds
[2025-01-02T19:02:48.697+0000] {processor.py:186} INFO - Started process (PID=7338) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:02:48.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:02:48.700+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:02:48.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:02:48.715+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:02:48.777+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:02:48.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:02:48.798+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:02:48.798+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:02:48.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T19:03:21.035+0000] {processor.py:186} INFO - Started process (PID=7364) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:03:21.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:03:21.038+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:03:21.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:03:21.054+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:03:21.086+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:03:21.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:03:21.108+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:03:21.108+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:03:21.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.161 seconds
[2025-01-02T19:03:54.331+0000] {processor.py:186} INFO - Started process (PID=7390) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:03:54.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:03:54.335+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:03:54.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:03:54.354+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:03:54.394+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:03:54.394+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:03:54.418+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:03:54.418+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:03:54.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.174 seconds
[2025-01-02T19:04:27.536+0000] {processor.py:186} INFO - Started process (PID=7416) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:04:27.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:04:27.540+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:04:27.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:04:27.562+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:04:27.595+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:04:27.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:04:27.682+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:04:27.681+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:04:27.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.175 seconds
[2025-01-02T19:04:59.707+0000] {processor.py:186} INFO - Started process (PID=7443) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:04:59.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:04:59.710+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:04:59.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:04:59.725+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:04:59.749+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:04:59.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:04:59.812+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:04:59.812+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:04:59.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2025-01-02T19:05:32.873+0000] {processor.py:186} INFO - Started process (PID=7469) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:05:32.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:05:32.876+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:05:32.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:05:32.891+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:05:32.915+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:05:32.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:05:32.938+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:05:32.938+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:05:33.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.147 seconds
[2025-01-02T19:06:06.294+0000] {processor.py:186} INFO - Started process (PID=7495) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:06:06.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:06:06.296+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:06:06.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:06:06.311+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:06:06.335+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:06:06.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:06:06.354+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:06:06.354+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:06:06.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.132 seconds
[2025-01-02T19:06:38.331+0000] {processor.py:186} INFO - Started process (PID=7521) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:06:38.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:06:38.334+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:06:38.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:06:38.356+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:06:38.409+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:06:38.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:06:38.431+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:06:38.431+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:06:38.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.123 seconds
[2025-01-02T19:07:11.623+0000] {processor.py:186} INFO - Started process (PID=7548) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:07:11.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:07:11.625+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:07:11.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:07:11.640+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:07:11.661+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:07:11.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:07:11.680+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:07:11.680+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:07:11.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T19:07:44.856+0000] {processor.py:186} INFO - Started process (PID=7574) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:07:44.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:07:44.859+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:07:44.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:07:44.877+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:07:44.901+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:07:44.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:07:44.956+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:07:44.956+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:07:44.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2025-01-02T19:08:17.214+0000] {processor.py:186} INFO - Started process (PID=7600) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:08:17.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:08:17.216+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:08:17.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:08:17.230+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:08:17.251+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:08:17.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:08:17.273+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:08:17.273+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:08:17.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2025-01-02T19:08:50.292+0000] {processor.py:186} INFO - Started process (PID=7626) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:08:50.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:08:50.295+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:08:50.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:08:50.310+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:08:50.353+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:08:50.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:08:50.375+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:08:50.374+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:08:50.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2025-01-02T19:09:23.564+0000] {processor.py:186} INFO - Started process (PID=7652) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:09:23.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:09:23.567+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:09:23.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:09:23.581+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:09:23.602+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:09:23.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:09:23.662+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:09:23.662+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:09:23.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2025-01-02T19:09:54.152+0000] {processor.py:186} INFO - Started process (PID=7677) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:09:54.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:09:54.155+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:09:54.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:09:54.173+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:09:54.197+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:09:54.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:09:54.222+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:09:54.222+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:09:54.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2025-01-02T19:10:24.396+0000] {processor.py:186} INFO - Started process (PID=7703) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:10:24.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:10:24.399+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:10:24.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:10:24.413+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:10:24.438+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:10:24.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:10:24.458+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:10:24.458+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:10:24.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.137 seconds
[2025-01-02T19:10:55.161+0000] {processor.py:186} INFO - Started process (PID=7729) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:10:55.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:10:55.164+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:10:55.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:10:55.178+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:10:55.210+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:10:55.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:10:55.229+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:10:55.229+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:10:55.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2025-01-02T19:11:25.342+0000] {processor.py:186} INFO - Started process (PID=7755) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:11:25.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:11:25.346+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:11:25.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:11:25.363+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:11:25.387+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:11:25.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:11:25.408+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:11:25.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:11:25.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2025-01-02T19:11:55.606+0000] {processor.py:186} INFO - Started process (PID=7775) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:11:55.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:11:55.609+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:11:55.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:11:55.627+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:11:55.652+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:11:55.652+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:11:55.715+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:11:55.715+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:11:55.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.132 seconds
[2025-01-02T19:12:25.845+0000] {processor.py:186} INFO - Started process (PID=7801) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:12:25.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:12:25.848+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:12:25.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:12:25.864+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:12:25.896+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:12:25.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:12:25.916+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:12:25.916+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:12:25.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2025-01-02T19:12:56.066+0000] {processor.py:186} INFO - Started process (PID=7828) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:12:56.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:12:56.069+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:12:56.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:12:56.083+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:12:56.104+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:12:56.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:12:56.124+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:12:56.123+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:12:56.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.082 seconds
[2025-01-02T19:13:26.298+0000] {processor.py:186} INFO - Started process (PID=7853) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:13:26.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:13:26.301+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:13:26.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:13:26.315+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:13:26.365+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:13:26.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:13:26.385+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:13:26.385+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:13:26.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2025-01-02T19:13:56.622+0000] {processor.py:186} INFO - Started process (PID=7881) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:13:56.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:13:56.625+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:13:56.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:13:56.719+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:13:56.810+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:13:56.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:13:56.912+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:13:56.912+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:13:56.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.319 seconds
[2025-01-02T19:14:27.108+0000] {processor.py:186} INFO - Started process (PID=7906) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:14:27.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:14:27.113+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:14:27.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:14:27.138+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:14:27.190+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:14:27.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:14:27.211+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:14:27.211+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:14:27.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T19:14:57.381+0000] {processor.py:186} INFO - Started process (PID=7925) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:14:57.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:14:57.384+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:14:57.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:14:57.399+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:14:57.421+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:14:57.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:14:57.481+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:14:57.480+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:14:57.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2025-01-02T19:15:27.643+0000] {processor.py:186} INFO - Started process (PID=7951) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:15:27.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:15:27.646+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:15:27.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:15:27.671+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:15:27.696+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:15:27.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:15:27.716+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:15:27.716+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:15:27.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.148 seconds
[2025-01-02T19:15:58.047+0000] {processor.py:186} INFO - Started process (PID=7977) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:15:58.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:15:58.049+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:15:58.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:15:58.064+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:15:58.105+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:15:58.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:15:58.125+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:15:58.125+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:15:58.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2025-01-02T19:16:31.183+0000] {processor.py:186} INFO - Started process (PID=8003) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:16:31.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:16:31.186+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:16:31.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:16:31.202+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:16:31.226+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:16:31.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:16:31.250+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:16:31.250+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:16:31.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.137 seconds
[2025-01-02T19:17:04.470+0000] {processor.py:186} INFO - Started process (PID=8029) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:17:04.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:17:04.473+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:17:04.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:17:04.490+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:17:04.514+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:17:04.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:17:04.534+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:17:04.534+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:17:04.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2025-01-02T19:17:36.820+0000] {processor.py:186} INFO - Started process (PID=8056) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:17:36.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:17:36.823+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:17:36.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:17:36.838+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:17:36.861+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:17:36.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:17:36.882+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:17:36.882+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:17:36.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.086 seconds
[2025-01-02T19:18:10.000+0000] {processor.py:186} INFO - Started process (PID=8081) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:18:10.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:18:10.003+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:18:10.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:18:10.019+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:18:10.041+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:18:10.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:18:10.102+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:18:10.101+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:18:10.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2025-01-02T19:18:43.285+0000] {processor.py:186} INFO - Started process (PID=8107) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:18:43.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:18:43.287+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:18:43.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:18:43.303+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:18:43.325+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:18:43.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:18:43.346+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:18:43.346+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:18:43.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T19:19:15.584+0000] {processor.py:186} INFO - Started process (PID=8132) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:19:15.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:19:15.587+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:19:15.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:19:15.602+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:19:15.624+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:19:15.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:19:15.642+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:19:15.642+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:19:15.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.221 seconds
[2025-01-02T19:19:48.760+0000] {processor.py:186} INFO - Started process (PID=8158) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:19:48.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:19:48.764+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:19:48.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:19:48.788+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:19:48.826+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:19:48.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:19:48.908+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:19:48.907+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:19:48.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.172 seconds
[2025-01-02T19:20:21.136+0000] {processor.py:186} INFO - Started process (PID=8183) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:20:21.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:20:21.139+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:20:21.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:20:21.155+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:20:21.178+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:20:21.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:20:21.198+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:20:21.198+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:20:21.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.088 seconds
[2025-01-02T19:20:54.288+0000] {processor.py:186} INFO - Started process (PID=8209) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:20:54.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:20:54.291+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:20:54.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:20:54.306+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:20:54.354+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:20:54.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:20:54.374+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:20:54.373+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:20:54.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2025-01-02T19:21:27.495+0000] {processor.py:186} INFO - Started process (PID=8236) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:21:27.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:21:27.498+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:21:27.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:21:27.512+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:21:27.546+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:21:27.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:21:27.566+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:21:27.566+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:21:27.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2025-01-02T19:22:00.761+0000] {processor.py:186} INFO - Started process (PID=8262) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:22:00.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:22:00.764+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:22:00.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:22:00.779+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:22:00.808+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:22:00.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:22:00.829+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:22:00.828+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:22:00.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2025-01-02T19:22:33.092+0000] {processor.py:186} INFO - Started process (PID=8288) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:22:33.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:22:33.095+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:22:33.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:22:33.110+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:22:33.147+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:22:33.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:22:33.167+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:22:33.167+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:22:33.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.100 seconds
[2025-01-02T19:23:06.217+0000] {processor.py:186} INFO - Started process (PID=8314) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:23:06.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:23:06.219+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:23:06.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:23:06.234+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:23:06.257+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:23:06.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:23:06.322+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:23:06.322+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:23:06.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.131 seconds
[2025-01-02T19:23:39.450+0000] {processor.py:186} INFO - Started process (PID=8340) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:23:39.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:23:39.453+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:23:39.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:23:39.468+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:23:39.522+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:23:39.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:23:39.540+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:23:39.540+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:23:39.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2025-01-02T19:24:11.660+0000] {processor.py:186} INFO - Started process (PID=8366) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:24:11.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:24:11.663+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:24:11.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:24:11.677+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:24:11.700+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:24:11.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:24:11.752+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:24:11.752+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:24:11.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2025-01-02T19:24:45.008+0000] {processor.py:186} INFO - Started process (PID=8392) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:24:45.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:24:45.011+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:24:45.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:24:45.026+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:24:45.047+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:24:45.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:24:45.065+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:24:45.065+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:24:45.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2025-01-02T19:25:18.158+0000] {processor.py:186} INFO - Started process (PID=8418) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:25:18.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:25:18.161+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:25:18.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:25:18.175+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:25:18.209+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:25:18.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:25:18.233+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:25:18.233+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:25:18.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.162 seconds
[2025-01-02T19:25:50.441+0000] {processor.py:186} INFO - Started process (PID=8444) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:25:50.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:25:50.444+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:25:50.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:25:50.458+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:25:50.481+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:25:50.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:25:50.508+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:25:50.508+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:25:50.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2025-01-02T19:26:23.600+0000] {processor.py:186} INFO - Started process (PID=8470) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:26:23.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:26:23.602+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:26:23.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:26:23.617+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:26:23.642+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:26:23.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:26:23.711+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:26:23.711+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:26:23.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.139 seconds
[2025-01-02T19:26:56.953+0000] {processor.py:186} INFO - Started process (PID=8497) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:26:56.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:26:56.955+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:26:56.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:26:56.971+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:26:56.992+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:26:56.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:26:57.011+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:26:57.011+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:26:57.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2025-01-02T19:27:29.196+0000] {processor.py:186} INFO - Started process (PID=8522) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:27:29.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:27:29.199+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:27:29.199+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:27:29.218+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:27:29.287+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:27:29.286+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:27:29.370+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:27:29.370+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:27:29.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.201 seconds
[2025-01-02T19:28:02.488+0000] {processor.py:186} INFO - Started process (PID=8548) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:28:02.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:28:02.490+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:28:02.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:28:02.506+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:28:02.553+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:28:02.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:28:02.571+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:28:02.571+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:28:02.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.147 seconds
[2025-01-02T19:28:35.668+0000] {processor.py:186} INFO - Started process (PID=8574) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:28:35.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:28:35.671+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:28:35.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:28:35.687+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:28:35.711+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:28:35.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:28:35.778+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:28:35.778+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:28:35.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T19:29:07.998+0000] {processor.py:186} INFO - Started process (PID=8600) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:29:07.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:29:08.000+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:29:08.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:29:08.014+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:29:08.035+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:29:08.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:29:08.057+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:29:08.056+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:29:08.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T19:29:41.133+0000] {processor.py:186} INFO - Started process (PID=8626) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:29:41.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:29:41.137+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:29:41.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:29:41.217+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:29:41.242+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:29:41.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:29:41.319+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:29:41.319+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:29:41.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.215 seconds
[2025-01-02T19:30:14.492+0000] {processor.py:186} INFO - Started process (PID=8652) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:30:14.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:30:14.495+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:30:14.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:30:14.510+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:30:14.564+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:30:14.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:30:14.583+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:30:14.583+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:30:14.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2025-01-02T19:30:46.698+0000] {processor.py:186} INFO - Started process (PID=8678) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:30:46.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:30:46.706+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:30:46.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:30:46.730+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:30:46.827+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:30:46.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:30:46.919+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:30:46.918+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:30:46.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.320 seconds
[2025-01-02T19:31:20.196+0000] {processor.py:186} INFO - Started process (PID=8704) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:31:20.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:31:20.200+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:31:20.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:31:20.221+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:31:20.259+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:31:20.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:31:20.282+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:31:20.282+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:31:20.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.155 seconds
[2025-01-02T19:31:52.377+0000] {processor.py:186} INFO - Started process (PID=8729) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:31:52.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:31:52.380+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:31:52.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:31:52.395+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:31:52.429+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:31:52.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:31:52.451+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:31:52.451+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:31:52.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2025-01-02T19:32:25.574+0000] {processor.py:186} INFO - Started process (PID=8755) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:32:25.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:32:25.576+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:32:25.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:32:25.593+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:32:25.616+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:32:25.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:32:25.679+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:32:25.679+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:32:25.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T19:32:58.758+0000] {processor.py:186} INFO - Started process (PID=8781) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:32:58.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:32:58.760+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:32:58.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:32:58.775+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:32:58.799+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:32:58.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:32:58.820+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:32:58.819+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:32:58.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T19:33:31.102+0000] {processor.py:186} INFO - Started process (PID=8807) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:33:31.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:33:31.105+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:33:31.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:33:31.121+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:33:31.157+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:33:31.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:33:31.179+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:33:31.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:33:31.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2025-01-02T19:34:04.415+0000] {processor.py:186} INFO - Started process (PID=8833) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:34:04.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:34:04.417+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:34:04.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:34:04.433+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:34:04.455+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:34:04.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:34:04.475+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:34:04.475+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:34:04.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T19:34:37.501+0000] {processor.py:186} INFO - Started process (PID=8859) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:34:37.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:34:37.503+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:34:37.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:34:37.518+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:34:37.561+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:34:37.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:34:37.580+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:34:37.579+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:34:37.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2025-01-02T19:35:09.792+0000] {processor.py:186} INFO - Started process (PID=8885) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:35:09.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:35:09.795+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:35:09.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:35:09.811+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:35:09.874+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:35:09.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:35:09.901+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:35:09.901+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:35:09.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.188 seconds
[2025-01-02T19:35:43.280+0000] {processor.py:186} INFO - Started process (PID=8911) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:35:43.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:35:43.283+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:35:43.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:35:43.297+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:35:43.353+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:35:43.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:35:43.371+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:35:43.371+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:35:43.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2025-01-02T19:36:15.547+0000] {processor.py:186} INFO - Started process (PID=8937) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:36:15.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:36:15.549+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:36:15.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:36:15.564+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:36:15.594+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:36:15.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:36:15.614+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:36:15.614+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:36:15.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.090 seconds
[2025-01-02T19:36:48.774+0000] {processor.py:186} INFO - Started process (PID=8963) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:36:48.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:36:48.777+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:36:48.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:36:48.793+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:36:48.847+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:36:48.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:36:48.865+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:36:48.865+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:36:48.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.160 seconds
[2025-01-02T19:37:22.101+0000] {processor.py:186} INFO - Started process (PID=8989) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:37:22.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:37:22.104+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:37:22.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:37:22.118+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:37:22.139+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:37:22.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:37:22.160+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:37:22.160+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:37:22.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.132 seconds
[2025-01-02T19:37:54.275+0000] {processor.py:186} INFO - Started process (PID=9015) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:37:54.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:37:54.278+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:37:54.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:37:54.297+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:37:54.356+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:37:54.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:37:54.433+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:37:54.433+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:37:54.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.187 seconds
[2025-01-02T19:38:27.687+0000] {processor.py:186} INFO - Started process (PID=9042) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:38:27.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:38:27.689+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:38:27.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:38:27.704+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:38:27.725+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:38:27.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:38:27.744+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:38:27.744+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:38:27.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2025-01-02T19:39:00.778+0000] {processor.py:186} INFO - Started process (PID=9067) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:39:00.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:39:00.781+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:39:00.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:39:00.796+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:39:00.817+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:39:00.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:39:00.836+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:39:00.835+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:39:00.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.128 seconds
[2025-01-02T19:39:33.086+0000] {processor.py:186} INFO - Started process (PID=9093) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:39:33.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:39:33.089+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:39:33.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:39:33.103+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:39:33.125+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:39:33.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:39:33.144+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:39:33.143+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:39:33.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.132 seconds
[2025-01-02T19:40:06.392+0000] {processor.py:186} INFO - Started process (PID=9119) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:40:06.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:40:06.395+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:40:06.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:40:06.409+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:40:06.432+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:40:06.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:40:06.450+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:40:06.450+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:40:06.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T19:40:37.047+0000] {processor.py:186} INFO - Started process (PID=9146) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:40:37.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:40:37.049+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:40:37.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:40:38.758+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:40:38.801+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:40:38.800+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:40:38.821+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:40:38.821+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:40:38.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2025-01-02T19:41:11.892+0000] {processor.py:186} INFO - Started process (PID=9172) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:41:11.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:41:11.895+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:41:11.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:41:11.909+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:41:11.974+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:41:11.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:41:11.994+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:41:11.994+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:41:12.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T19:41:45.194+0000] {processor.py:186} INFO - Started process (PID=9198) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:41:45.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:41:45.197+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:41:45.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:41:45.211+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:41:45.232+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:41:45.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:41:45.250+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:41:45.250+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:41:45.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2025-01-02T19:42:15.656+0000] {processor.py:186} INFO - Started process (PID=9224) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:42:15.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:42:15.659+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:42:15.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:42:17.367+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:42:17.401+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:42:17.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:42:17.420+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:42:17.420+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:42:17.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2025-01-02T19:42:50.685+0000] {processor.py:186} INFO - Started process (PID=9251) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:42:50.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:42:50.689+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:42:50.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:42:50.705+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:42:50.731+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:42:50.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:42:50.798+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:42:50.797+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:42:50.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T19:43:23.728+0000] {processor.py:186} INFO - Started process (PID=9277) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:43:23.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:43:23.731+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:43:23.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:43:23.746+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:43:23.781+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:43:23.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:43:23.800+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:43:23.800+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:43:23.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2025-01-02T19:43:55.243+0000] {processor.py:186} INFO - Started process (PID=9303) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:43:55.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:43:55.246+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:43:55.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:43:55.274+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:43:55.336+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:43:55.336+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:43:55.356+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:43:55.356+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:43:55.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.197 seconds
[2025-01-02T19:44:25.619+0000] {processor.py:186} INFO - Started process (PID=9329) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:44:25.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:44:25.622+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:44:25.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:44:25.637+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:44:25.659+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:44:25.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:44:25.676+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:44:25.676+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:44:25.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2025-01-02T19:44:56.318+0000] {processor.py:186} INFO - Started process (PID=9349) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:44:56.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:44:56.321+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:44:56.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:44:56.434+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:44:56.512+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:44:56.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:44:56.612+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:44:56.612+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:44:56.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.323 seconds
[2025-01-02T19:45:26.973+0000] {processor.py:186} INFO - Started process (PID=9375) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:45:26.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:45:26.978+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:45:26.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:45:27.070+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:45:27.181+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:45:27.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:45:27.286+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:45:27.286+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:45:27.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.415 seconds
[2025-01-02T19:45:57.492+0000] {processor.py:186} INFO - Started process (PID=9400) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:45:57.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:45:57.495+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:45:57.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:45:57.513+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:45:57.540+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:45:57.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:45:57.569+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:45:57.569+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:45:57.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.160 seconds
[2025-01-02T19:46:27.795+0000] {processor.py:186} INFO - Started process (PID=9426) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:46:27.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:46:27.799+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:46:27.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:46:27.819+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:46:27.884+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:46:27.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:46:27.964+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:46:27.964+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:46:27.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.201 seconds
[2025-01-02T19:46:58.318+0000] {processor.py:186} INFO - Started process (PID=9457) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:46:58.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:46:58.333+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:46:58.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:46:58.362+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:46:58.392+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:46:58.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:46:58.425+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:46:58.425+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:46:58.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2025-01-02T19:47:28.621+0000] {processor.py:186} INFO - Started process (PID=9496) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:47:28.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:47:28.624+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:47:28.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:47:28.639+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:47:28.661+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:47:28.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:47:28.682+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:47:28.681+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:47:28.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.083 seconds
[2025-01-02T19:47:58.884+0000] {processor.py:186} INFO - Started process (PID=9516) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:47:58.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:47:58.887+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:47:58.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:47:58.902+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:47:58.927+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:47:58.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:47:58.952+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:47:58.952+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:47:58.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2025-01-02T19:48:29.248+0000] {processor.py:186} INFO - Started process (PID=9550) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:48:29.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:48:29.251+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:48:29.251+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:48:29.269+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:48:29.291+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:48:29.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:48:29.310+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:48:29.310+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:48:29.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.086 seconds
[2025-01-02T19:48:59.479+0000] {processor.py:186} INFO - Started process (PID=9577) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:48:59.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:48:59.483+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:48:59.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:48:59.501+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:48:59.527+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:48:59.526+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:48:59.561+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:48:59.561+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:48:59.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2025-01-02T19:49:29.834+0000] {processor.py:186} INFO - Started process (PID=9604) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:49:29.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:49:29.837+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:49:29.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:49:29.856+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:49:29.887+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:49:29.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:49:29.909+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:49:29.908+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:49:29.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2025-01-02T19:50:00.150+0000] {processor.py:186} INFO - Started process (PID=9630) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:50:00.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:50:00.158+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:50:00.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:50:00.187+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:50:00.244+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:50:00.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:50:00.318+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:50:00.317+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:50:00.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.235 seconds
[2025-01-02T19:50:31.511+0000] {processor.py:186} INFO - Started process (PID=9651) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:50:31.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:50:31.514+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:50:31.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:50:31.532+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:50:31.589+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:50:31.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:50:31.613+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:50:31.613+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:50:31.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2025-01-02T19:51:04.908+0000] {processor.py:186} INFO - Started process (PID=9677) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:51:04.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:51:04.911+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:51:04.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:51:04.929+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:51:04.993+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:51:04.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:51:05.017+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:51:05.016+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:51:05.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.179 seconds
[2025-01-02T19:51:37.161+0000] {processor.py:186} INFO - Started process (PID=9703) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:51:37.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:51:37.164+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:51:37.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:51:37.179+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:51:37.203+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:51:37.203+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:51:37.221+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:51:37.221+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:51:37.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.087 seconds
[2025-01-02T19:52:10.405+0000] {processor.py:186} INFO - Started process (PID=9730) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:52:10.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:52:10.407+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:52:10.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:52:10.440+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:52:10.514+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:52:10.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:52:10.586+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:52:10.586+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:52:10.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.208 seconds
[2025-01-02T19:52:43.829+0000] {processor.py:186} INFO - Started process (PID=9756) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:52:43.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:52:43.831+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:52:43.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:52:43.846+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:52:43.866+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:52:43.866+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:52:43.926+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:52:43.926+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:52:43.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2025-01-02T19:53:15.964+0000] {processor.py:186} INFO - Started process (PID=9782) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:53:15.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:53:15.967+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:53:15.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:53:15.981+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:53:16.029+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:53:16.029+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:53:16.110+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:53:16.110+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:53:16.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.168 seconds
[2025-01-02T19:53:49.280+0000] {processor.py:186} INFO - Started process (PID=9808) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:53:49.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:53:49.306+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:53:49.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:53:49.328+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:53:49.409+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:53:49.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:53:49.489+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:53:49.489+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:53:49.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.235 seconds
[2025-01-02T19:54:22.493+0000] {processor.py:186} INFO - Started process (PID=9834) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:54:22.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:54:22.495+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:54:22.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:54:22.511+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:54:22.564+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:54:22.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:54:22.583+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:54:22.583+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:54:22.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.169 seconds
[2025-01-02T19:54:53.011+0000] {processor.py:186} INFO - Started process (PID=9854) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:54:53.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:54:53.014+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:54:53.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:54:54.722+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:54:54.750+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:54:54.750+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:54:54.802+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:54:54.802+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:54:54.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T19:55:28.039+0000] {processor.py:186} INFO - Started process (PID=9886) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:55:28.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:55:28.043+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:55:28.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:55:28.065+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:55:28.142+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:55:28.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:55:28.169+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:55:28.168+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:55:28.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.219 seconds
[2025-01-02T19:56:01.358+0000] {processor.py:186} INFO - Started process (PID=9912) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:56:01.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:56:01.362+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:56:01.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:56:01.377+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:56:01.399+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:56:01.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:56:01.423+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:56:01.423+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:56:01.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.089 seconds
[2025-01-02T19:56:33.696+0000] {processor.py:186} INFO - Started process (PID=9932) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:56:33.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:56:33.745+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:56:33.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:56:33.857+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:56:33.943+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:56:33.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:56:33.962+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:56:33.962+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:56:33.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.292 seconds
[2025-01-02T19:57:06.954+0000] {processor.py:186} INFO - Started process (PID=9958) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:57:07.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:57:07.009+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:57:07.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:57:07.110+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:57:07.217+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:57:07.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:57:07.313+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:57:07.313+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:57:07.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.386 seconds
[2025-01-02T19:57:39.454+0000] {processor.py:186} INFO - Started process (PID=9984) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:57:39.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:57:39.514+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:57:39.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:57:39.532+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:57:39.621+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:57:39.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:57:39.716+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:57:39.716+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:57:39.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.292 seconds
[2025-01-02T19:58:12.593+0000] {processor.py:186} INFO - Started process (PID=10010) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:58:12.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:58:12.596+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:58:12.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:58:12.612+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:58:12.698+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:58:12.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:58:12.791+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:58:12.791+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:58:12.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.298 seconds
[2025-01-02T19:58:46.154+0000] {processor.py:186} INFO - Started process (PID=10037) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:58:46.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:58:46.222+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:58:46.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:58:46.528+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:58:46.622+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:58:46.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:58:46.726+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:58:46.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:58:46.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.597 seconds
[2025-01-02T19:59:19.012+0000] {processor.py:186} INFO - Started process (PID=10063) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:59:19.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:59:19.082+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:59:19.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:59:19.182+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:59:19.209+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:59:19.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:59:19.304+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:59:19.304+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:59:19.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.384 seconds
[2025-01-02T19:59:51.170+0000] {processor.py:186} INFO - Started process (PID=10089) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:59:51.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T19:59:51.173+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:59:51.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:59:51.195+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T19:59:51.225+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:59:51.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T19:59:51.288+0000] {logging_mixin.py:190} INFO - [2025-01-02T19:59:51.287+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 18:00:00+00:00, run_after=2025-01-02 19:00:00+00:00
[2025-01-02T19:59:51.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2025-01-02T20:00:24.277+0000] {processor.py:186} INFO - Started process (PID=10121) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:00:24.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:00:24.280+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:00:24.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:00:24.293+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:00:24.337+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:00:24.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:00:24.357+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:00:24.357+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:00:24.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.107 seconds
[2025-01-02T20:00:57.460+0000] {processor.py:186} INFO - Started process (PID=10148) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:00:57.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:00:57.469+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:00:57.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:00:57.494+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:00:57.519+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:00:57.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:00:57.581+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:00:57.581+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:00:57.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.146 seconds
[2025-01-02T20:01:29.781+0000] {processor.py:186} INFO - Started process (PID=10173) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:01:29.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:01:29.784+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:01:29.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:01:29.799+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:01:29.832+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:01:29.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:01:29.853+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:01:29.852+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:01:29.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2025-01-02T20:02:02.935+0000] {processor.py:186} INFO - Started process (PID=10199) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:02:02.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:02:02.938+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:02:02.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:02:02.953+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:02:02.974+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:02:02.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:02:03.044+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:02:03.044+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:02:03.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.133 seconds
[2025-01-02T20:02:36.155+0000] {processor.py:186} INFO - Started process (PID=10225) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:02:36.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:02:36.158+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:02:36.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:02:36.173+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:02:36.196+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:02:36.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:02:36.217+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:02:36.217+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:02:36.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2025-01-02T20:03:09.332+0000] {processor.py:186} INFO - Started process (PID=10251) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:03:09.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:03:09.334+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:03:09.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:03:09.354+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:03:09.413+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:03:09.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:03:09.433+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:03:09.433+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:03:09.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T20:03:41.710+0000] {processor.py:186} INFO - Started process (PID=10276) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:03:41.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:03:41.715+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:03:41.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:03:41.732+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:03:41.791+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:03:41.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:03:41.812+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:03:41.811+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:03:41.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.178 seconds
[2025-01-02T20:04:15.054+0000] {processor.py:186} INFO - Started process (PID=10301) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:04:15.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:04:15.057+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:04:15.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:04:15.071+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:04:15.092+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:04:15.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:04:15.110+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:04:15.110+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:04:15.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2025-01-02T20:04:45.595+0000] {processor.py:186} INFO - Started process (PID=10327) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:04:45.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:04:45.598+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:04:45.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:04:45.611+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:04:45.632+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:04:45.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:04:45.650+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:04:45.650+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:04:45.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2025-01-02T20:05:16.054+0000] {processor.py:186} INFO - Started process (PID=10353) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:05:16.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:05:16.056+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:05:16.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:05:16.070+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:05:16.091+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:05:16.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:05:16.115+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:05:16.115+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:05:16.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.087 seconds
[2025-01-02T20:05:46.778+0000] {processor.py:186} INFO - Started process (PID=10379) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:05:46.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:05:46.781+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:05:46.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:05:46.796+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:05:46.851+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:05:46.851+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:05:46.874+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:05:46.874+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:05:46.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2025-01-02T20:06:17.177+0000] {processor.py:186} INFO - Started process (PID=10405) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:06:17.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:06:17.180+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:06:17.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:06:17.194+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:06:17.215+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:06:17.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:06:17.234+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:06:17.233+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:06:17.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2025-01-02T20:06:47.362+0000] {processor.py:186} INFO - Started process (PID=10431) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:06:47.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:06:47.364+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:06:47.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:06:47.379+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:06:47.402+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:06:47.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:06:47.462+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:06:47.462+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:06:47.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T20:07:17.569+0000] {processor.py:186} INFO - Started process (PID=10451) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:07:17.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:07:17.572+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:07:17.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:07:17.612+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:07:17.637+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:07:17.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:07:17.656+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:07:17.656+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:07:17.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.162 seconds
[2025-01-02T20:07:47.888+0000] {processor.py:186} INFO - Started process (PID=10477) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:07:47.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:07:47.891+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:07:47.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:07:47.904+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:07:47.948+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:07:47.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:07:47.966+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:07:47.966+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:07:48.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2025-01-02T20:08:18.199+0000] {processor.py:186} INFO - Started process (PID=10503) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:08:18.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:08:18.202+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:08:18.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:08:18.219+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:08:18.254+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:08:18.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:08:18.276+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:08:18.276+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:08:18.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2025-01-02T20:08:48.570+0000] {processor.py:186} INFO - Started process (PID=10529) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:08:48.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:08:48.576+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:08:48.575+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:08:48.601+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:08:48.661+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:08:48.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:08:48.684+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:08:48.684+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:08:48.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.191 seconds
[2025-01-02T20:09:18.785+0000] {processor.py:186} INFO - Started process (PID=10553) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:09:18.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:09:18.787+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:09:18.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:09:18.843+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:09:18.881+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:09:18.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:09:18.944+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:09:18.944+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:09:18.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.183 seconds
[2025-01-02T20:09:49.073+0000] {processor.py:186} INFO - Started process (PID=10579) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:09:49.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:09:49.077+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:09:49.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:09:49.099+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:09:49.188+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:09:49.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:09:49.273+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:09:49.273+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:09:49.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.301 seconds
[2025-01-02T20:10:19.540+0000] {processor.py:186} INFO - Started process (PID=10598) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:10:19.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:10:19.542+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:10:19.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:10:19.556+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:10:19.601+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:10:19.600+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:10:19.621+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:10:19.621+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:10:19.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2025-01-02T20:10:49.799+0000] {processor.py:186} INFO - Started process (PID=10624) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:10:49.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:10:49.803+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:10:49.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:10:49.821+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:10:49.845+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:10:49.845+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:10:49.909+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:10:49.909+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:10:49.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.138 seconds
[2025-01-02T20:11:23.001+0000] {processor.py:186} INFO - Started process (PID=10650) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:11:23.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:11:23.004+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:11:23.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:11:23.019+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:11:23.041+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:11:23.040+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:11:23.060+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:11:23.060+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:11:23.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2025-01-02T20:11:53.511+0000] {processor.py:186} INFO - Started process (PID=10676) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:11:53.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:11:53.514+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:11:53.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:11:53.532+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:11:53.558+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:11:53.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:11:53.578+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:11:53.578+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:11:53.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2025-01-02T20:12:23.921+0000] {processor.py:186} INFO - Started process (PID=10702) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:12:23.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:12:23.924+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:12:23.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:12:23.938+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:12:23.958+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:12:23.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:12:23.976+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:12:23.976+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:12:24.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2025-01-02T20:12:54.609+0000] {processor.py:186} INFO - Started process (PID=10728) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:12:54.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:12:54.612+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:12:54.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:12:54.626+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:12:54.651+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:12:54.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:12:54.669+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:12:54.669+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:12:54.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2025-01-02T20:13:24.887+0000] {processor.py:186} INFO - Started process (PID=10754) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:13:24.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:13:24.889+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:13:24.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:13:24.903+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:13:24.926+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:13:24.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:13:24.947+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:13:24.946+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:13:24.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.084 seconds
[2025-01-02T20:13:56.013+0000] {processor.py:186} INFO - Started process (PID=10781) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:13:56.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:13:56.016+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:13:56.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:13:56.037+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:13:56.098+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:13:56.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:13:56.175+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:13:56.174+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:13:56.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.193 seconds
[2025-01-02T20:14:26.364+0000] {processor.py:186} INFO - Started process (PID=10800) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:14:26.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:14:26.367+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:14:26.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:14:26.381+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:14:26.402+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:14:26.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:14:26.420+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:14:26.420+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:14:26.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.084 seconds
[2025-01-02T20:14:56.598+0000] {processor.py:186} INFO - Started process (PID=10831) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:14:56.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:14:56.601+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:14:56.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:14:56.615+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:14:56.637+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:14:56.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:14:56.655+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:14:56.655+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:14:56.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.081 seconds
[2025-01-02T20:15:26.909+0000] {processor.py:186} INFO - Started process (PID=10852) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:15:26.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:15:26.912+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:15:26.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:15:26.927+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:15:26.949+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:15:26.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:15:26.968+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:15:26.968+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:15:27.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.134 seconds
[2025-01-02T20:15:57.104+0000] {processor.py:186} INFO - Started process (PID=10877) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:15:57.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:15:57.107+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:15:57.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:15:57.122+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:15:57.147+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:15:57.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:15:57.166+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:15:57.165+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:15:57.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.086 seconds
[2025-01-02T20:16:27.371+0000] {processor.py:186} INFO - Started process (PID=10906) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:16:27.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:16:27.374+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:16:27.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:16:27.460+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:16:27.484+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:16:27.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:16:27.503+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:16:27.502+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:16:27.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.180 seconds
[2025-01-02T20:16:57.987+0000] {processor.py:186} INFO - Started process (PID=10928) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:16:57.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:16:57.990+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:16:57.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:16:58.007+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:16:58.086+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:16:58.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:16:58.111+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:16:58.110+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:16:58.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.238 seconds
[2025-01-02T20:17:28.726+0000] {processor.py:186} INFO - Started process (PID=10947) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:17:28.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:17:28.728+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:17:28.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:17:28.742+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:17:28.799+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:17:28.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:17:28.818+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:17:28.818+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:17:28.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.117 seconds
[2025-01-02T20:17:59.028+0000] {processor.py:186} INFO - Started process (PID=10972) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:17:59.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:17:59.031+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:17:59.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:17:59.045+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:17:59.066+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:17:59.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:17:59.085+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:17:59.085+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:17:59.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.082 seconds
[2025-01-02T20:18:30.239+0000] {processor.py:186} INFO - Started process (PID=10998) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:18:30.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:18:30.241+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:18:30.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:18:30.257+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:18:30.303+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:18:30.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:18:30.323+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:18:30.323+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:18:30.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.160 seconds
[2025-01-02T20:19:03.509+0000] {processor.py:186} INFO - Started process (PID=11024) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:19:03.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:19:03.511+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:19:03.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:19:03.525+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:19:03.588+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:19:03.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:19:03.609+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:19:03.609+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:19:03.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.188 seconds
[2025-01-02T20:19:35.676+0000] {processor.py:186} INFO - Started process (PID=11051) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:19:35.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:19:35.679+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:19:35.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:19:35.699+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:19:35.723+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:19:35.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:19:35.796+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:19:35.795+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:19:35.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.145 seconds
[2025-01-02T20:20:08.967+0000] {processor.py:186} INFO - Started process (PID=11076) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:20:08.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:20:08.970+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:20:08.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:20:08.983+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:20:09.006+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:20:09.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:20:09.024+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:20:09.024+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:20:09.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T20:20:42.167+0000] {processor.py:186} INFO - Started process (PID=11102) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:20:42.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:20:42.170+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:20:42.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:20:42.188+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:20:42.236+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:20:42.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:20:42.323+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:20:42.323+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:20:42.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.186 seconds
[2025-01-02T20:21:14.488+0000] {processor.py:186} INFO - Started process (PID=11128) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:21:14.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:21:14.491+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:21:14.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:21:14.506+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:21:14.530+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:21:14.530+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:21:14.551+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:21:14.551+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:21:14.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.089 seconds
[2025-01-02T20:21:47.571+0000] {processor.py:186} INFO - Started process (PID=11154) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:21:47.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:21:47.574+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:21:47.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:21:47.588+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:21:47.657+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:21:47.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:21:47.680+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:21:47.680+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:21:47.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.194 seconds
[2025-01-02T20:22:21.022+0000] {processor.py:186} INFO - Started process (PID=11180) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:22:21.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:22:21.025+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:22:21.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:22:21.070+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:22:21.093+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:22:21.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:22:21.114+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:22:21.114+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:22:21.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.160 seconds
[2025-01-02T20:22:53.431+0000] {processor.py:186} INFO - Started process (PID=11205) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:22:53.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:22:53.434+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:22:53.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:22:53.449+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:22:53.515+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:22:53.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:22:53.597+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:22:53.597+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:22:53.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.196 seconds
[2025-01-02T20:23:26.615+0000] {processor.py:186} INFO - Started process (PID=11231) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:23:26.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:23:26.618+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:23:26.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:23:26.633+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:23:26.710+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:23:26.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:23:26.792+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:23:26.792+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:23:26.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.201 seconds
[2025-01-02T20:23:58.981+0000] {processor.py:186} INFO - Started process (PID=11257) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:23:58.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:23:58.983+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:23:58.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:23:59.000+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:23:59.028+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:23:59.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:23:59.090+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:23:59.089+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:23:59.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T20:24:30.520+0000] {processor.py:186} INFO - Started process (PID=11283) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:24:30.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:24:30.523+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:24:30.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:24:30.539+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:24:30.561+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:24:30.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:24:30.581+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:24:30.581+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:24:30.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2025-01-02T20:25:00.776+0000] {processor.py:186} INFO - Started process (PID=11310) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:25:00.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:25:00.778+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:25:00.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:25:00.793+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:25:00.813+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:25:00.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:25:00.833+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:25:00.833+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:25:00.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.082 seconds
[2025-01-02T20:25:31.386+0000] {processor.py:186} INFO - Started process (PID=11336) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:25:31.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:25:31.388+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:25:31.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:25:31.408+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:25:31.431+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:25:31.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:25:31.487+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:25:31.487+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:25:31.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2025-01-02T20:26:01.737+0000] {processor.py:186} INFO - Started process (PID=11362) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:26:01.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:26:01.742+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:26:01.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:26:01.788+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:26:01.877+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:26:01.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:26:01.900+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:26:01.900+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:26:01.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.193 seconds
[2025-01-02T20:26:32.061+0000] {processor.py:186} INFO - Started process (PID=11381) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:26:32.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:26:32.064+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:26:32.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:26:32.079+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:26:32.152+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:26:32.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:26:32.202+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:26:32.202+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:26:32.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.207 seconds
[2025-01-02T20:27:02.663+0000] {processor.py:186} INFO - Started process (PID=11406) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:27:02.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:27:02.667+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:27:02.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:27:02.682+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:27:02.738+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:27:02.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:27:02.822+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:27:02.821+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:27:02.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.183 seconds
[2025-01-02T20:27:33.530+0000] {processor.py:186} INFO - Started process (PID=11432) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:27:33.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:27:33.533+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:27:33.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:27:33.548+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:27:33.569+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:27:33.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:27:33.588+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:27:33.588+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:27:33.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2025-01-02T20:28:03.729+0000] {processor.py:186} INFO - Started process (PID=11458) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:28:03.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:28:03.732+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:28:03.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:28:03.747+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:28:03.800+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:28:03.800+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:28:03.823+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:28:03.823+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:28:03.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.175 seconds
[2025-01-02T20:28:33.974+0000] {processor.py:186} INFO - Started process (PID=11483) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:28:33.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:28:33.977+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:28:33.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:28:33.991+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:28:34.034+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:28:34.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:28:34.053+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:28:34.053+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:28:34.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2025-01-02T20:29:04.191+0000] {processor.py:186} INFO - Started process (PID=11509) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:29:04.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:29:04.194+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:29:04.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:29:04.208+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:29:04.272+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:29:04.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:29:04.291+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:29:04.290+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:29:04.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.175 seconds
[2025-01-02T20:29:34.443+0000] {processor.py:186} INFO - Started process (PID=11529) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:29:34.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:29:34.447+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:29:34.446+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:29:34.466+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:29:34.511+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:29:34.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:29:34.534+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:29:34.533+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:29:34.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.162 seconds
[2025-01-02T20:30:04.691+0000] {processor.py:186} INFO - Started process (PID=11555) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:30:04.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:30:04.694+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:30:04.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:30:04.710+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:30:04.736+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:30:04.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:30:04.799+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:30:04.799+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:30:04.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T20:30:35.018+0000] {processor.py:186} INFO - Started process (PID=11581) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:30:35.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:30:35.021+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:30:35.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:30:35.041+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:30:35.071+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:30:35.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:30:35.139+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:30:35.139+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:30:35.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.150 seconds
[2025-01-02T20:31:06.289+0000] {processor.py:186} INFO - Started process (PID=11607) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:31:06.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:31:06.291+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:31:06.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:31:06.306+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:31:06.443+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:31:06.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:31:06.464+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:31:06.464+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:31:06.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.198 seconds
[2025-01-02T20:31:39.756+0000] {processor.py:186} INFO - Started process (PID=11633) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:31:39.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:31:39.759+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:31:39.759+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:31:39.773+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:31:39.799+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:31:39.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:31:39.910+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:31:39.910+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:31:39.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.242 seconds
[2025-01-02T20:32:12.061+0000] {processor.py:186} INFO - Started process (PID=11659) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:32:12.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:32:12.064+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:32:12.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:32:12.079+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:32:12.125+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:32:12.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:32:12.152+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:32:12.151+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:32:12.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.165 seconds
[2025-01-02T20:32:45.347+0000] {processor.py:186} INFO - Started process (PID=11684) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:32:45.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:32:45.351+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:32:45.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:32:45.377+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:32:45.411+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:32:45.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:32:45.472+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:32:45.471+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:32:45.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.152 seconds
[2025-01-02T20:33:17.730+0000] {processor.py:186} INFO - Started process (PID=11710) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:33:17.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:33:17.733+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:33:17.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:33:17.749+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:33:17.773+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:33:17.772+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:33:17.796+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:33:17.796+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:33:17.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.154 seconds
[2025-01-02T20:33:51.124+0000] {processor.py:186} INFO - Started process (PID=11737) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:33:51.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:33:51.127+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:33:51.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:33:51.144+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:33:51.169+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:33:51.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:33:51.231+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:33:51.231+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:33:51.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2025-01-02T20:34:23.384+0000] {processor.py:186} INFO - Started process (PID=11763) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:34:23.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:34:23.387+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:34:23.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:34:23.401+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:34:23.460+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:34:23.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:34:23.482+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:34:23.482+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:34:23.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.163 seconds
[2025-01-02T20:34:56.738+0000] {processor.py:186} INFO - Started process (PID=11789) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:34:56.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:34:56.741+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:34:56.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:34:56.755+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:34:56.787+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:34:56.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:34:56.806+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:34:56.805+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:34:56.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2025-01-02T20:35:30.027+0000] {processor.py:186} INFO - Started process (PID=11815) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:35:30.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:35:30.030+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:35:30.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:35:30.046+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:35:30.067+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:35:30.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:35:30.131+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:35:30.130+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:35:30.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2025-01-02T20:36:02.409+0000] {processor.py:186} INFO - Started process (PID=11842) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:36:02.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:36:02.412+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:36:02.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:36:02.427+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:36:02.470+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:36:02.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:36:02.490+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:36:02.490+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:36:02.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2025-01-02T20:36:35.473+0000] {processor.py:186} INFO - Started process (PID=11868) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:36:35.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:36:35.475+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:36:35.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:36:35.490+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:36:35.512+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:36:35.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:36:35.573+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:36:35.573+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:36:35.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.144 seconds
[2025-01-02T20:37:08.728+0000] {processor.py:186} INFO - Started process (PID=11894) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:37:08.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:37:08.732+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:37:08.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:37:08.750+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:37:08.819+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:37:08.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:37:08.842+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:37:08.841+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:37:08.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.142 seconds
[2025-01-02T20:37:39.202+0000] {processor.py:186} INFO - Started process (PID=11920) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:37:39.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:37:39.206+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:37:39.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:37:39.222+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:37:39.296+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:37:39.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:37:39.322+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:37:39.322+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:37:39.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.150 seconds
[2025-01-02T20:38:09.652+0000] {processor.py:186} INFO - Started process (PID=11947) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:38:09.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:38:09.655+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:38:09.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:38:09.672+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:38:09.694+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:38:09.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:38:09.754+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:38:09.754+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:38:09.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T20:38:40.356+0000] {processor.py:186} INFO - Started process (PID=11972) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:38:40.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:38:40.359+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:38:40.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:38:40.377+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:38:40.410+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:38:40.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:38:40.485+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:38:40.485+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:38:40.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.165 seconds
[2025-01-02T20:39:10.698+0000] {processor.py:186} INFO - Started process (PID=11993) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:39:10.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:39:10.701+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:39:10.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:39:10.716+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:39:10.761+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:39:10.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:39:10.778+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:39:10.778+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:39:10.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2025-01-02T20:39:40.976+0000] {processor.py:186} INFO - Started process (PID=12019) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:39:40.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:39:40.980+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:39:40.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:39:40.994+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:39:41.016+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:39:41.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:39:41.080+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:39:41.080+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:39:41.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2025-01-02T20:40:11.267+0000] {processor.py:186} INFO - Started process (PID=12045) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:40:11.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:40:11.341+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:40:11.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:40:11.365+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:40:11.458+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:40:11.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:40:11.552+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:40:11.552+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:40:11.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.383 seconds
[2025-01-02T20:40:41.742+0000] {processor.py:186} INFO - Started process (PID=12070) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:40:41.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:40:41.744+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:40:41.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:40:41.759+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:40:41.814+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:40:41.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:40:41.834+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:40:41.834+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:40:41.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.117 seconds
[2025-01-02T20:41:11.925+0000] {processor.py:186} INFO - Started process (PID=12097) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:41:11.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:41:11.927+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:41:11.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:41:11.943+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:41:11.980+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:41:11.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:41:12.054+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:41:12.054+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:41:12.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.154 seconds
[2025-01-02T20:41:43.053+0000] {processor.py:186} INFO - Started process (PID=12123) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:41:43.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:41:43.056+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:41:43.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:41:43.070+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:41:43.090+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:41:43.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:41:43.144+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:41:43.144+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:41:43.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2025-01-02T20:42:13.320+0000] {processor.py:186} INFO - Started process (PID=12143) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:42:13.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:42:13.323+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:42:13.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:42:13.338+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:42:13.359+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:42:13.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:42:13.379+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:42:13.378+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:42:13.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2025-01-02T20:42:43.552+0000] {processor.py:186} INFO - Started process (PID=12168) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:42:43.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:42:43.555+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:42:43.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:42:43.571+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:42:43.605+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:42:43.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:42:43.625+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:42:43.625+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:42:43.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.145 seconds
[2025-01-02T20:43:13.807+0000] {processor.py:186} INFO - Started process (PID=12194) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:43:13.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:43:13.810+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:43:13.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:43:13.824+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:43:13.877+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:43:13.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:43:13.898+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:43:13.898+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:43:13.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.116 seconds
[2025-01-02T20:43:44.793+0000] {processor.py:186} INFO - Started process (PID=12219) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:43:44.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:43:44.795+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:43:44.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:43:44.811+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:43:44.833+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:43:44.833+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:43:44.853+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:43:44.853+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:43:44.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2025-01-02T20:44:15.045+0000] {processor.py:186} INFO - Started process (PID=12245) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:44:15.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:44:15.048+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:44:15.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:44:15.062+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:44:15.115+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:44:15.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:44:15.136+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:44:15.135+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:44:15.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.120 seconds
[2025-01-02T20:44:48.208+0000] {processor.py:186} INFO - Started process (PID=12271) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:44:48.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:44:48.211+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:44:48.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:44:48.226+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:44:48.303+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:44:48.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:44:48.323+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:44:48.323+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:44:48.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.141 seconds
[2025-01-02T20:45:21.532+0000] {processor.py:186} INFO - Started process (PID=12297) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:45:21.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:45:21.535+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:45:21.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:45:21.551+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:45:21.573+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:45:21.573+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:45:21.593+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:45:21.593+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:45:21.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.086 seconds
[2025-01-02T20:45:53.626+0000] {processor.py:186} INFO - Started process (PID=12323) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:45:53.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:45:53.629+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:45:53.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:45:53.643+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:45:53.664+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:45:53.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:45:53.724+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:45:53.724+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:45:53.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2025-01-02T20:46:26.787+0000] {processor.py:186} INFO - Started process (PID=12349) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:46:26.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:46:26.790+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:46:26.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:46:26.804+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:46:26.836+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:46:26.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:46:26.857+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:46:26.857+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:46:26.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2025-01-02T20:47:00.006+0000] {processor.py:186} INFO - Started process (PID=12375) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:47:00.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:47:00.009+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:47:00.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:47:00.025+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:47:00.047+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:47:00.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:47:00.110+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:47:00.110+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:47:00.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2025-01-02T20:47:33.098+0000] {processor.py:186} INFO - Started process (PID=12402) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:47:33.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:47:33.101+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:47:33.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:47:33.115+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:47:33.178+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:47:33.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:47:33.199+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:47:33.198+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:47:33.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2025-01-02T20:48:05.378+0000] {processor.py:186} INFO - Started process (PID=12428) to work on /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:48:05.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2025-01-02T20:48:05.382+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:48:05.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:48:05.403+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2025-01-02T20:48:05.480+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:48:05.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-02T20:48:05.561+0000] {logging_mixin.py:190} INFO - [2025-01-02T20:48:05.560+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2025-01-02 19:00:00+00:00, run_after=2025-01-02 20:00:00+00:00
[2025-01-02T20:48:05.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.210 seconds
