[2024-12-22T02:58:38.773+0000] {processor.py:186} INFO - Started process (PID=413) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T02:58:38.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T02:58:38.831+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:38.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T02:58:38.935+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T02:58:39.660+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:39.660+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_job_pipeline
[2024-12-22T02:58:42.065+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:42.064+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_job_pipeline
[2024-12-22T02:58:42.074+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:42.074+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_job_pipeline
[2024-12-22T02:58:42.088+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:42.088+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_job_pipeline
[2024-12-22T02:58:42.099+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:42.098+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_job_pipeline
[2024-12-22T02:58:42.108+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:42.107+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_job_pipeline
[2024-12-22T02:58:42.119+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:42.119+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_job_pipeline
[2024-12-22T02:58:42.120+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:42.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T02:58:42.161+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:42.161+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_job_pipeline
[2024-12-22T02:58:42.210+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:58:42.209+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 01:00:00+00:00, run_after=2024-12-22 02:00:00+00:00
[2024-12-22T02:58:42.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 3.505 seconds
[2024-12-22T02:59:12.445+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T02:59:12.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T02:59:12.450+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:59:12.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T02:59:12.486+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T02:59:12.522+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:59:12.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T02:59:12.552+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:59:12.552+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 01:00:00+00:00, run_after=2024-12-22 02:00:00+00:00
[2024-12-22T02:59:12.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.145 seconds
[2024-12-22T02:59:42.699+0000] {processor.py:186} INFO - Started process (PID=435) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T02:59:42.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T02:59:42.703+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:59:42.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T02:59:42.743+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T02:59:42.777+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:59:42.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T02:59:42.806+0000] {logging_mixin.py:190} INFO - [2024-12-22T02:59:42.805+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 01:00:00+00:00, run_after=2024-12-22 02:00:00+00:00
[2024-12-22T02:59:42.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2024-12-22T03:01:28.881+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:01:28.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:01:28.886+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:01:28.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:01:28.921+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:01:29.216+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:01:29.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:01:29.523+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:01:29.523+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:01:29.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.843 seconds
[2024-12-22T03:02:00.124+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:02:00.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:02:00.272+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:02:00.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:02:00.464+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:02:01.113+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:02:01.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:02:01.242+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:02:01.242+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:02:01.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.264 seconds
[2024-12-22T03:02:31.409+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:02:31.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:02:31.414+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:02:31.414+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:02:31.442+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:02:31.489+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:02:31.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:02:31.566+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:02:31.565+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:02:31.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.197 seconds
[2024-12-22T03:03:01.708+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:03:01.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:03:01.711+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:03:01.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:03:01.728+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:03:01.756+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:03:01.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:03:01.781+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:03:01.781+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:03:01.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-22T03:03:31.913+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:03:31.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:03:31.919+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:03:31.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:03:31.960+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:03:32.067+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:03:32.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:03:32.100+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:03:32.100+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:03:32.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.224 seconds
[2024-12-22T03:04:02.307+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:04:02.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:04:02.311+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:04:02.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:04:02.350+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:04:02.384+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:04:02.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:04:02.410+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:04:02.410+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:04:02.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.137 seconds
[2024-12-22T03:04:32.532+0000] {processor.py:186} INFO - Started process (PID=309) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:04:32.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:04:32.536+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:04:32.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:04:32.563+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:04:32.596+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:04:32.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:04:32.632+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:04:32.631+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:04:32.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2024-12-22T03:05:02.749+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:05:02.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:05:02.753+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:05:02.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:05:02.776+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:05:02.814+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:05:02.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:05:02.837+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:05:02.836+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:05:02.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2024-12-22T03:05:32.949+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:05:32.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:05:32.952+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:05:32.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:05:32.974+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:05:33.005+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:05:33.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:05:33.032+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:05:33.032+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:05:33.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2024-12-22T03:06:03.134+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:06:03.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:06:03.137+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:06:03.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:06:03.157+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:06:03.187+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:06:03.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:06:03.213+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:06:03.213+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:06:03.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.113 seconds
[2024-12-22T03:06:33.353+0000] {processor.py:186} INFO - Started process (PID=355) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:06:33.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:06:33.357+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:06:33.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:06:33.374+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:06:33.399+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:06:33.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:06:33.424+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:06:33.423+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:06:33.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-22T03:07:03.600+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:07:03.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:07:03.641+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:07:03.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:07:03.672+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:07:03.703+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:07:03.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:07:03.729+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:07:03.728+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:07:03.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.169 seconds
[2024-12-22T03:07:33.930+0000] {processor.py:186} INFO - Started process (PID=377) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:07:33.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:07:33.934+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:07:33.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:07:33.966+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:07:33.998+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:07:33.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:07:34.019+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:07:34.019+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:07:34.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.146 seconds
[2024-12-22T03:08:04.159+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:08:04.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:08:04.163+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:08:04.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:08:04.199+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:08:04.237+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:08:04.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:08:04.267+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:08:04.267+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:08:04.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.143 seconds
[2024-12-22T03:08:34.397+0000] {processor.py:186} INFO - Started process (PID=399) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:08:34.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:08:34.401+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:08:34.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:08:34.429+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:08:34.466+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:08:34.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:08:34.492+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:08:34.492+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:08:34.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.130 seconds
[2024-12-22T03:09:04.595+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:09:04.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:09:04.600+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:09:04.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:09:04.624+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:09:04.652+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:09:04.652+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:09:04.677+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:09:04.677+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:09:04.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2024-12-22T03:09:35.545+0000] {processor.py:186} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:09:35.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:09:35.550+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:09:35.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:09:35.573+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:09:35.605+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:09:35.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:09:35.628+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:09:35.628+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:09:35.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2024-12-22T03:10:05.699+0000] {processor.py:186} INFO - Started process (PID=430) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:10:05.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:10:05.702+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:10:05.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:10:05.720+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:10:05.751+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:10:05.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:10:05.776+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:10:05.776+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:10:05.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2024-12-22T03:10:35.924+0000] {processor.py:186} INFO - Started process (PID=441) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:10:35.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:10:35.931+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:10:35.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:10:35.976+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:10:36.059+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:10:36.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:10:36.097+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:10:36.096+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:10:36.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.216 seconds
[2024-12-22T03:11:06.251+0000] {processor.py:186} INFO - Started process (PID=452) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:11:06.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:11:06.256+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:11:06.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:11:06.288+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:11:06.318+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:11:06.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:11:06.342+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:11:06.341+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:11:06.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2024-12-22T03:11:36.991+0000] {processor.py:186} INFO - Started process (PID=463) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:11:36.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:11:36.997+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:11:36.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:11:37.019+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:11:37.056+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:11:37.056+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:11:37.083+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:11:37.083+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:11:37.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.123 seconds
[2024-12-22T03:12:07.991+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:12:07.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:12:07.999+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:12:07.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:12:08.047+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:12:08.097+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:12:08.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:12:08.136+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:12:08.136+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:12:08.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.192 seconds
[2024-12-22T03:12:38.818+0000] {processor.py:186} INFO - Started process (PID=485) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:12:38.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:12:38.822+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:12:38.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:12:38.844+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:12:38.871+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:12:38.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:12:38.894+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:12:38.894+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:12:38.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.107 seconds
[2024-12-22T03:13:09.747+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:13:09.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:13:09.754+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:13:09.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:13:09.804+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:13:09.855+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:13:09.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:13:09.894+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:13:09.894+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:13:09.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.204 seconds
[2024-12-22T03:13:40.693+0000] {processor.py:186} INFO - Started process (PID=507) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:13:40.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:13:40.706+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:13:40.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:13:40.786+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:13:40.869+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:13:40.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:13:40.931+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:13:40.930+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:13:40.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.315 seconds
[2024-12-22T03:14:11.649+0000] {processor.py:186} INFO - Started process (PID=518) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:14:11.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:14:11.664+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:14:11.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:14:11.730+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:14:11.809+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:14:11.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:14:11.850+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:14:11.849+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:14:11.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.264 seconds
[2024-12-22T03:14:42.056+0000] {processor.py:186} INFO - Started process (PID=529) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:14:42.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:14:42.069+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:14:42.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:14:42.145+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:14:42.227+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:14:42.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:14:42.304+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:14:42.303+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:14:42.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.324 seconds
[2024-12-22T03:15:12.810+0000] {processor.py:186} INFO - Started process (PID=540) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:15:12.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:15:12.820+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:15:12.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:15:12.886+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:15:12.958+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:15:12.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:15:13.033+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:15:13.033+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:15:13.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.291 seconds
[2024-12-22T03:15:43.499+0000] {processor.py:186} INFO - Started process (PID=551) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:15:43.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:15:43.507+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:15:43.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:15:43.557+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:15:43.624+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:15:43.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:15:43.688+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:15:43.687+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:15:43.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.255 seconds
[2024-12-22T03:16:14.245+0000] {processor.py:186} INFO - Started process (PID=562) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:16:14.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:16:14.255+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:16:14.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:16:14.322+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:16:14.396+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:16:14.396+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:16:14.461+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:16:14.460+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:16:14.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.285 seconds
[2024-12-22T03:16:44.744+0000] {processor.py:186} INFO - Started process (PID=573) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:16:44.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:16:44.756+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:16:44.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:16:44.813+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:16:44.881+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:16:44.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:16:44.959+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:16:44.959+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:16:45.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.276 seconds
[2024-12-22T03:17:15.190+0000] {processor.py:186} INFO - Started process (PID=584) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:17:15.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:17:15.199+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:17:15.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:17:15.263+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:17:15.343+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:17:15.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:17:15.380+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:17:15.380+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:17:15.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.231 seconds
[2024-12-22T03:17:45.923+0000] {processor.py:186} INFO - Started process (PID=594) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:17:45.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:17:45.932+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:17:45.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:17:45.999+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:17:46.072+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:17:46.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:17:46.128+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:17:46.128+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:17:46.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.254 seconds
[2024-12-22T03:18:16.459+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:18:16.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:18:16.466+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:18:16.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:18:16.506+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:18:16.552+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:18:16.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:18:16.601+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:18:16.600+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:18:16.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.203 seconds
[2024-12-22T03:18:47.247+0000] {processor.py:186} INFO - Started process (PID=616) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:18:47.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:18:47.256+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:18:47.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:18:47.321+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:18:47.404+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:18:47.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:18:47.478+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:18:47.477+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:18:47.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.304 seconds
[2024-12-22T03:19:18.311+0000] {processor.py:186} INFO - Started process (PID=627) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:19:18.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:19:18.320+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:19:18.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:19:18.393+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:19:18.468+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:19:18.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:19:18.534+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:19:18.533+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:19:18.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.286 seconds
[2024-12-22T03:19:48.859+0000] {processor.py:186} INFO - Started process (PID=638) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:19:48.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:19:48.866+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:19:48.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:19:48.915+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:19:48.962+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:19:48.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:19:48.993+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:19:48.993+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:19:49.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.177 seconds
[2024-12-22T03:20:19.642+0000] {processor.py:186} INFO - Started process (PID=649) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:20:19.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:20:19.650+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:20:19.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:20:19.699+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:20:19.742+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:20:19.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:20:19.787+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:20:19.787+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:20:19.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.193 seconds
[2024-12-22T03:20:50.024+0000] {processor.py:186} INFO - Started process (PID=660) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:20:50.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:20:50.033+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:20:50.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:20:50.102+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:20:50.177+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:20:50.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:20:50.245+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:20:50.245+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:20:50.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.289 seconds
[2024-12-22T03:21:20.496+0000] {processor.py:186} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:21:20.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:21:20.505+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:21:20.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:21:20.575+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:21:20.650+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:21:20.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:21:20.718+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:21:20.717+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:21:20.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.288 seconds
[2024-12-22T03:21:51.040+0000] {processor.py:186} INFO - Started process (PID=682) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:21:51.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:21:51.048+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:21:51.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:21:51.110+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:21:51.178+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:21:51.177+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:21:51.240+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:21:51.240+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:21:51.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.265 seconds
[2024-12-22T03:22:21.488+0000] {processor.py:186} INFO - Started process (PID=692) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:22:21.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:22:21.498+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:22:21.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:22:21.551+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:22:21.599+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:22:21.599+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:22:21.642+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:22:21.641+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:22:21.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.202 seconds
[2024-12-22T03:22:52.208+0000] {processor.py:186} INFO - Started process (PID=703) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:22:52.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:22:52.216+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:22:52.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:22:52.269+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:22:52.344+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:22:52.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:22:52.409+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:22:52.409+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:22:52.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.264 seconds
[2024-12-22T03:23:23.353+0000] {processor.py:186} INFO - Started process (PID=714) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:23:23.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:23:23.361+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:23:23.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:23:23.426+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:23:23.499+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:23:23.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:23:23.557+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:23:23.557+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:23:23.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.273 seconds
[2024-12-22T03:23:54.219+0000] {processor.py:186} INFO - Started process (PID=725) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:23:54.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:23:54.228+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:23:54.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:23:54.292+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:23:54.356+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:23:54.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:23:54.425+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:23:54.425+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:23:54.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.269 seconds
[2024-12-22T03:24:25.079+0000] {processor.py:186} INFO - Started process (PID=736) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:24:25.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:24:25.090+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:24:25.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:24:25.157+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:24:25.199+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:24:25.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:24:25.248+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:24:25.247+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:24:25.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.222 seconds
[2024-12-22T03:24:55.860+0000] {processor.py:186} INFO - Started process (PID=747) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:24:55.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:24:55.869+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:24:55.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:24:55.929+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:24:56.005+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:24:56.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:24:56.067+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:24:56.066+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:24:56.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.273 seconds
[2024-12-22T03:25:26.830+0000] {processor.py:186} INFO - Started process (PID=758) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:25:26.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:25:26.839+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:25:26.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:25:26.905+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:25:26.974+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:25:26.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:25:27.033+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:25:27.032+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:25:27.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.272 seconds
[2024-12-22T03:25:57.634+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:25:57.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:25:57.643+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:25:57.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:25:57.703+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:25:57.777+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:25:57.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:25:57.841+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:25:57.840+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:25:57.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.271 seconds
[2024-12-22T03:26:28.031+0000] {processor.py:186} INFO - Started process (PID=780) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:26:28.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:26:28.041+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:26:28.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:26:28.108+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:26:28.152+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:26:28.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:26:28.207+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:26:28.207+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:26:28.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.237 seconds
[2024-12-22T03:26:58.822+0000] {processor.py:186} INFO - Started process (PID=791) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:26:58.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:26:58.829+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:26:58.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:26:58.863+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:26:58.903+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:26:58.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:26:58.945+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:26:58.944+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:26:58.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.163 seconds
[2024-12-22T03:27:29.724+0000] {processor.py:186} INFO - Started process (PID=802) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:27:29.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:27:29.733+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:27:29.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:27:29.794+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:27:29.868+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:27:29.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:27:29.911+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:27:29.911+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:27:29.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.240 seconds
[2024-12-22T03:28:00.464+0000] {processor.py:186} INFO - Started process (PID=813) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:28:00.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:28:00.473+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:28:00.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:28:00.543+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:28:00.615+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:28:00.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:28:00.689+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:28:00.689+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:28:00.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.286 seconds
[2024-12-22T03:28:31.410+0000] {processor.py:186} INFO - Started process (PID=824) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:28:31.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:28:31.419+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:28:31.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:28:31.479+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:28:31.551+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:28:31.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:28:31.613+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:28:31.612+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:28:31.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.274 seconds
[2024-12-22T03:29:02.202+0000] {processor.py:186} INFO - Started process (PID=835) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:29:02.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:29:02.210+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:29:02.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:29:02.271+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:29:02.335+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:29:02.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:29:02.402+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:29:02.401+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:29:02.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.265 seconds
[2024-12-22T03:29:33.223+0000] {processor.py:186} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:29:33.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:29:33.232+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:29:33.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:29:33.303+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:29:33.358+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:29:33.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:29:33.401+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:29:33.400+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:29:33.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.238 seconds
[2024-12-22T03:30:04.232+0000] {processor.py:186} INFO - Started process (PID=857) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:30:04.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:30:04.241+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:30:04.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:30:04.298+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:30:04.343+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:30:04.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:30:04.379+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:30:04.379+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:30:04.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.193 seconds
[2024-12-22T03:30:35.110+0000] {processor.py:186} INFO - Started process (PID=868) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:30:35.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:30:35.117+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:30:35.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:30:35.154+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:30:35.222+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:30:35.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:30:35.283+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:30:35.283+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:30:35.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.240 seconds
[2024-12-22T03:31:05.860+0000] {processor.py:186} INFO - Started process (PID=879) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:31:05.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:31:05.870+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:31:05.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:31:05.934+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:31:06.004+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:31:06.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:31:06.067+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:31:06.066+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:31:06.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.274 seconds
[2024-12-22T03:31:36.827+0000] {processor.py:186} INFO - Started process (PID=890) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:31:36.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:31:36.835+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:31:36.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:31:36.899+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:31:36.947+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:31:36.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:31:36.989+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:31:36.989+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:31:37.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.213 seconds
[2024-12-22T03:32:07.527+0000] {processor.py:186} INFO - Started process (PID=901) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:32:07.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:32:07.536+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:32:07.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:32:07.574+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:32:07.608+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:32:07.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:32:07.635+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:32:07.635+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:32:07.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.154 seconds
[2024-12-22T03:32:38.362+0000] {processor.py:186} INFO - Started process (PID=912) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:32:38.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:32:38.366+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:32:38.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:32:38.403+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:32:38.455+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:32:38.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:32:38.486+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:32:38.486+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:32:38.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.169 seconds
[2024-12-22T03:33:08.934+0000] {processor.py:186} INFO - Started process (PID=922) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:33:08.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:33:08.938+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:33:08.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:33:08.964+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:33:09.000+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:33:09.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:33:09.031+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:33:09.031+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:33:09.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.136 seconds
[2024-12-22T03:33:39.985+0000] {processor.py:186} INFO - Started process (PID=933) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:33:39.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:33:39.995+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:33:39.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:33:40.086+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:33:40.141+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:33:40.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:33:40.171+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:33:40.171+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:33:40.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.225 seconds
[2024-12-22T03:34:10.791+0000] {processor.py:186} INFO - Started process (PID=945) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:34:10.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:34:10.801+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:34:10.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:34:10.882+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:34:10.918+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:34:10.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:34:10.945+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:34:10.945+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:34:10.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.196 seconds
[2024-12-22T03:34:41.057+0000] {processor.py:186} INFO - Started process (PID=956) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:34:41.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T03:34:41.062+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:34:41.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:34:41.092+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T03:34:41.131+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:34:41.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T03:34:41.167+0000] {logging_mixin.py:190} INFO - [2024-12-22T03:34:41.167+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 02:00:00+00:00, run_after=2024-12-22 03:00:00+00:00
[2024-12-22T03:34:41.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.145 seconds
[2024-12-22T15:28:47.626+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:28:47.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:28:47.644+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:28:47.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:28:47.855+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:28:48.120+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:28:48.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:28:48.200+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:28:48.200+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:28:48.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.657 seconds
[2024-12-22T15:33:03.673+0000] {processor.py:186} INFO - Started process (PID=218) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:33:03.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:33:03.696+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:33:03.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:33:03.759+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:33:04.045+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:33:04.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:33:04.325+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:33:04.325+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:33:04.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.894 seconds
[2024-12-22T15:33:34.853+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:33:34.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:33:34.867+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:33:34.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:33:34.980+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:33:35.126+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:33:35.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:33:35.199+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:33:35.199+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:33:35.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.430 seconds
[2024-12-22T15:34:05.686+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:34:05.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:34:05.712+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:34:05.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:34:05.765+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:34:05.804+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:34:05.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:34:05.836+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:34:05.836+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:34:05.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.251 seconds
[2024-12-22T15:34:36.169+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:34:36.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:34:36.178+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:34:36.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:34:36.255+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:34:36.366+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:34:36.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:34:36.389+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:34:36.388+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:34:36.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.251 seconds
[2024-12-22T15:35:06.710+0000] {processor.py:186} INFO - Started process (PID=283) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:35:06.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:35:06.714+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:35:06.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:35:06.731+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:35:06.781+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:35:06.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:35:06.809+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:35:06.809+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:35:06.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2024-12-22T15:35:37.070+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:35:37.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:35:37.089+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:35:37.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:35:37.148+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:35:37.248+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:35:37.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:35:37.321+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:35:37.321+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:35:37.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.330 seconds
[2024-12-22T15:36:07.433+0000] {processor.py:186} INFO - Started process (PID=299) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:36:07.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:36:07.437+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:36:07.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:36:07.463+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:36:07.494+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:36:07.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:36:07.514+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:36:07.514+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:36:07.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2024-12-22T15:36:39.079+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:36:39.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:36:39.083+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:36:39.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:36:39.108+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:36:39.139+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:36:39.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:36:39.164+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:36:39.164+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:36:39.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2024-12-22T15:37:10.821+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:37:10.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:37:10.829+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:37:10.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:37:10.856+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:37:10.899+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:37:10.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:37:10.928+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:37:10.928+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:37:10.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.151 seconds
[2024-12-22T15:37:43.324+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:37:43.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:37:43.330+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:37:43.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:37:43.361+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:37:43.388+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:37:43.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:37:43.414+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:37:43.414+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:37:43.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.120 seconds
[2024-12-22T15:38:16.017+0000] {processor.py:186} INFO - Started process (PID=343) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:38:16.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:38:16.073+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:38:16.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:38:16.147+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:38:16.240+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:38:16.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:38:16.327+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:38:16.326+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:38:16.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.395 seconds
[2024-12-22T15:38:47.281+0000] {processor.py:186} INFO - Started process (PID=354) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:38:47.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:38:47.285+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:38:47.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:38:47.311+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:38:47.349+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:38:47.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:38:47.384+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:38:47.384+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:38:47.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2024-12-22T15:39:20.152+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:39:20.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:39:20.162+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:39:20.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:39:20.185+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:39:20.211+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:39:20.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:39:20.233+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:39:20.233+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:39:20.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2024-12-22T15:39:52.636+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:39:52.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:39:52.640+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:39:52.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:39:52.670+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:39:52.702+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:39:52.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:39:52.729+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:39:52.729+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:39:52.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.120 seconds
[2024-12-22T15:40:25.519+0000] {processor.py:186} INFO - Started process (PID=387) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:40:25.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:40:25.523+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:40:25.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:40:25.552+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:40:25.577+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:40:25.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:40:25.599+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:40:25.599+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:40:25.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.112 seconds
[2024-12-22T15:40:56.842+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:40:56.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:40:56.845+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:40:56.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:40:56.866+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:40:56.892+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:40:56.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:40:56.911+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:40:56.911+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:40:56.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-22T15:41:29.310+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:41:29.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:41:29.314+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:41:29.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:41:29.340+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:41:29.366+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:41:29.366+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:41:29.387+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:41:29.387+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:41:29.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.107 seconds
[2024-12-22T15:42:02.210+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:42:02.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:42:02.213+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:42:02.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:42:02.240+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:42:02.268+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:42:02.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:42:02.288+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:42:02.288+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:42:02.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2024-12-22T15:42:34.076+0000] {processor.py:186} INFO - Started process (PID=431) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:42:34.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:42:34.079+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:42:34.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:42:34.109+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:42:34.134+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:42:34.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:42:34.153+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:42:34.153+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:42:34.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-22T15:43:06.744+0000] {processor.py:186} INFO - Started process (PID=442) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:43:06.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:43:06.747+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:43:06.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:43:06.763+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:43:06.786+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:43:06.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:43:06.805+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:43:06.804+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:43:06.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.087 seconds
[2024-12-22T15:43:39.344+0000] {processor.py:186} INFO - Started process (PID=453) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:43:39.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:43:39.347+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:43:39.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:43:39.372+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:43:39.418+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:43:39.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:43:39.449+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:43:39.449+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:43:39.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2024-12-22T15:44:11.181+0000] {processor.py:186} INFO - Started process (PID=463) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:44:11.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:44:11.190+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:44:11.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:44:11.228+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:44:11.255+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:44:11.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:44:11.276+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:44:11.276+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:44:11.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2024-12-22T15:44:43.952+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:44:43.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:44:43.955+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:44:43.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:44:43.974+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:44:43.999+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:44:43.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:44:44.021+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:44:44.021+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:44:44.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-22T15:45:16.670+0000] {processor.py:186} INFO - Started process (PID=485) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:45:16.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:45:16.673+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:45:16.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:45:16.695+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:45:16.719+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:45:16.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:45:16.741+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:45:16.740+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:45:16.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-22T15:45:48.333+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:45:48.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:45:48.337+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:45:48.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:45:48.364+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:45:48.391+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:45:48.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:45:48.413+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:45:48.413+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:45:48.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2024-12-22T15:46:21.160+0000] {processor.py:186} INFO - Started process (PID=507) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:46:21.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:46:21.166+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:46:21.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:46:21.195+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:46:21.222+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:46:21.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:46:21.243+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:46:21.243+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:46:21.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.112 seconds
[2024-12-22T15:46:53.905+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:46:53.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:46:53.909+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:46:53.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:46:53.927+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:46:53.952+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:46:53.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:46:53.974+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:46:53.974+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:46:53.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-22T15:47:25.632+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:47:25.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:47:25.635+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:47:25.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:47:25.651+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:47:25.675+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:47:25.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:47:25.697+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:47:25.697+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:47:25.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-22T15:47:58.323+0000] {processor.py:186} INFO - Started process (PID=539) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:47:58.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:47:58.326+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:47:58.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:47:58.358+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:47:58.383+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:47:58.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:47:58.407+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:47:58.407+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:47:58.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.111 seconds
[2024-12-22T15:48:31.038+0000] {processor.py:186} INFO - Started process (PID=549) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:48:31.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:48:31.043+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:48:31.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:48:31.069+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:48:31.092+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:48:31.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:48:31.111+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:48:31.111+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:48:31.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2024-12-22T15:49:02.868+0000] {processor.py:186} INFO - Started process (PID=560) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:49:02.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:49:02.873+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:49:02.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:49:02.895+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:49:02.925+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:49:02.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:49:02.945+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:49:02.945+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:49:02.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-22T15:49:35.668+0000] {processor.py:186} INFO - Started process (PID=571) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:49:35.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:49:35.672+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:49:35.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:49:35.698+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:49:35.723+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:49:35.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:49:35.745+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:49:35.745+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:49:35.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.107 seconds
[2024-12-22T15:50:08.404+0000] {processor.py:186} INFO - Started process (PID=582) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:50:08.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:50:08.410+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:50:08.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:50:08.434+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:50:08.473+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:50:08.473+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:50:08.503+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:50:08.503+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:50:08.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.150 seconds
[2024-12-22T15:50:40.173+0000] {processor.py:186} INFO - Started process (PID=593) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:50:40.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:50:40.177+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:50:40.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:50:40.193+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:50:40.233+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:50:40.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:50:40.268+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:50:40.268+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:50:40.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.121 seconds
[2024-12-22T15:51:13.004+0000] {processor.py:186} INFO - Started process (PID=604) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:51:13.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:51:13.009+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:51:13.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:51:13.033+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:51:13.064+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:51:13.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:51:13.092+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:51:13.092+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:51:13.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.117 seconds
[2024-12-22T15:51:45.635+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:51:45.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:51:45.638+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:51:45.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:51:45.658+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:51:45.683+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:51:45.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:51:45.713+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:51:45.713+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:51:45.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2024-12-22T15:52:18.315+0000] {processor.py:186} INFO - Started process (PID=626) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:52:18.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:52:18.319+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:52:18.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:52:18.346+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:52:18.376+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:52:18.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:52:18.399+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:52:18.399+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:52:18.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.112 seconds
[2024-12-22T15:52:50.025+0000] {processor.py:186} INFO - Started process (PID=636) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:52:50.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:52:50.029+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:52:50.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:52:50.053+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:52:50.080+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:52:50.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:52:50.102+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:52:50.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:52:50.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.107 seconds
[2024-12-22T15:53:22.814+0000] {processor.py:186} INFO - Started process (PID=647) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:53:22.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:53:22.819+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:53:22.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:53:22.848+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:53:22.877+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:53:22.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:53:22.901+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:53:22.901+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:53:22.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2024-12-22T15:53:55.512+0000] {processor.py:186} INFO - Started process (PID=658) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:53:55.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:53:55.515+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:53:55.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:53:55.538+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:53:55.568+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:53:55.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:53:55.600+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:53:55.599+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:53:55.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.120 seconds
[2024-12-22T15:54:27.257+0000] {processor.py:186} INFO - Started process (PID=669) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:54:27.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:54:27.261+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:54:27.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:54:27.284+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:54:27.329+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:54:27.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:54:27.355+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:54:27.354+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:54:27.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2024-12-22T15:55:00.042+0000] {processor.py:186} INFO - Started process (PID=680) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:55:00.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:55:00.060+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:55:00.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:55:00.131+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:55:00.233+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:55:00.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:55:00.353+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:55:00.352+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:55:00.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.386 seconds
[2024-12-22T15:55:32.788+0000] {processor.py:186} INFO - Started process (PID=691) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:55:32.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:55:32.791+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:55:32.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:55:32.838+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:55:32.901+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:55:32.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:55:32.960+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:55:32.959+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:55:33.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.226 seconds
[2024-12-22T15:56:04.710+0000] {processor.py:186} INFO - Started process (PID=702) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:56:04.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:56:04.718+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:56:04.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:56:04.756+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:56:04.792+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:56:04.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:56:04.817+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:56:04.817+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:56:04.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.144 seconds
[2024-12-22T15:56:37.387+0000] {processor.py:186} INFO - Started process (PID=713) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:56:37.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:56:37.392+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:56:37.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:56:37.428+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:56:37.457+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:56:37.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:56:37.481+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:56:37.480+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:56:37.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2024-12-22T15:57:10.148+0000] {processor.py:186} INFO - Started process (PID=725) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:57:10.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:57:10.150+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:57:10.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:57:10.174+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:57:10.196+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:57:10.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:57:10.218+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:57:10.218+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:57:10.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-22T15:57:42.929+0000] {processor.py:186} INFO - Started process (PID=736) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:57:42.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:57:42.934+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:57:42.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:57:42.967+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:57:42.998+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:57:42.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:57:43.024+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:57:43.024+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:57:43.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.120 seconds
[2024-12-22T15:58:14.757+0000] {processor.py:186} INFO - Started process (PID=747) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:58:14.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:58:14.760+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:58:14.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:58:14.797+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:58:14.830+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:58:14.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:58:14.855+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:58:14.855+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:58:14.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2024-12-22T15:58:47.611+0000] {processor.py:186} INFO - Started process (PID=758) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:58:47.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:58:47.621+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:58:47.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:58:47.658+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:58:47.702+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:58:47.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:58:47.811+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:58:47.811+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:58:47.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.233 seconds
[2024-12-22T15:59:20.362+0000] {processor.py:186} INFO - Started process (PID=792) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:59:20.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:59:20.369+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:59:20.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:59:20.422+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:59:20.502+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:59:20.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:59:20.562+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:59:20.562+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:59:20.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.232 seconds
[2024-12-22T15:59:52.345+0000] {processor.py:186} INFO - Started process (PID=803) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:59:52.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T15:59:52.349+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:59:52.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:59:52.388+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T15:59:52.430+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:59:52.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T15:59:52.459+0000] {logging_mixin.py:190} INFO - [2024-12-22T15:59:52.458+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 14:00:00+00:00, run_after=2024-12-22 15:00:00+00:00
[2024-12-22T15:59:52.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.144 seconds
[2024-12-22T16:00:25.135+0000] {processor.py:186} INFO - Started process (PID=813) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:00:25.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:00:25.139+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:00:25.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:00:25.165+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:00:25.197+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:00:25.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:00:25.224+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:00:25.224+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:00:25.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2024-12-22T16:00:57.906+0000] {processor.py:186} INFO - Started process (PID=824) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:00:57.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:00:57.910+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:00:57.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:00:57.937+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:00:57.965+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:00:57.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:00:57.988+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:00:57.987+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:00:58.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2024-12-22T16:01:29.852+0000] {processor.py:186} INFO - Started process (PID=835) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:01:29.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:01:29.856+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:01:29.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:01:29.880+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:01:29.906+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:01:29.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:01:29.928+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:01:29.927+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:01:29.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-22T16:02:02.670+0000] {processor.py:186} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:02:02.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:02:02.674+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:02:02.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:02:02.709+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:02:02.737+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:02:02.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:02:02.763+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:02:02.763+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:02:02.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2024-12-22T16:02:35.529+0000] {processor.py:186} INFO - Started process (PID=857) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:02:35.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:02:35.534+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:02:35.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:02:35.565+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:02:35.594+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:02:35.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:02:35.620+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:02:35.620+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:02:35.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.119 seconds
[2024-12-22T16:03:07.426+0000] {processor.py:186} INFO - Started process (PID=867) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:03:07.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:03:07.430+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:03:07.430+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:03:07.454+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:03:07.479+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:03:07.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:03:07.499+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:03:07.499+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:03:07.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-22T16:03:40.232+0000] {processor.py:186} INFO - Started process (PID=878) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:03:40.233+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:03:40.235+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:03:40.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:03:40.261+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:03:40.294+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:03:40.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:03:40.319+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:03:40.319+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:03:40.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.113 seconds
[2024-12-22T16:04:13.114+0000] {processor.py:186} INFO - Started process (PID=889) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:04:13.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:04:13.117+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:04:13.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:04:13.143+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:04:13.169+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:04:13.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:04:13.191+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:04:13.191+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:04:13.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2024-12-22T16:04:44.935+0000] {processor.py:186} INFO - Started process (PID=900) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:04:44.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:04:44.938+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:04:44.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:04:44.965+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:04:44.995+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:04:44.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:04:45.016+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:04:45.015+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:04:45.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2024-12-22T16:05:17.763+0000] {processor.py:186} INFO - Started process (PID=911) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:05:17.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:05:17.767+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:05:17.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:05:17.794+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:05:17.825+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:05:17.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:05:17.845+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:05:17.845+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:05:17.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.112 seconds
[2024-12-22T16:05:50.639+0000] {processor.py:186} INFO - Started process (PID=922) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:05:50.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:05:50.644+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:05:50.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:05:50.674+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:05:50.703+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:05:50.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:05:50.730+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:05:50.729+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:05:50.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2024-12-22T16:06:20.918+0000] {processor.py:186} INFO - Started process (PID=932) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:06:22.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:06:22.533+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:06:22.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:06:22.557+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:06:22.583+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:06:22.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:06:22.601+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:06:22.601+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:06:22.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-22T16:06:55.478+0000] {processor.py:186} INFO - Started process (PID=943) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:06:55.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:06:55.482+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:06:55.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:06:55.506+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:06:55.536+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:06:55.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:06:55.557+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:06:55.557+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:06:55.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-22T16:07:28.289+0000] {processor.py:186} INFO - Started process (PID=954) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:07:28.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:07:28.292+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:07:28.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:07:28.318+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:07:28.344+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:07:28.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:07:28.363+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:07:28.363+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:07:28.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-22T16:08:00.270+0000] {processor.py:186} INFO - Started process (PID=965) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:08:00.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:08:00.273+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:08:00.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:08:00.292+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:08:00.321+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:08:00.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:08:00.349+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:08:00.349+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:08:00.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-22T16:08:33.122+0000] {processor.py:186} INFO - Started process (PID=977) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:08:33.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:08:33.127+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:08:33.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:08:33.153+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:08:33.180+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:08:33.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:08:33.201+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:08:33.201+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:08:33.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2024-12-22T16:09:05.965+0000] {processor.py:186} INFO - Started process (PID=989) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:09:05.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:09:05.968+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:09:05.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:09:05.990+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:09:06.015+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:09:06.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:09:06.037+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:09:06.037+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:09:06.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-22T16:09:36.346+0000] {processor.py:186} INFO - Started process (PID=1000) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:09:36.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:09:36.351+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:09:36.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:09:37.998+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:09:38.021+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:09:38.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:09:38.042+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:09:38.042+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:09:38.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-22T16:10:10.958+0000] {processor.py:186} INFO - Started process (PID=1011) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:10:10.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:10:10.961+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:10:10.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:10:10.987+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:10:11.011+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:10:11.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:10:11.032+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:10:11.032+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:10:11.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-22T16:10:43.847+0000] {processor.py:186} INFO - Started process (PID=1022) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:10:43.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:10:43.852+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:10:43.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:10:43.879+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:10:43.900+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:10:43.900+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:10:43.919+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:10:43.919+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:10:43.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-22T16:11:14.157+0000] {processor.py:186} INFO - Started process (PID=1032) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:11:14.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:11:15.773+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:11:15.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:11:15.791+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:11:15.815+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:11:15.815+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:11:15.836+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:11:15.835+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:11:15.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-22T16:11:48.664+0000] {processor.py:186} INFO - Started process (PID=1043) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:11:48.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:11:48.667+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:11:48.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:11:48.691+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:11:48.714+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:11:48.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:11:48.732+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:11:48.732+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:11:48.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-22T16:12:21.707+0000] {processor.py:186} INFO - Started process (PID=1054) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:12:21.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:12:21.710+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:12:21.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:12:21.733+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:12:21.757+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:12:21.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:12:21.775+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:12:21.775+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:12:21.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-22T16:12:54.471+0000] {processor.py:186} INFO - Started process (PID=1065) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:12:54.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:12:54.474+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:12:54.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:12:54.495+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:12:54.519+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:12:54.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:12:54.540+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:12:54.540+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:12:54.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2024-12-22T16:13:26.397+0000] {processor.py:186} INFO - Started process (PID=1076) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:13:26.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:13:26.401+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:13:26.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:13:26.425+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:13:26.449+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:13:26.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:13:26.470+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:13:26.470+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:13:26.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-22T16:13:59.271+0000] {processor.py:186} INFO - Started process (PID=1087) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:13:59.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:13:59.275+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:13:59.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:13:59.296+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:13:59.320+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:13:59.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:13:59.339+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:13:59.339+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:13:59.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.090 seconds
[2024-12-22T16:14:32.294+0000] {processor.py:186} INFO - Started process (PID=1098) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:14:32.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:14:32.298+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:14:32.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:14:32.325+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:14:32.356+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:14:32.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:14:32.379+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:14:32.378+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:14:32.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.112 seconds
[2024-12-22T16:15:02.518+0000] {processor.py:186} INFO - Started process (PID=1109) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:15:02.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:15:02.520+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:15:02.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:15:02.544+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:15:02.569+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:15:02.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:15:02.591+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:15:02.591+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:15:02.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.100 seconds
[2024-12-22T16:15:32.708+0000] {processor.py:186} INFO - Started process (PID=1120) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:15:32.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:15:32.711+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:15:32.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:15:32.743+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:15:32.768+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:15:32.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:15:32.791+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:15:32.791+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:15:32.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2024-12-22T16:16:03.202+0000] {processor.py:186} INFO - Started process (PID=1131) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:16:03.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:16:03.206+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:16:03.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:16:03.232+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:16:03.257+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:16:03.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:16:03.277+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:16:03.276+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:16:03.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.100 seconds
[2024-12-22T16:16:34.150+0000] {processor.py:186} INFO - Started process (PID=1142) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:16:34.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:16:34.153+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:16:34.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:16:34.182+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:16:34.207+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:16:34.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:16:34.228+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:16:34.228+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:16:34.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-22T16:17:04.961+0000] {processor.py:186} INFO - Started process (PID=1153) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:17:04.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:17:04.965+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:17:04.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:17:04.997+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:17:05.023+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:17:05.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:17:05.044+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:17:05.044+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:17:05.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.111 seconds
[2024-12-22T16:17:35.843+0000] {processor.py:186} INFO - Started process (PID=1164) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:17:35.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:17:35.846+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:17:35.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:17:35.864+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:17:35.893+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:17:35.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:17:35.918+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:17:35.918+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:17:35.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-22T16:18:06.736+0000] {processor.py:186} INFO - Started process (PID=1174) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:18:06.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:18:06.739+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:18:06.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:18:06.768+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:18:06.792+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:18:06.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:18:06.811+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:18:06.810+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:18:06.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-22T16:18:37.639+0000] {processor.py:186} INFO - Started process (PID=1185) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:18:37.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:18:37.642+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:18:37.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:18:37.665+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:18:37.686+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:18:37.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:18:37.705+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:18:37.705+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:18:37.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.090 seconds
[2024-12-22T16:19:08.622+0000] {processor.py:186} INFO - Started process (PID=1197) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:19:08.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:19:08.624+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:19:08.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:19:08.646+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:19:08.668+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:19:08.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:19:08.686+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:19:08.685+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:19:08.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.089 seconds
[2024-12-22T16:19:39.467+0000] {processor.py:186} INFO - Started process (PID=1208) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:19:39.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:19:39.472+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:19:39.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:19:39.495+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:19:39.520+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:19:39.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:19:39.539+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:19:39.539+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:19:39.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-22T16:20:10.306+0000] {processor.py:186} INFO - Started process (PID=1220) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:20:10.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:20:10.309+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:20:10.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:20:10.330+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:20:10.360+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:20:10.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:20:10.378+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:20:10.377+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:20:10.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-22T16:20:41.222+0000] {processor.py:186} INFO - Started process (PID=1231) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:20:41.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:20:41.225+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:20:41.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:20:41.247+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:20:41.268+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:20:41.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:20:41.288+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:20:41.288+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:20:41.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.089 seconds
[2024-12-22T16:21:12.131+0000] {processor.py:186} INFO - Started process (PID=1241) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:21:12.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:21:12.134+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:21:12.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:21:12.157+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:21:12.182+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:21:12.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:21:12.199+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:21:12.199+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:21:12.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2024-12-22T16:21:43.020+0000] {processor.py:186} INFO - Started process (PID=1252) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:21:43.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:21:43.023+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:21:43.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:21:43.047+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:21:43.067+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:21:43.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:21:43.086+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:21:43.086+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:21:43.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.088 seconds
[2024-12-22T16:22:13.900+0000] {processor.py:186} INFO - Started process (PID=1257) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:22:13.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:22:13.903+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:22:13.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:22:13.927+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:22:13.948+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:22:13.948+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:22:13.982+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:22:13.981+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:22:14.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.114 seconds
[2024-12-22T16:22:44.759+0000] {processor.py:186} INFO - Started process (PID=1268) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:22:44.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:22:44.762+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:22:44.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:22:44.787+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:22:44.812+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:22:44.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:22:44.829+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:22:44.829+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:22:44.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-22T16:23:15.776+0000] {processor.py:186} INFO - Started process (PID=1279) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:23:15.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:23:15.780+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:23:15.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:23:15.802+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:23:15.824+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:23:15.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:23:15.843+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:23:15.843+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:23:15.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.090 seconds
[2024-12-22T16:23:46.694+0000] {processor.py:186} INFO - Started process (PID=1290) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:23:46.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:23:46.698+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:23:46.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:23:46.722+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:23:46.748+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:23:46.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:23:46.768+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:23:46.768+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:23:46.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2024-12-22T16:24:18.585+0000] {processor.py:186} INFO - Started process (PID=1300) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:24:18.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:24:18.587+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:24:18.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:24:18.606+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:24:18.635+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:24:18.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:24:18.654+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:24:18.654+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:24:18.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-22T16:24:51.409+0000] {processor.py:186} INFO - Started process (PID=1311) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:24:51.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:24:51.412+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:24:51.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:24:51.429+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:24:51.453+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:24:51.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:24:51.474+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:24:51.474+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:24:51.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.086 seconds
[2024-12-22T16:25:24.421+0000] {processor.py:186} INFO - Started process (PID=1322) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:25:24.423+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:25:24.425+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:25:24.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:25:24.448+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:25:24.472+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:25:24.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:25:24.491+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:25:24.491+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:25:24.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2024-12-22T16:25:54.738+0000] {processor.py:186} INFO - Started process (PID=1333) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:25:54.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:25:54.741+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:25:54.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:25:54.766+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:25:54.791+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:25:54.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:25:54.817+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:25:54.817+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:25:54.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2024-12-22T16:26:24.930+0000] {processor.py:186} INFO - Started process (PID=1343) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:26:24.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:26:24.933+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:26:24.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:26:24.952+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:26:24.976+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:26:24.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:26:24.996+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:26:24.996+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:26:25.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-22T16:26:55.403+0000] {processor.py:186} INFO - Started process (PID=1354) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:26:55.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:26:55.406+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:26:55.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:26:55.428+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:26:55.451+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:26:55.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:26:55.468+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:26:55.468+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:26:55.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.089 seconds
[2024-12-22T16:27:26.333+0000] {processor.py:186} INFO - Started process (PID=1365) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:27:26.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:27:26.337+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:27:26.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:27:26.353+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:27:26.382+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:27:26.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:27:26.406+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:27:26.406+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:27:26.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-22T16:27:57.235+0000] {processor.py:186} INFO - Started process (PID=1376) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:27:57.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:27:57.238+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:27:57.238+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:27:57.263+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:27:57.287+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:27:57.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:27:57.310+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:27:57.310+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:27:57.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-22T16:28:28.209+0000] {processor.py:186} INFO - Started process (PID=1387) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:28:28.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:28:28.213+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:28:28.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:28:28.234+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:28:28.266+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:28:28.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:28:28.292+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:28:28.291+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:28:28.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2024-12-22T16:28:58.979+0000] {processor.py:186} INFO - Started process (PID=1399) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:28:58.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:28:58.983+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:28:58.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:28:59.007+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:28:59.030+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:28:59.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:28:59.049+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:28:59.049+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:28:59.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2024-12-22T16:29:29.862+0000] {processor.py:186} INFO - Started process (PID=1410) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:29:29.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:29:29.865+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:29:29.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:29:29.888+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:29:29.911+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:29:29.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:29:29.930+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:29:29.930+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:29:29.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2024-12-22T16:30:00.766+0000] {processor.py:186} INFO - Started process (PID=1421) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:30:00.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:30:00.769+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:30:00.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:30:00.791+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:30:00.811+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:30:00.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:30:00.830+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:30:00.829+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:30:00.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.088 seconds
[2024-12-22T16:30:31.748+0000] {processor.py:186} INFO - Started process (PID=1432) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:30:31.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:30:31.751+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:30:31.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:30:31.776+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:30:31.800+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:30:31.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:30:31.818+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:30:31.818+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:30:31.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-22T16:31:02.494+0000] {processor.py:186} INFO - Started process (PID=1443) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:31:02.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:31:02.497+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:31:02.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:31:02.522+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:31:02.545+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:31:02.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:31:02.566+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:31:02.565+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:31:02.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-22T16:31:33.381+0000] {processor.py:186} INFO - Started process (PID=1454) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:31:33.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:31:33.385+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:31:33.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:31:33.402+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:31:33.426+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:31:33.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:31:33.443+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:31:33.443+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:31:33.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.082 seconds
[2024-12-22T16:32:04.311+0000] {processor.py:186} INFO - Started process (PID=1466) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:32:04.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:32:04.314+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:32:04.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:32:04.337+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:32:04.360+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:32:04.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:32:04.379+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:32:04.379+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:32:04.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.091 seconds
[2024-12-22T16:32:35.275+0000] {processor.py:186} INFO - Started process (PID=1471) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:32:35.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:32:35.279+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:32:35.279+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:32:35.307+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:32:35.331+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:32:35.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:32:35.350+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:32:35.350+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:32:35.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.098 seconds
[2024-12-22T16:33:06.153+0000] {processor.py:186} INFO - Started process (PID=1482) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:33:06.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:33:06.156+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:33:06.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:33:06.182+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:33:06.210+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:33:06.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:33:06.235+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:33:06.235+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:33:06.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2024-12-22T16:33:37.016+0000] {processor.py:186} INFO - Started process (PID=1492) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:33:37.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:33:37.019+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:33:37.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:33:37.041+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:33:37.066+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:33:37.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:33:37.084+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:33:37.084+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:33:37.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.089 seconds
[2024-12-22T16:34:07.993+0000] {processor.py:186} INFO - Started process (PID=1503) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:34:07.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:34:07.996+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:34:07.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:34:08.017+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:34:08.043+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:34:08.042+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:34:08.064+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:34:08.064+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:34:08.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-22T16:34:39.012+0000] {processor.py:186} INFO - Started process (PID=1514) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:34:39.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:34:39.017+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:34:39.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:34:39.057+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:34:39.088+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:34:39.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:34:39.111+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:34:39.111+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:34:39.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2024-12-22T16:35:11.030+0000] {processor.py:186} INFO - Started process (PID=1525) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:35:11.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:35:11.032+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:35:11.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:35:11.050+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:35:11.073+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:35:11.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:35:11.094+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:35:11.094+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:35:11.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.086 seconds
[2024-12-22T16:35:44.075+0000] {processor.py:186} INFO - Started process (PID=1536) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:35:44.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:35:44.079+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:35:44.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:35:44.100+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:35:44.121+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:35:44.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:35:44.144+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:35:44.144+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:35:44.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-22T16:36:16.964+0000] {processor.py:186} INFO - Started process (PID=1548) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:36:16.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:36:16.967+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:36:16.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:36:16.984+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:36:17.013+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:36:17.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:36:17.039+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:36:17.039+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:36:17.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-22T16:36:49.945+0000] {processor.py:186} INFO - Started process (PID=1559) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:36:49.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:36:49.948+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:36:49.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:36:49.974+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:36:49.998+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:36:49.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:36:50.018+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:36:50.018+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:36:50.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.097 seconds
[2024-12-22T16:37:21.858+0000] {processor.py:186} INFO - Started process (PID=1570) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:37:21.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:37:21.862+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:37:21.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:37:21.879+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:37:21.902+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:37:21.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:37:21.923+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:37:21.923+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:37:21.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-22T16:37:55.009+0000] {processor.py:186} INFO - Started process (PID=1580) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:37:55.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:37:55.012+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:37:55.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:37:55.032+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:37:55.053+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:37:55.053+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:37:55.072+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:37:55.072+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:37:55.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.086 seconds
[2024-12-22T16:38:27.895+0000] {processor.py:186} INFO - Started process (PID=1591) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:38:27.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:38:27.898+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:38:27.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:38:27.919+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:38:27.941+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:38:27.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:38:27.962+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:38:27.962+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:38:27.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.090 seconds
[2024-12-22T16:38:59.838+0000] {processor.py:186} INFO - Started process (PID=1602) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:38:59.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:38:59.842+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:38:59.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:38:59.875+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:38:59.904+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:38:59.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:38:59.927+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:38:59.926+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:38:59.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2024-12-22T16:39:32.793+0000] {processor.py:186} INFO - Started process (PID=1613) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:39:32.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:39:32.796+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:39:32.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:39:32.819+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:39:32.848+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:39:32.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:39:32.873+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:39:32.873+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:39:32.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-22T16:40:04.319+0000] {processor.py:186} INFO - Started process (PID=1624) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:40:04.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:40:04.322+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:40:04.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:40:04.342+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:40:04.365+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:40:04.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:40:04.383+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:40:04.383+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:40:06.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.794 seconds
[2024-12-22T16:40:36.260+0000] {processor.py:186} INFO - Started process (PID=1636) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:40:36.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:40:36.262+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:40:36.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:40:36.285+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:40:36.308+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:40:36.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:40:36.326+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:40:36.326+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:40:36.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-22T16:41:06.869+0000] {processor.py:186} INFO - Started process (PID=1647) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:41:06.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:41:06.872+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:41:06.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:41:06.896+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:41:06.921+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:41:06.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:41:06.943+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:41:06.943+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:41:06.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-22T16:41:37.877+0000] {processor.py:186} INFO - Started process (PID=1657) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:41:37.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:41:37.881+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:41:37.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:41:37.899+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:41:37.928+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:41:37.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:41:37.949+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:41:37.949+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:41:37.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-22T16:42:08.915+0000] {processor.py:186} INFO - Started process (PID=1668) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:42:08.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:42:08.917+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:42:08.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:42:08.937+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:42:08.960+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:42:08.960+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:42:08.979+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:42:08.979+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:42:08.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.089 seconds
[2024-12-22T16:42:39.965+0000] {processor.py:186} INFO - Started process (PID=1680) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:42:39.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:42:39.968+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:42:39.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:42:39.990+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:42:40.013+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:42:40.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:42:40.031+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:42:40.031+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:42:40.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-22T16:43:10.863+0000] {processor.py:186} INFO - Started process (PID=1691) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:43:10.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:43:10.865+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:43:10.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:43:10.883+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:43:10.906+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:43:10.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:43:10.925+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:43:10.925+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:43:11.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.205 seconds
[2024-12-22T16:43:41.790+0000] {processor.py:186} INFO - Started process (PID=1702) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:43:41.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:43:41.794+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:43:41.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:43:41.815+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:43:41.839+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:43:41.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:43:41.858+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:43:41.858+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:43:41.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2024-12-22T16:44:12.721+0000] {processor.py:186} INFO - Started process (PID=1713) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:44:12.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:44:12.724+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:44:12.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:44:12.741+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:44:12.766+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:44:12.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:44:12.786+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:44:12.786+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:44:12.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-22T16:44:43.812+0000] {processor.py:186} INFO - Started process (PID=1724) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:44:43.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:44:43.814+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:44:43.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:44:43.833+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:44:43.855+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:44:43.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:44:43.871+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:44:43.871+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:44:43.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.081 seconds
[2024-12-22T16:45:14.811+0000] {processor.py:186} INFO - Started process (PID=1735) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:45:14.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:45:14.815+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:45:14.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:45:14.838+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:45:14.861+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:45:14.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:45:14.880+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:45:14.880+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:45:14.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-22T16:45:45.779+0000] {processor.py:186} INFO - Started process (PID=1746) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:45:45.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:45:45.782+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:45:45.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:45:45.802+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:45:45.824+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:45:45.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:45:45.843+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:45:45.842+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:45:45.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.088 seconds
[2024-12-22T16:46:16.726+0000] {processor.py:186} INFO - Started process (PID=1756) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:46:16.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:46:16.732+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:46:16.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:46:16.751+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:46:16.774+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:46:16.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:46:16.791+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:46:16.791+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:46:16.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.224 seconds
[2024-12-22T16:46:47.653+0000] {processor.py:186} INFO - Started process (PID=1767) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:46:47.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:46:47.656+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:46:47.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:46:47.677+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:46:47.704+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:46:47.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:46:47.729+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:46:47.729+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:46:47.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2024-12-22T16:47:18.614+0000] {processor.py:186} INFO - Started process (PID=1772) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:47:18.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:47:18.616+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:47:18.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:47:18.640+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:47:18.663+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:47:18.662+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:47:18.682+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:47:18.682+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:47:18.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.091 seconds
[2024-12-22T16:47:49.583+0000] {processor.py:186} INFO - Started process (PID=1783) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:47:49.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:47:49.587+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:47:49.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:47:49.610+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:47:49.632+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:47:49.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:47:49.652+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:47:49.651+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:47:49.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-22T16:48:20.569+0000] {processor.py:186} INFO - Started process (PID=1794) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:48:20.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:48:20.572+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:48:20.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:48:20.595+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:48:20.617+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:48:20.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:48:20.635+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:48:20.635+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:48:20.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.090 seconds
[2024-12-22T16:48:51.542+0000] {processor.py:186} INFO - Started process (PID=1805) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:48:51.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:48:51.544+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:48:51.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:48:51.569+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:48:51.592+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:48:51.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:48:51.610+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:48:51.610+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:48:51.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.091 seconds
[2024-12-22T16:49:22.527+0000] {processor.py:186} INFO - Started process (PID=1816) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:49:22.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:49:22.531+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:49:22.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:49:22.555+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:49:22.578+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:49:22.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:49:22.596+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:49:22.596+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:49:22.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.200 seconds
[2024-12-22T16:49:54.440+0000] {processor.py:186} INFO - Started process (PID=1827) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:49:54.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:49:54.443+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:49:54.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:49:54.459+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:49:54.482+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:49:54.482+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:49:54.500+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:49:54.500+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:49:54.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.084 seconds
[2024-12-22T16:50:27.396+0000] {processor.py:186} INFO - Started process (PID=1838) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:50:27.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:50:27.399+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:50:27.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:50:27.421+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:50:27.450+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:50:27.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:50:27.474+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:50:27.474+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:50:27.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.107 seconds
[2024-12-22T16:50:59.470+0000] {processor.py:186} INFO - Started process (PID=1849) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:50:59.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:50:59.473+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:50:59.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:50:59.493+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:50:59.515+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:50:59.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:50:59.534+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:50:59.534+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:50:59.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.088 seconds
[2024-12-22T16:51:32.537+0000] {processor.py:186} INFO - Started process (PID=1860) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:51:32.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:51:32.540+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:51:32.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:51:32.562+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:51:32.584+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:51:32.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:51:32.603+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:51:32.603+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:51:32.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.090 seconds
[2024-12-22T16:52:05.336+0000] {processor.py:186} INFO - Started process (PID=1872) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:52:05.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:52:05.339+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:52:05.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:52:05.362+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:52:05.385+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:52:05.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:52:05.404+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:52:05.404+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:52:05.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-22T16:52:38.317+0000] {processor.py:186} INFO - Started process (PID=1883) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:52:38.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:52:38.321+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:52:38.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:52:38.351+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:52:38.377+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:52:38.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:52:38.399+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:52:38.398+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:52:38.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.215 seconds
[2024-12-22T16:53:10.347+0000] {processor.py:186} INFO - Started process (PID=1894) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:53:10.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:53:10.350+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:53:10.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:53:10.374+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:53:10.402+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:53:10.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:53:10.431+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:53:10.431+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:53:10.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.110 seconds
[2024-12-22T16:53:43.240+0000] {processor.py:186} INFO - Started process (PID=1904) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:53:43.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:53:43.243+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:53:43.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:53:43.259+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:53:43.284+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:53:43.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:53:43.302+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:53:43.301+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:53:43.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2024-12-22T16:54:16.138+0000] {processor.py:186} INFO - Started process (PID=1915) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:54:16.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:54:16.141+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:54:16.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:54:16.162+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:54:16.185+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:54:16.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:54:16.205+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:54:16.205+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:54:16.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-22T16:54:48.116+0000] {processor.py:186} INFO - Started process (PID=1926) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:54:48.117+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:54:48.119+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:54:48.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:54:48.141+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:54:48.163+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:54:48.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:54:48.182+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:54:48.182+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:54:48.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.089 seconds
[2024-12-22T16:55:21.043+0000] {processor.py:186} INFO - Started process (PID=1937) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:55:21.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:55:21.046+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:55:21.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:55:21.070+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:55:21.093+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:55:21.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:55:21.111+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:55:21.111+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:55:21.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.091 seconds
[2024-12-22T16:55:54.066+0000] {processor.py:186} INFO - Started process (PID=1949) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:55:54.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:55:54.068+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:55:54.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:55:54.093+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:55:54.118+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:55:54.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:55:54.139+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:55:54.139+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:55:54.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.219 seconds
[2024-12-22T16:56:26.893+0000] {processor.py:186} INFO - Started process (PID=1960) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:56:26.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:56:26.895+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:56:26.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:56:26.910+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:56:26.934+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:56:26.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:56:26.953+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:56:26.953+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:56:26.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.084 seconds
[2024-12-22T16:56:58.921+0000] {processor.py:186} INFO - Started process (PID=1971) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:56:58.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:56:58.924+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:56:58.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:56:58.949+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:56:58.972+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:56:58.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:56:58.998+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:56:58.997+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:56:59.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2024-12-22T16:57:31.915+0000] {processor.py:186} INFO - Started process (PID=1982) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:57:31.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:57:31.918+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:57:31.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:57:31.942+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:57:31.984+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:57:31.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:57:32.005+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:57:32.005+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:57:32.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.117 seconds
[2024-12-22T16:58:05.027+0000] {processor.py:186} INFO - Started process (PID=1993) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:58:05.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:58:05.030+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:58:05.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:58:05.044+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:58:05.066+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:58:05.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:58:05.087+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:58:05.087+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:58:05.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.083 seconds
[2024-12-22T16:58:36.890+0000] {processor.py:186} INFO - Started process (PID=2004) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:58:36.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:58:36.895+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:58:36.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:58:36.919+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:58:36.947+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:58:36.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:58:36.968+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:58:36.968+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:58:36.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2024-12-22T16:59:09.843+0000] {processor.py:186} INFO - Started process (PID=2015) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:59:09.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:59:09.846+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:59:09.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:59:09.860+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:59:09.882+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:59:09.882+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:59:10.049+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:59:10.048+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:59:10.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.228 seconds
[2024-12-22T16:59:42.912+0000] {processor.py:186} INFO - Started process (PID=2026) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:59:42.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T16:59:42.915+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:59:42.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:59:42.941+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T16:59:42.964+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:59:42.964+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T16:59:42.985+0000] {logging_mixin.py:190} INFO - [2024-12-22T16:59:42.985+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 15:00:00+00:00, run_after=2024-12-22 16:00:00+00:00
[2024-12-22T16:59:43.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.101 seconds
[2024-12-22T17:00:16.082+0000] {processor.py:186} INFO - Started process (PID=2037) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:00:16.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:00:16.084+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:00:16.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:00:16.107+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:00:16.131+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:00:16.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:00:16.150+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:00:16.150+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:00:16.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-22T17:00:47.875+0000] {processor.py:186} INFO - Started process (PID=2048) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:00:47.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:00:47.879+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:00:47.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:00:47.902+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:00:47.926+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:00:47.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:00:47.946+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:00:47.946+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:00:47.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-22T17:01:20.904+0000] {processor.py:186} INFO - Started process (PID=2060) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:01:20.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:01:20.906+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:01:20.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:01:20.925+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:01:20.946+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:01:20.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:01:20.965+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:01:20.965+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:01:20.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.085 seconds
[2024-12-22T17:01:53.884+0000] {processor.py:186} INFO - Started process (PID=2071) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:01:53.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:01:53.887+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:01:53.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:01:53.913+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:01:53.935+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:01:53.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:01:53.953+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:01:53.953+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:01:54.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.246 seconds
[2024-12-22T17:02:25.957+0000] {processor.py:186} INFO - Started process (PID=2082) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:02:25.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:02:25.960+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:02:25.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:02:25.979+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:02:26.003+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:02:26.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:02:26.149+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:02:26.148+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:02:26.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.219 seconds
[2024-12-22T17:02:58.964+0000] {processor.py:186} INFO - Started process (PID=2093) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:02:58.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:02:58.966+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:02:58.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:02:58.992+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:02:59.013+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:02:59.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:02:59.032+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:02:59.032+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:02:59.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-22T17:03:31.846+0000] {processor.py:186} INFO - Started process (PID=2104) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:03:31.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:03:31.849+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:03:31.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:03:31.872+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:03:31.897+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:03:31.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:03:31.916+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:03:31.916+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:03:31.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2024-12-22T17:04:03.888+0000] {processor.py:186} INFO - Started process (PID=2115) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:04:03.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:04:03.892+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:04:03.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:04:03.917+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:04:03.942+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:04:03.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:04:03.961+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:04:03.961+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:04:03.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-22T17:04:36.846+0000] {processor.py:186} INFO - Started process (PID=2125) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:04:36.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:04:36.849+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:04:36.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:04:36.874+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:04:36.902+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:04:36.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:04:36.921+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:04:36.920+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:04:36.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.100 seconds
[2024-12-22T17:05:09.846+0000] {processor.py:186} INFO - Started process (PID=2136) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:05:09.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:05:09.849+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:05:09.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:05:09.868+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:05:09.890+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:05:09.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:05:09.908+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:05:09.908+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:05:10.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.232 seconds
[2024-12-22T17:05:42.030+0000] {processor.py:186} INFO - Started process (PID=2147) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:05:42.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:05:42.036+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:05:42.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:05:42.064+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:05:42.086+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:05:42.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:05:42.106+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:05:42.106+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:05:42.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.105 seconds
[2024-12-22T17:06:14.964+0000] {processor.py:186} INFO - Started process (PID=2158) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:06:14.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:06:14.966+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:06:14.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:06:14.991+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:06:15.015+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:06:15.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:06:15.034+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:06:15.033+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:06:15.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.094 seconds
[2024-12-22T17:06:48.016+0000] {processor.py:186} INFO - Started process (PID=2169) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:06:48.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:06:48.019+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:06:48.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:06:48.043+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:06:48.067+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:06:48.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:06:48.086+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:06:48.086+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:06:48.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.095 seconds
[2024-12-22T17:07:20.199+0000] {processor.py:186} INFO - Started process (PID=2179) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:07:20.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:07:20.202+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:07:20.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:07:20.225+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:07:20.248+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:07:20.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:07:20.266+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:07:20.266+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:07:20.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2024-12-22T17:07:53.225+0000] {processor.py:186} INFO - Started process (PID=2190) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:07:53.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:07:53.229+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:07:53.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:07:53.251+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:07:53.289+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:07:53.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:07:53.310+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:07:53.310+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:07:53.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.112 seconds
[2024-12-22T17:08:26.300+0000] {processor.py:186} INFO - Started process (PID=2201) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:08:26.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:08:26.304+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:08:26.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:08:26.327+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:08:26.350+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:08:26.350+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:08:26.505+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:08:26.505+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:08:26.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.233 seconds
[2024-12-22T17:08:56.607+0000] {processor.py:186} INFO - Started process (PID=2212) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:08:56.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T17:08:56.610+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:08:56.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:08:58.240+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T17:08:58.267+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:08:58.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T17:08:58.287+0000] {logging_mixin.py:190} INFO - [2024-12-22T17:08:58.287+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 16:00:00+00:00, run_after=2024-12-22 17:00:00+00:00
[2024-12-22T17:08:58.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.096 seconds
[2024-12-22T18:29:52.689+0000] {processor.py:186} INFO - Started process (PID=2217) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:29:52.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:29:52.816+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:29:52.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:29:52.977+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:29:53.097+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:29:53.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:29:53.212+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:29:53.212+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:29:53.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.654 seconds
[2024-12-22T18:30:23.659+0000] {processor.py:186} INFO - Started process (PID=2228) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:30:23.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:30:23.663+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:30:23.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:30:23.682+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:30:23.710+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:30:23.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:30:23.735+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:30:23.734+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:30:23.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.103 seconds
[2024-12-22T18:30:53.959+0000] {processor.py:186} INFO - Started process (PID=2239) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:30:53.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:30:53.967+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:30:53.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:30:54.038+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:30:54.073+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:30:54.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:30:54.104+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:30:54.104+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:30:54.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.173 seconds
[2024-12-22T18:31:24.828+0000] {processor.py:186} INFO - Started process (PID=2250) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:31:24.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:31:24.832+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:31:24.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:31:24.861+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:31:24.888+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:31:24.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:31:24.910+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:31:24.910+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:31:24.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.115 seconds
[2024-12-22T18:31:55.737+0000] {processor.py:186} INFO - Started process (PID=2261) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:31:55.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:31:55.740+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:31:55.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:31:55.767+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:31:55.791+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:31:55.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:31:55.809+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:31:55.809+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:31:55.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.241 seconds
[2024-12-22T18:32:26.726+0000] {processor.py:186} INFO - Started process (PID=2272) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:32:26.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:32:26.730+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:32:26.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:32:26.746+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:32:26.773+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:32:26.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:32:26.911+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:32:26.911+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:32:26.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.215 seconds
[2024-12-22T18:32:58.622+0000] {processor.py:186} INFO - Started process (PID=2282) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:32:58.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:32:58.628+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:32:58.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:32:58.651+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:32:58.698+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:32:58.697+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:32:58.739+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:32:58.738+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:32:58.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.157 seconds
[2024-12-22T18:33:30.647+0000] {processor.py:186} INFO - Started process (PID=2293) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:33:30.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:33:30.651+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:33:30.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:33:30.680+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:33:30.705+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:33:30.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:33:30.726+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:33:30.726+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:33:30.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.113 seconds
[2024-12-22T18:34:02.094+0000] {processor.py:186} INFO - Started process (PID=2304) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:34:02.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:34:02.101+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:34:02.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:34:02.129+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:34:02.156+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:34:02.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:34:02.178+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:34:02.178+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:34:02.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2024-12-22T18:34:32.739+0000] {processor.py:186} INFO - Started process (PID=2315) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:34:32.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:34:32.742+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:34:32.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:34:32.764+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:34:32.793+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:34:32.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:34:32.823+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:34:32.823+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:34:32.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.109 seconds
[2024-12-22T18:35:03.065+0000] {processor.py:186} INFO - Started process (PID=2326) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:35:03.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:35:03.070+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:35:03.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:35:03.101+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:35:03.136+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:35:03.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:35:03.164+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:35:03.164+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:35:03.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.311 seconds
[2024-12-22T18:35:34.046+0000] {processor.py:186} INFO - Started process (PID=2338) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:35:34.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:35:34.050+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:35:34.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:35:34.075+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:35:34.103+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:35:34.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:35:34.255+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:35:34.255+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:35:34.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.234 seconds
[2024-12-22T18:36:04.960+0000] {processor.py:186} INFO - Started process (PID=2349) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:36:04.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:36:04.964+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:36:04.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:36:04.990+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:36:05.018+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:36:05.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:36:05.041+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:36:05.041+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:36:05.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.108 seconds
[2024-12-22T18:36:35.778+0000] {processor.py:186} INFO - Started process (PID=2360) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:36:35.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:36:35.781+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:36:35.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:36:35.802+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:36:35.835+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:36:35.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:36:35.857+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:36:35.857+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:36:35.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-22T18:37:06.724+0000] {processor.py:186} INFO - Started process (PID=2371) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:37:06.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:37:06.727+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:37:06.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:37:06.750+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:37:06.772+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:37:06.772+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:37:06.792+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:37:06.791+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:37:06.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.093 seconds
[2024-12-22T18:37:37.462+0000] {processor.py:186} INFO - Started process (PID=2382) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:37:37.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:37:37.466+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:37:37.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:37:37.488+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:37:37.512+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:37:37.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:37:37.532+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:37:37.532+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:37:37.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.099 seconds
[2024-12-22T18:38:08.279+0000] {processor.py:186} INFO - Started process (PID=2393) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:38:08.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:38:08.283+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:38:08.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:38:08.306+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:38:08.335+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:38:08.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:38:08.355+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:38:08.355+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:38:08.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.214 seconds
[2024-12-22T18:38:39.079+0000] {processor.py:186} INFO - Started process (PID=2404) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:38:39.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:38:39.085+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:38:39.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:38:39.116+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:38:39.148+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:38:39.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:38:39.308+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:38:39.307+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:38:39.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.263 seconds
[2024-12-22T18:39:10.155+0000] {processor.py:186} INFO - Started process (PID=2416) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:39:10.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:39:10.160+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:39:10.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:39:10.194+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:39:10.225+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:39:10.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:39:10.251+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:39:10.251+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:39:10.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2024-12-22T18:43:11.184+0000] {processor.py:186} INFO - Started process (PID=2427) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:43:11.233+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T18:43:11.247+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:43:11.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:43:11.994+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T18:43:12.085+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:43:12.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T18:43:12.177+0000] {logging_mixin.py:190} INFO - [2024-12-22T18:43:12.176+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 17:00:00+00:00, run_after=2024-12-22 18:00:00+00:00
[2024-12-22T18:43:12.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.251 seconds
[2024-12-22T19:05:09.070+0000] {processor.py:186} INFO - Started process (PID=2432) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:05:09.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:05:09.083+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:05:09.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:05:09.131+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:05:09.211+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:05:09.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:05:09.262+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:05:09.262+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:05:09.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.226 seconds
[2024-12-22T19:05:39.842+0000] {processor.py:186} INFO - Started process (PID=2443) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:05:39.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:05:39.844+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:05:39.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:05:39.860+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:05:39.886+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:05:39.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:05:39.905+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:05:39.905+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:05:39.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.092 seconds
[2024-12-22T19:06:10.085+0000] {processor.py:186} INFO - Started process (PID=2454) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:06:10.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:06:10.088+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:06:10.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:06:10.112+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:06:10.143+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:06:10.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:06:10.171+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:06:10.170+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:06:10.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.125 seconds
[2024-12-22T19:06:40.414+0000] {processor.py:186} INFO - Started process (PID=2459) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:06:40.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:06:40.424+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:06:40.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:06:40.484+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:06:40.550+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:06:40.549+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:06:40.613+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:06:40.613+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:06:40.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.477 seconds
[2024-12-22T19:07:11.551+0000] {processor.py:186} INFO - Started process (PID=2470) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:07:11.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:07:11.560+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:07:11.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:07:11.624+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:07:11.693+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:07:11.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:07:11.875+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:07:11.875+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:07:11.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.356 seconds
[2024-12-22T19:07:42.924+0000] {processor.py:186} INFO - Started process (PID=2482) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:07:42.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:07:43.007+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:07:42.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:07:43.406+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:07:43.555+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:07:43.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:07:43.678+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:07:43.678+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:07:43.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.867 seconds
[2024-12-22T19:08:14.664+0000] {processor.py:186} INFO - Started process (PID=2493) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:08:14.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:08:14.674+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:08:14.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:08:14.741+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:08:14.810+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:08:14.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:08:14.838+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:08:14.837+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:08:14.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.221 seconds
[2024-12-22T19:08:45.380+0000] {processor.py:186} INFO - Started process (PID=2504) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:08:45.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:08:45.389+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:08:45.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:08:45.446+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:08:45.521+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:08:45.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:08:45.561+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:08:45.561+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:08:45.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.253 seconds
[2024-12-22T19:09:16.371+0000] {processor.py:186} INFO - Started process (PID=2515) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:09:16.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:09:16.380+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:09:16.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:09:16.431+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:09:16.505+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:09:16.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:09:16.572+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:09:16.572+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:09:16.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.254 seconds
[2024-12-22T19:09:47.074+0000] {processor.py:186} INFO - Started process (PID=2526) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:09:47.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:09:47.083+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:09:47.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:09:47.141+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:09:47.210+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:09:47.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:09:47.416+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:09:47.415+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:09:47.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.732 seconds
[2024-12-22T19:10:17.996+0000] {processor.py:186} INFO - Started process (PID=2537) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:10:17.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:10:18.002+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:10:18.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:10:18.044+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:10:18.087+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:10:18.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:10:18.263+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:10:18.263+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:10:18.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.313 seconds
[2024-12-22T19:10:48.774+0000] {processor.py:186} INFO - Started process (PID=2548) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:10:48.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:10:48.783+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:10:48.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:10:48.845+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:10:48.917+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:10:48.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:10:48.975+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:10:48.974+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:10:49.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.261 seconds
[2024-12-22T19:11:20.699+0000] {processor.py:186} INFO - Started process (PID=2559) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:11:20.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:11:20.708+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:11:20.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:11:20.752+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:11:20.799+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:11:20.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:11:20.821+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:11:20.821+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:11:20.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.157 seconds
[2024-12-22T19:11:52.697+0000] {processor.py:186} INFO - Started process (PID=2570) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:11:52.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:11:52.705+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:11:52.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:11:52.770+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:11:52.835+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:11:52.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:11:52.877+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:11:52.876+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:11:52.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.242 seconds
[2024-12-22T19:12:25.398+0000] {processor.py:186} INFO - Started process (PID=2581) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:12:25.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:12:25.407+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:12:25.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:12:25.459+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:12:25.525+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:12:25.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:12:25.584+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:12:25.583+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:12:25.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.249 seconds
[2024-12-22T19:12:55.961+0000] {processor.py:186} INFO - Started process (PID=2592) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:12:55.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:12:55.970+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:12:55.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:12:56.026+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:12:56.089+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:12:56.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:12:56.128+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:12:56.128+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:12:58.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.622 seconds
[2024-12-22T19:13:28.321+0000] {processor.py:186} INFO - Started process (PID=2603) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:13:28.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:13:28.329+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:13:28.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:13:28.390+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:13:29.884+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:13:29.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:13:30.123+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:13:30.123+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:13:30.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.404 seconds
[2024-12-22T19:14:02.597+0000] {processor.py:186} INFO - Started process (PID=2614) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:14:02.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:14:02.605+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:14:02.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:14:02.669+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:14:02.739+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:14:02.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:14:02.803+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:14:02.802+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:14:02.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.266 seconds
[2024-12-22T19:14:34.729+0000] {processor.py:186} INFO - Started process (PID=2624) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:14:34.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:14:34.737+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:14:34.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:14:34.796+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:14:34.837+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:14:34.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:14:34.876+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:14:34.875+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:14:34.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.189 seconds
[2024-12-22T19:15:07.561+0000] {processor.py:186} INFO - Started process (PID=2635) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:15:07.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:15:07.565+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:15:07.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:15:07.606+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:15:07.648+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:15:07.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:15:07.685+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:15:07.685+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:15:07.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.172 seconds
[2024-12-22T19:15:39.360+0000] {processor.py:186} INFO - Started process (PID=2646) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:15:39.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:15:39.376+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:15:39.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:15:39.430+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:15:39.482+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:15:39.482+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:15:39.524+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:15:39.524+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:15:39.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.222 seconds
[2024-12-22T19:16:12.218+0000] {processor.py:186} INFO - Started process (PID=2656) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:16:12.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:16:12.229+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:16:12.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:16:12.293+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:16:12.372+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:16:12.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:16:12.701+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:16:12.701+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:16:12.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.536 seconds
[2024-12-22T19:16:44.462+0000] {processor.py:186} INFO - Started process (PID=2667) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:16:44.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:16:44.470+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:16:44.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:16:44.527+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:16:44.595+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:16:44.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:16:44.818+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:16:44.818+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:16:44.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.398 seconds
[2024-12-22T19:17:16.797+0000] {processor.py:186} INFO - Started process (PID=2678) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:17:16.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:17:16.805+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:17:16.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:17:16.846+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:17:16.901+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:17:16.900+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:17:16.953+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:17:16.953+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:17:16.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.188 seconds
[2024-12-22T19:17:49.015+0000] {processor.py:186} INFO - Started process (PID=2689) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:17:49.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:17:49.025+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:17:49.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:17:49.096+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:17:49.138+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:17:49.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:17:49.174+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:17:49.174+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:17:49.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.204 seconds
[2024-12-22T19:18:21.496+0000] {processor.py:186} INFO - Started process (PID=2700) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:18:21.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:18:21.506+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:18:21.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:18:21.572+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:18:21.632+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:18:21.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:18:21.674+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:18:21.674+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:18:21.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.226 seconds
[2024-12-22T19:18:54.388+0000] {processor.py:186} INFO - Started process (PID=2711) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:18:54.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:18:54.397+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:18:54.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:18:54.439+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:18:54.497+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:18:54.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:18:54.520+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:18:54.520+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:18:54.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.349 seconds
[2024-12-22T19:19:26.219+0000] {processor.py:186} INFO - Started process (PID=2722) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:19:26.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:19:26.226+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:19:26.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:19:26.280+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:19:26.333+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:19:26.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:19:26.555+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:19:26.555+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:19:26.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.371 seconds
[2024-12-22T19:19:56.952+0000] {processor.py:186} INFO - Started process (PID=2733) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:19:56.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:19:56.959+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:19:56.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:19:57.012+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:19:57.067+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:19:57.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:19:57.238+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:19:57.238+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:19:58.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.323 seconds
[2024-12-22T19:20:29.676+0000] {processor.py:186} INFO - Started process (PID=2744) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:20:29.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:20:29.699+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:20:29.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:20:29.852+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:20:29.920+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:20:29.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:20:29.984+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:20:29.983+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:20:30.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.371 seconds
[2024-12-22T19:21:01.765+0000] {processor.py:186} INFO - Started process (PID=2755) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:21:01.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:21:01.774+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:21:01.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:21:01.838+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:21:01.908+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:21:01.908+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:21:01.971+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:21:01.971+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:21:02.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.278 seconds
[2024-12-22T19:21:32.490+0000] {processor.py:186} INFO - Started process (PID=2766) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:21:32.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:21:32.499+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:21:32.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:21:32.561+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:21:32.626+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:21:32.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:21:32.663+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:21:32.663+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:21:32.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.218 seconds
[2024-12-22T19:22:03.715+0000] {processor.py:186} INFO - Started process (PID=2777) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:22:03.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:22:03.723+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:22:03.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:22:03.781+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:22:03.845+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:22:03.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:22:03.897+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:22:03.896+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:22:04.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.435 seconds
[2024-12-22T19:22:34.463+0000] {processor.py:186} INFO - Started process (PID=2788) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:22:34.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:22:34.472+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:22:34.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:22:34.530+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:22:34.590+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:22:34.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:22:34.783+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:22:34.782+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:22:34.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.364 seconds
[2024-12-22T19:23:04.970+0000] {processor.py:186} INFO - Started process (PID=2799) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:23:04.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:23:04.979+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:23:04.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:23:05.040+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:23:05.119+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:23:05.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:23:05.346+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:23:05.346+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:23:05.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.416 seconds
[2024-12-22T19:23:36.309+0000] {processor.py:186} INFO - Started process (PID=2810) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:23:36.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:23:36.316+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:23:36.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:23:36.353+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:23:36.395+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:23:36.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:23:36.430+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:23:36.430+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:23:36.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.164 seconds
[2024-12-22T19:24:06.996+0000] {processor.py:186} INFO - Started process (PID=2822) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:24:06.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:24:07.002+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:24:07.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:24:07.050+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:24:07.094+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:24:07.094+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:24:07.125+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:24:07.125+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:24:07.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.161 seconds
[2024-12-22T19:24:37.891+0000] {processor.py:186} INFO - Started process (PID=2832) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:24:37.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:24:37.896+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:24:37.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:24:37.931+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:24:37.973+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:24:37.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:24:38.010+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:24:38.010+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:24:38.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.155 seconds
[2024-12-22T19:25:08.546+0000] {processor.py:186} INFO - Started process (PID=2843) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:25:08.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:25:08.556+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:25:08.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:25:08.611+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:25:08.671+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:25:08.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:25:08.706+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:25:08.706+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:25:08.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.339 seconds
[2024-12-22T19:25:39.218+0000] {processor.py:186} INFO - Started process (PID=2854) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:25:39.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:25:39.227+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:25:39.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:25:39.288+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:25:39.356+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:25:39.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:25:39.592+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:25:39.591+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:25:39.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.428 seconds
[2024-12-22T19:26:10.566+0000] {processor.py:186} INFO - Started process (PID=2859) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:26:10.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:26:10.574+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:26:10.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:26:10.628+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:26:10.705+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:26:10.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:26:10.900+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:26:10.900+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:26:10.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.371 seconds
[2024-12-22T19:26:41.277+0000] {processor.py:186} INFO - Started process (PID=2870) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:26:41.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:26:41.285+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:26:41.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:26:41.352+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:26:41.419+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:26:41.419+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:26:41.476+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:26:41.476+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:26:41.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.258 seconds
[2024-12-22T19:27:12.213+0000] {processor.py:186} INFO - Started process (PID=2881) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:27:12.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:27:12.216+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:27:12.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:27:12.250+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:27:12.287+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:27:12.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:27:12.331+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:27:12.331+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:27:12.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.146 seconds
[2024-12-22T19:27:43.143+0000] {processor.py:186} INFO - Started process (PID=2892) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:27:43.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:27:43.149+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:27:43.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:27:43.193+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:27:43.237+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:27:43.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:27:43.283+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:27:43.282+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:27:43.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.195 seconds
[2024-12-22T19:28:13.923+0000] {processor.py:186} INFO - Started process (PID=2903) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:28:13.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:28:13.932+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:28:13.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:28:13.996+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:28:14.068+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:28:14.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:28:14.118+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:28:14.117+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:28:14.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.373 seconds
[2024-12-22T19:28:44.825+0000] {processor.py:186} INFO - Started process (PID=2914) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:28:44.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:28:44.833+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:28:44.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:28:44.884+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:28:44.946+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:28:44.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:28:45.155+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:28:45.155+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:28:45.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.359 seconds
[2024-12-22T19:29:16.003+0000] {processor.py:186} INFO - Started process (PID=2925) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:29:16.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:29:16.009+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:29:16.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:29:16.041+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:29:16.093+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:29:16.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:29:16.233+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:29:16.233+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:29:16.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.265 seconds
[2024-12-22T19:29:46.848+0000] {processor.py:186} INFO - Started process (PID=2936) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:29:46.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:29:46.855+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:29:46.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:29:46.903+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:29:46.945+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:29:46.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:29:46.980+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:29:46.980+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:29:47.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.174 seconds
[2024-12-22T19:30:17.944+0000] {processor.py:186} INFO - Started process (PID=2947) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:30:17.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:30:17.951+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:30:17.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:30:18.004+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:30:18.064+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:30:18.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:30:18.102+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:30:18.101+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:30:18.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.202 seconds
[2024-12-22T19:30:48.511+0000] {processor.py:186} INFO - Started process (PID=2958) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:30:48.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:30:48.517+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:30:48.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:30:48.559+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:30:48.605+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:30:48.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:30:48.645+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:30:48.644+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:30:48.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.177 seconds
[2024-12-22T19:31:19.423+0000] {processor.py:186} INFO - Started process (PID=2969) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:31:19.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:31:19.433+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:31:19.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:31:19.495+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:31:19.592+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:31:19.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:31:19.656+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:31:19.656+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:31:19.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.500 seconds
[2024-12-22T19:31:51.440+0000] {processor.py:186} INFO - Started process (PID=2980) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:31:51.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:31:51.448+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:31:51.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:31:51.499+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:31:51.584+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:31:51.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:31:51.793+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:31:51.793+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:31:51.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.385 seconds
[2024-12-22T19:32:22.094+0000] {processor.py:186} INFO - Started process (PID=2992) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:32:22.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:32:22.102+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:32:22.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:32:22.168+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:32:23.726+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:32:23.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:32:23.939+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:32:23.938+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:32:23.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.423 seconds
[2024-12-22T19:32:54.853+0000] {processor.py:186} INFO - Started process (PID=3002) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:32:54.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:32:54.862+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:32:54.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:32:54.921+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:32:55.001+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:32:55.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:32:55.036+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:32:55.036+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:32:55.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.228 seconds
[2024-12-22T19:33:28.940+0000] {processor.py:186} INFO - Started process (PID=3013) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:33:28.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:33:28.948+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:33:28.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:33:29.001+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:33:29.053+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:33:29.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:33:29.105+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:33:29.105+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:33:29.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.216 seconds
[2024-12-22T19:34:00.994+0000] {processor.py:186} INFO - Started process (PID=3024) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:34:00.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:34:01.000+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:34:01.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:34:01.053+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:34:01.136+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:34:01.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:34:01.200+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:34:01.199+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:34:01.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.269 seconds
[2024-12-22T19:34:33.772+0000] {processor.py:186} INFO - Started process (PID=3035) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:34:33.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:34:33.782+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:34:33.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:34:33.847+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:34:33.932+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:34:33.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:34:34.002+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:34:34.002+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:34:34.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.463 seconds
[2024-12-22T19:35:05.920+0000] {processor.py:186} INFO - Started process (PID=3046) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:35:05.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:35:05.925+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:35:05.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:35:05.953+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:35:05.995+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:35:05.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:35:06.134+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:35:06.134+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:35:06.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.237 seconds
[2024-12-22T19:35:39.117+0000] {processor.py:186} INFO - Started process (PID=3056) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:35:39.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:35:39.126+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:35:39.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:35:39.179+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:35:39.255+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:35:39.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:35:39.432+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:35:39.431+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:35:39.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.353 seconds
[2024-12-22T19:36:11.173+0000] {processor.py:186} INFO - Started process (PID=3067) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:36:11.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:36:11.180+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:36:11.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:36:11.233+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:36:11.289+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:36:11.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:36:11.329+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:36:11.329+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:36:11.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.202 seconds
[2024-12-22T19:36:41.578+0000] {processor.py:186} INFO - Started process (PID=3078) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:36:41.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:36:41.587+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:36:41.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:36:41.649+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:36:41.730+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:36:41.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:36:41.796+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:36:41.795+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:36:41.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.276 seconds
[2024-12-22T19:37:12.372+0000] {processor.py:186} INFO - Started process (PID=3089) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:37:12.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:37:12.381+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:37:12.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:37:12.442+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:37:12.520+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:37:12.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:37:12.556+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:37:12.556+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:37:12.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.228 seconds
[2024-12-22T19:37:43.342+0000] {processor.py:186} INFO - Started process (PID=3100) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:37:43.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:37:43.351+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:37:43.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:37:43.412+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:37:43.489+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:37:43.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:37:43.554+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:37:43.554+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:37:43.755+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.427 seconds
[2024-12-22T19:38:14.044+0000] {processor.py:186} INFO - Started process (PID=3111) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:38:14.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:38:14.051+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:38:14.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:38:14.096+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:38:14.151+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:38:14.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:38:14.309+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:38:14.309+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:38:14.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.295 seconds
[2024-12-22T19:38:45.390+0000] {processor.py:186} INFO - Started process (PID=3122) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:38:45.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:38:45.397+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:38:45.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:38:45.443+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:38:45.523+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:38:45.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:38:45.797+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:38:45.796+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:38:45.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.460 seconds
[2024-12-22T19:39:16.074+0000] {processor.py:186} INFO - Started process (PID=3133) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:39:16.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:39:16.083+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:39:16.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:39:16.145+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:39:16.197+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:39:16.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:39:16.234+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:39:16.234+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:39:16.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.205 seconds
[2024-12-22T19:39:46.776+0000] {processor.py:186} INFO - Started process (PID=3144) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:39:46.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:39:46.784+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:39:46.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:39:46.844+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:39:46.921+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:39:46.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:39:46.978+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:39:46.977+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:39:47.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.264 seconds
[2024-12-22T19:40:17.727+0000] {processor.py:186} INFO - Started process (PID=3155) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:40:17.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:40:17.734+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:40:17.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:40:17.761+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:40:17.793+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:40:17.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:40:17.814+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:40:17.814+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:40:17.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.113 seconds
[2024-12-22T19:40:48.667+0000] {processor.py:186} INFO - Started process (PID=3160) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:40:48.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:40:48.677+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:40:48.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:40:48.716+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:40:48.751+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:40:48.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:40:48.797+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:40:48.797+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:40:48.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.292 seconds
[2024-12-22T19:41:19.257+0000] {processor.py:186} INFO - Started process (PID=3171) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:41:19.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:41:19.263+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:41:19.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:41:19.306+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:41:19.360+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:41:19.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:41:19.564+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:41:19.564+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:41:19.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.332 seconds
[2024-12-22T19:41:50.301+0000] {processor.py:186} INFO - Started process (PID=3182) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:41:50.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:41:50.310+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:41:50.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:41:50.372+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:41:50.452+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:41:50.452+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:41:50.726+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:41:50.726+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:41:50.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.461 seconds
[2024-12-22T19:42:21.081+0000] {processor.py:186} INFO - Started process (PID=3193) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:42:21.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:42:21.086+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:42:21.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:42:21.122+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:42:21.178+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:42:21.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:42:21.238+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:42:21.238+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:42:21.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.194 seconds
[2024-12-22T19:42:51.632+0000] {processor.py:186} INFO - Started process (PID=3204) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:42:51.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:42:51.640+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:42:51.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:42:51.697+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:42:51.797+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:42:51.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:42:51.847+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:42:51.847+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:42:51.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.252 seconds
[2024-12-22T19:43:22.520+0000] {processor.py:186} INFO - Started process (PID=3215) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:43:22.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:43:22.529+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:43:22.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:43:22.587+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:43:22.677+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:43:22.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:43:22.717+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:43:22.717+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:43:22.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.245 seconds
[2024-12-22T19:43:53.356+0000] {processor.py:186} INFO - Started process (PID=3226) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:43:53.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:43:53.364+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:43:53.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:43:53.401+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:43:53.428+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:43:53.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:43:53.448+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:43:53.448+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:43:53.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.228 seconds
[2024-12-22T19:44:24.473+0000] {processor.py:186} INFO - Started process (PID=3237) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:44:24.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:44:24.481+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:44:24.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:44:24.553+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:44:24.616+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:44:24.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:44:24.859+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:44:24.859+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:44:24.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.420 seconds
[2024-12-22T19:44:55.202+0000] {processor.py:186} INFO - Started process (PID=3247) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:44:55.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:44:55.210+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:44:55.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:44:55.256+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:44:55.291+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:44:55.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:44:55.430+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:44:55.430+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:44:55.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.252 seconds
[2024-12-22T19:45:25.892+0000] {processor.py:186} INFO - Started process (PID=3258) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:45:25.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:45:25.902+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:45:25.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:45:25.978+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:45:26.040+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:45:26.040+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:45:26.103+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:45:26.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:45:26.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.273 seconds
[2024-12-22T19:45:56.692+0000] {processor.py:186} INFO - Started process (PID=3269) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:45:56.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:45:56.698+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:45:56.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:45:56.764+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:45:56.829+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:45:56.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:45:56.885+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:45:56.885+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:45:56.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.249 seconds
[2024-12-22T19:46:27.237+0000] {processor.py:186} INFO - Started process (PID=3280) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:46:27.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:46:27.247+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:46:27.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:46:27.327+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:46:27.385+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:46:27.384+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:46:27.439+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:46:27.439+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:46:27.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.249 seconds
[2024-12-22T19:46:59.291+0000] {processor.py:186} INFO - Started process (PID=3291) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:46:59.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:46:59.299+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:46:59.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:46:59.373+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:46:59.441+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:46:59.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:46:59.504+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:46:59.504+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:46:59.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.469 seconds
[2024-12-22T19:47:31.448+0000] {processor.py:186} INFO - Started process (PID=3302) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:47:31.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:47:31.456+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:47:31.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:47:31.515+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:47:31.566+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:47:31.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:47:31.754+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:47:31.753+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:47:31.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.351 seconds
[2024-12-22T19:48:03.313+0000] {processor.py:186} INFO - Started process (PID=3313) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:48:03.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:48:03.322+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:48:03.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:48:03.394+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:48:03.462+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:48:03.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:48:03.675+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:48:03.675+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:48:03.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.393 seconds
[2024-12-22T19:48:36.082+0000] {processor.py:186} INFO - Started process (PID=3324) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:48:36.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:48:36.091+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:48:36.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:48:36.168+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:48:36.399+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:48:36.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:48:36.417+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:48:36.417+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:48:36.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.367 seconds
[2024-12-22T19:49:06.719+0000] {processor.py:186} INFO - Started process (PID=3335) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:49:06.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:49:06.727+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:49:06.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:49:06.818+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:49:06.886+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:49:06.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:49:06.944+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:49:06.943+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:49:08.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.287 seconds
[2024-12-22T19:49:38.862+0000] {processor.py:186} INFO - Started process (PID=3347) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:49:38.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:49:38.871+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:49:38.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:49:38.938+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:49:38.983+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:49:38.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:49:39.021+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:49:39.021+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:49:39.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.201 seconds
[2024-12-22T19:50:09.518+0000] {processor.py:186} INFO - Started process (PID=3358) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:50:09.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:50:09.526+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:50:09.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:50:09.584+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:50:09.660+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:50:09.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:50:09.727+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:50:09.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:50:09.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.376 seconds
[2024-12-22T19:50:40.685+0000] {processor.py:186} INFO - Started process (PID=3369) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:50:40.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:50:40.690+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:50:40.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:50:40.736+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:50:40.785+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:50:40.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:50:40.987+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:50:40.986+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:50:41.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.336 seconds
[2024-12-22T19:51:11.493+0000] {processor.py:186} INFO - Started process (PID=3380) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:51:11.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:51:11.500+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:51:11.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:51:11.582+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:51:11.638+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:51:11.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:51:11.795+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:51:11.795+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:51:11.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.335 seconds
[2024-12-22T19:51:42.511+0000] {processor.py:186} INFO - Started process (PID=3391) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:51:42.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:51:42.520+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:51:42.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:51:42.599+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:51:42.875+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:51:42.875+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:51:42.892+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:51:42.892+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:51:42.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.415 seconds
[2024-12-22T19:52:13.434+0000] {processor.py:186} INFO - Started process (PID=3402) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:52:13.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:52:13.443+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:52:13.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:52:13.516+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:52:13.582+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:52:13.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:52:13.639+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:52:13.639+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:52:13.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.268 seconds
[2024-12-22T19:52:44.457+0000] {processor.py:186} INFO - Started process (PID=3413) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:52:44.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:52:44.466+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:52:44.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:52:44.539+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:52:44.602+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:52:44.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:52:44.658+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:52:44.658+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:52:44.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.261 seconds
[2024-12-22T19:53:15.146+0000] {processor.py:186} INFO - Started process (PID=3418) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:53:15.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:53:15.155+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:53:15.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:53:15.227+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:53:15.294+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:53:15.293+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:53:15.354+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:53:15.353+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:53:15.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.445 seconds
[2024-12-22T19:53:46.092+0000] {processor.py:186} INFO - Started process (PID=3429) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:53:46.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:53:46.100+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:53:46.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:53:46.151+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:53:46.219+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:53:46.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:53:46.430+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:53:46.430+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:53:46.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.377 seconds
[2024-12-22T19:54:17.250+0000] {processor.py:186} INFO - Started process (PID=3441) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:54:17.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:54:17.259+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:54:17.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:54:17.317+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:54:17.376+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:54:17.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:54:17.537+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:54:17.537+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:54:17.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.344 seconds
[2024-12-22T19:54:48.090+0000] {processor.py:186} INFO - Started process (PID=3452) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:54:48.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:54:48.099+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:54:48.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:54:48.151+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:54:48.432+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:54:48.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:54:48.474+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:54:48.474+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:54:48.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.420 seconds
[2024-12-22T19:55:18.964+0000] {processor.py:186} INFO - Started process (PID=3464) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:55:18.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:55:18.973+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:55:18.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:55:19.036+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:55:19.111+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:55:19.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:55:19.136+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:55:19.136+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:55:19.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.206 seconds
[2024-12-22T19:55:49.859+0000] {processor.py:186} INFO - Started process (PID=3475) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:55:49.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:55:49.865+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:55:49.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:55:49.910+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:55:49.950+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:55:49.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:55:49.972+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:55:49.972+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:55:49.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.142 seconds
[2024-12-22T19:56:20.891+0000] {processor.py:186} INFO - Started process (PID=3486) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:56:20.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:56:20.899+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:56:20.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:56:20.938+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:56:20.979+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:56:20.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:56:21.015+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:56:21.014+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:56:21.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.375 seconds
[2024-12-22T19:56:51.638+0000] {processor.py:186} INFO - Started process (PID=3497) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:56:51.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:56:51.646+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:56:51.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:56:51.707+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:56:51.755+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:56:51.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:56:51.963+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:56:51.963+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:56:51.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.364 seconds
[2024-12-22T19:57:22.893+0000] {processor.py:186} INFO - Started process (PID=3508) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:57:22.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:57:22.897+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:57:22.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:57:22.930+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:57:22.962+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:57:22.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:57:23.078+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:57:23.078+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:57:23.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.207 seconds
[2024-12-22T19:57:53.648+0000] {processor.py:186} INFO - Started process (PID=3520) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:57:53.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:57:53.658+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:57:53.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:57:53.700+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:57:53.906+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:57:53.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:57:53.958+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:57:53.958+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:57:54.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.368 seconds
[2024-12-22T19:58:24.429+0000] {processor.py:186} INFO - Started process (PID=3532) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:58:24.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:58:24.438+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:58:24.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:58:24.500+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:58:24.570+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:58:24.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:58:24.629+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:58:24.628+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:58:24.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.260 seconds
[2024-12-22T19:58:54.946+0000] {processor.py:186} INFO - Started process (PID=3543) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:58:54.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:58:54.955+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:58:54.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:58:55.019+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:58:55.074+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:58:55.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:58:55.105+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:58:55.105+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:58:55.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.194 seconds
[2024-12-22T19:59:25.785+0000] {processor.py:186} INFO - Started process (PID=3553) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:59:25.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:59:25.793+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:59:25.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:59:25.851+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:59:25.920+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:59:25.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:59:25.979+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:59:25.979+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:59:26.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.425 seconds
[2024-12-22T19:59:56.389+0000] {processor.py:186} INFO - Started process (PID=3564) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:59:56.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T19:59:56.397+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:59:56.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:59:56.448+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T19:59:56.514+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:59:56.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T19:59:56.741+0000] {logging_mixin.py:190} INFO - [2024-12-22T19:59:56.741+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 18:00:00+00:00, run_after=2024-12-22 19:00:00+00:00
[2024-12-22T19:59:56.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.406 seconds
[2024-12-22T20:00:28.734+0000] {processor.py:186} INFO - Started process (PID=3575) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:00:28.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:00:28.743+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:00:28.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:00:28.803+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:00:28.868+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:00:28.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:00:29.026+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:00:29.026+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:00:29.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.322 seconds
[2024-12-22T20:01:00.961+0000] {processor.py:186} INFO - Started process (PID=3586) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:01:00.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:01:00.970+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:01:00.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:01:01.032+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:01:01.275+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:01:01.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:01:01.316+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:01:01.315+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:01:01.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.402 seconds
[2024-12-22T20:01:33.790+0000] {processor.py:186} INFO - Started process (PID=3597) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:01:33.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:01:33.799+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:01:33.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:01:33.859+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:01:33.909+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:01:33.909+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:01:33.947+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:01:33.946+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:01:33.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.210 seconds
[2024-12-22T20:02:04.260+0000] {processor.py:186} INFO - Started process (PID=3609) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:02:04.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:02:04.265+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:02:04.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:02:04.311+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:02:04.359+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:02:04.358+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:02:04.379+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:02:04.378+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:02:04.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.149 seconds
[2024-12-22T20:02:34.644+0000] {processor.py:186} INFO - Started process (PID=3619) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:02:34.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:02:34.652+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:02:34.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:02:34.710+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:02:34.777+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:02:34.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:02:34.834+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:02:34.834+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:02:35.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.433 seconds
[2024-12-22T20:03:06.669+0000] {processor.py:186} INFO - Started process (PID=3630) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:03:06.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:03:06.677+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:03:06.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:03:06.743+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:03:06.813+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:03:06.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:03:07.057+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:03:07.056+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:03:07.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.421 seconds
[2024-12-22T20:03:37.679+0000] {processor.py:186} INFO - Started process (PID=3641) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:03:37.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:03:37.686+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:03:37.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:03:37.726+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:03:37.769+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:03:37.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:03:37.936+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:03:37.936+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:03:37.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.282 seconds
[2024-12-22T20:04:08.778+0000] {processor.py:186} INFO - Started process (PID=3652) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:04:08.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:04:08.787+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:04:08.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:04:08.839+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:04:09.044+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:04:09.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:04:09.063+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:04:09.062+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:04:09.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.319 seconds
[2024-12-22T20:04:39.486+0000] {processor.py:186} INFO - Started process (PID=3663) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:04:39.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:04:39.494+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:04:39.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:04:39.550+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:04:39.608+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:04:39.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:04:39.673+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:04:39.672+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:04:39.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.258 seconds
[2024-12-22T20:05:10.403+0000] {processor.py:186} INFO - Started process (PID=3674) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:05:10.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:05:10.408+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:05:10.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:05:10.440+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:05:10.470+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:05:10.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:05:10.498+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:05:10.498+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:05:10.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.135 seconds
[2024-12-22T20:05:41.162+0000] {processor.py:186} INFO - Started process (PID=3679) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:05:41.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:05:41.169+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:05:41.168+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:05:41.232+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:05:41.296+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:05:41.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:05:41.357+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:05:41.356+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:05:41.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.471 seconds
[2024-12-22T20:06:11.905+0000] {processor.py:186} INFO - Started process (PID=3690) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:06:11.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T20:06:11.908+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:06:11.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:06:11.954+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T20:06:12.009+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:06:12.009+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T20:06:12.196+0000] {logging_mixin.py:190} INFO - [2024-12-22T20:06:12.196+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 19:00:00+00:00, run_after=2024-12-22 20:00:00+00:00
[2024-12-22T20:06:12.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.320 seconds
[2024-12-22T22:29:41.800+0000] {processor.py:186} INFO - Started process (PID=3701) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:29:41.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:29:41.829+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:29:41.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:29:42.356+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:29:42.456+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:29:42.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:29:43.054+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:29:43.053+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:29:43.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 1.168 seconds
[2024-12-22T22:30:14.373+0000] {processor.py:186} INFO - Started process (PID=3711) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:30:14.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:30:14.382+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:30:14.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:30:14.415+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:30:14.598+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:30:14.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:30:14.630+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:30:14.629+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:30:14.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.295 seconds
[2024-12-22T22:30:45.385+0000] {processor.py:186} INFO - Started process (PID=3722) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:30:45.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:30:45.390+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:30:45.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:30:45.634+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:30:45.660+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:30:45.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:30:45.695+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:30:45.695+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:30:45.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.351 seconds
[2024-12-22T22:31:16.001+0000] {processor.py:186} INFO - Started process (PID=3733) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:31:16.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:31:16.007+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:31:16.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:31:16.036+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:31:16.060+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:31:16.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:31:16.080+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:31:16.080+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:31:16.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.106 seconds
[2024-12-22T22:31:46.244+0000] {processor.py:186} INFO - Started process (PID=3744) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:31:46.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:31:46.249+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:31:46.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:31:46.278+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:31:46.319+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:31:46.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:31:46.357+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:31:46.357+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:31:46.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.159 seconds
[2024-12-22T22:32:16.711+0000] {processor.py:186} INFO - Started process (PID=3755) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:32:16.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:32:16.717+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:32:16.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:32:16.752+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:32:16.794+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:32:16.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:32:16.835+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:32:16.835+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:32:16.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.162 seconds
[2024-12-22T22:32:47.599+0000] {processor.py:186} INFO - Started process (PID=3760) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:32:47.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:32:47.608+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:32:47.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:32:47.669+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:32:47.733+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:32:47.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:32:47.814+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:32:47.814+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:32:47.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.267 seconds
[2024-12-22T22:33:17.967+0000] {processor.py:186} INFO - Started process (PID=3772) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:33:17.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:33:17.977+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:33:17.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:33:18.034+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:33:18.116+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:33:18.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:33:18.177+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:33:18.177+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:33:18.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.276 seconds
[2024-12-22T22:33:48.950+0000] {processor.py:186} INFO - Started process (PID=3783) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:33:48.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:33:48.956+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:33:48.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:33:48.992+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:33:49.036+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:33:49.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:33:49.057+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:33:49.056+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:33:49.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.144 seconds
[2024-12-22T22:34:19.498+0000] {processor.py:186} INFO - Started process (PID=3794) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:34:19.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:34:19.507+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:34:19.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:34:19.554+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:34:19.640+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:34:19.639+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:34:19.668+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:34:19.668+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:34:19.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.204 seconds
[2024-12-22T22:34:50.206+0000] {processor.py:186} INFO - Started process (PID=3805) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:34:50.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:34:50.215+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:34:50.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:34:50.271+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:34:50.335+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:34:50.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:34:50.377+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:34:50.376+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:34:50.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.215 seconds
[2024-12-22T22:35:20.800+0000] {processor.py:186} INFO - Started process (PID=3816) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:35:20.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:35:20.809+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:35:20.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:35:20.846+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:35:20.880+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:35:20.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:35:20.915+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:35:20.915+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:35:20.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.167 seconds
[2024-12-22T22:35:51.389+0000] {processor.py:186} INFO - Started process (PID=3826) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:35:51.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:35:51.397+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:35:51.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:35:51.451+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:35:51.487+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:35:51.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:35:51.516+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:35:51.516+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:35:51.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.173 seconds
[2024-12-22T22:36:22.095+0000] {processor.py:186} INFO - Started process (PID=3837) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:36:22.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T22:36:22.101+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:36:22.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:36:22.139+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T22:36:22.173+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:36:22.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T22:36:22.202+0000] {logging_mixin.py:190} INFO - [2024-12-22T22:36:22.202+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 21:00:00+00:00, run_after=2024-12-22 22:00:00+00:00
[2024-12-22T22:36:22.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.141 seconds
[2024-12-22T23:04:11.523+0000] {processor.py:186} INFO - Started process (PID=3848) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:04:11.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:04:11.538+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:04:11.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:04:11.676+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:04:11.820+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:04:11.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:04:11.975+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:04:11.966+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:04:12.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.544 seconds
[2024-12-22T23:04:42.567+0000] {processor.py:186} INFO - Started process (PID=3859) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:04:42.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:04:42.577+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:04:42.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:04:42.612+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:04:42.643+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:04:42.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:04:42.667+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:04:42.667+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:04:42.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.145 seconds
[2024-12-22T23:05:13.024+0000] {processor.py:186} INFO - Started process (PID=3864) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:05:13.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:05:13.027+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:05:13.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:05:13.052+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:05:13.086+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:05:13.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:05:13.113+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:05:13.113+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:05:13.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.124 seconds
[2024-12-22T23:05:43.454+0000] {processor.py:186} INFO - Started process (PID=3875) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:05:43.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:05:43.459+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:05:43.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:05:43.489+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:05:43.528+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:05:43.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:05:43.566+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:05:43.566+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:05:43.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.153 seconds
[2024-12-22T23:06:13.740+0000] {processor.py:186} INFO - Started process (PID=3885) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:06:13.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:06:13.748+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:06:13.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:06:13.787+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:06:13.823+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:06:13.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:06:13.847+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:06:13.846+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:06:13.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.142 seconds
[2024-12-22T23:06:44.472+0000] {processor.py:186} INFO - Started process (PID=3896) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:06:44.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:06:44.479+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:06:44.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:06:44.529+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:06:44.586+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:06:44.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:06:44.628+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:06:44.627+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:06:44.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.204 seconds
[2024-12-22T23:07:15.184+0000] {processor.py:186} INFO - Started process (PID=3908) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:07:15.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:07:15.190+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:07:15.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:07:15.223+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:07:15.266+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:07:15.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:07:15.290+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:07:15.290+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:07:15.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.140 seconds
[2024-12-22T23:07:45.998+0000] {processor.py:186} INFO - Started process (PID=3919) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:07:46.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:07:46.008+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:07:46.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:07:46.067+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:07:46.128+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:07:46.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:07:46.163+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:07:46.163+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:07:46.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.223 seconds
[2024-12-22T23:08:17.102+0000] {processor.py:186} INFO - Started process (PID=3930) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:08:17.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:08:17.111+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:08:17.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:08:17.152+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:08:17.204+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:08:17.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:08:17.251+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:08:17.251+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:08:17.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.191 seconds
[2024-12-22T23:08:47.807+0000] {processor.py:186} INFO - Started process (PID=3941) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:08:47.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:08:47.816+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:08:47.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:08:47.869+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:08:47.940+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:08:47.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:08:48.001+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:08:48.000+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:08:48.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.255 seconds
[2024-12-22T23:09:18.817+0000] {processor.py:186} INFO - Started process (PID=3952) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:09:18.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:09:18.826+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:09:18.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:09:18.873+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:09:18.929+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:09:18.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:09:18.970+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:09:18.970+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:09:19.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.225 seconds
[2024-12-22T23:09:49.927+0000] {processor.py:186} INFO - Started process (PID=3963) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:09:49.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:09:49.956+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:09:49.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:09:49.978+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:09:50.008+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:09:50.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:09:50.037+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:09:50.037+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:09:50.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.168 seconds
[2024-12-22T23:10:20.951+0000] {processor.py:186} INFO - Started process (PID=3973) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:10:20.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:10:20.958+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:10:20.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:10:21.008+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:10:21.052+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:10:21.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:10:21.093+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:10:21.093+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:10:21.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.188 seconds
[2024-12-22T23:10:51.780+0000] {processor.py:186} INFO - Started process (PID=3984) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:10:51.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:10:51.786+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:10:51.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:10:51.834+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:10:51.880+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:10:51.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:10:51.920+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:10:51.920+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:10:51.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.176 seconds
[2024-12-22T23:11:22.715+0000] {processor.py:186} INFO - Started process (PID=3995) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:11:22.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:11:22.725+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:11:22.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:11:22.778+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:11:22.820+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:11:22.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:11:22.855+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:11:22.855+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:11:22.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.184 seconds
[2024-12-22T23:11:53.505+0000] {processor.py:186} INFO - Started process (PID=4006) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:11:53.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:11:53.511+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:11:53.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:11:53.558+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:11:53.604+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:11:53.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:11:53.642+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:11:53.642+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:11:53.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.183 seconds
[2024-12-22T23:12:24.435+0000] {processor.py:186} INFO - Started process (PID=4017) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:12:24.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:12:24.444+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:12:24.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:12:24.512+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:12:24.586+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:12:24.585+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:12:24.625+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:12:24.625+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:12:24.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.238 seconds
[2024-12-22T23:12:55.349+0000] {processor.py:186} INFO - Started process (PID=4029) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:12:55.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:12:55.354+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:12:55.353+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:12:55.385+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:12:55.427+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:12:55.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:12:55.455+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:12:55.455+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:12:55.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.140 seconds
[2024-12-22T23:13:25.942+0000] {processor.py:186} INFO - Started process (PID=4040) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:13:25.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:13:25.945+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:13:25.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:13:25.980+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:13:26.067+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:13:26.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:13:26.102+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:13:26.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:13:26.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.191 seconds
[2024-12-22T23:13:56.355+0000] {processor.py:186} INFO - Started process (PID=4051) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:13:56.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:13:56.360+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:13:56.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:13:56.393+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:13:57.805+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:13:57.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:13:57.836+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:13:57.836+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:13:57.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.144 seconds
[2024-12-22T23:14:30.551+0000] {processor.py:186} INFO - Started process (PID=4062) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:14:30.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:14:30.561+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:14:30.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:14:30.623+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:14:30.696+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:14:30.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:14:30.741+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:14:30.741+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:14:30.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.236 seconds
[2024-12-22T23:15:01.049+0000] {processor.py:186} INFO - Started process (PID=4073) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:15:01.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:15:01.058+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:15:01.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:15:01.124+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:15:01.167+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:15:01.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:15:01.203+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:15:01.202+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:15:01.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.202 seconds
[2024-12-22T23:15:31.952+0000] {processor.py:186} INFO - Started process (PID=4084) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:15:31.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:15:31.958+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:15:31.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:15:31.997+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:15:32.044+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:15:32.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:15:32.083+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:15:32.083+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:15:32.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.177 seconds
[2024-12-22T23:16:02.643+0000] {processor.py:186} INFO - Started process (PID=4089) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:16:02.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:16:02.653+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:16:02.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:16:02.711+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:16:02.790+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:16:02.789+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:16:02.847+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:16:02.846+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:16:02.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.271 seconds
[2024-12-22T23:16:33.717+0000] {processor.py:186} INFO - Started process (PID=4100) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:16:33.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:16:33.727+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:16:33.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:16:33.788+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:16:33.855+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:16:33.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:16:33.892+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:16:33.891+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:16:33.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.221 seconds
[2024-12-22T23:17:04.750+0000] {processor.py:186} INFO - Started process (PID=4111) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:17:04.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:17:04.761+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:17:04.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:17:04.818+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:17:04.879+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:17:04.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:17:04.940+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:17:04.939+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:17:04.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.252 seconds
[2024-12-22T23:17:35.499+0000] {processor.py:186} INFO - Started process (PID=4122) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:17:35.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:17:35.506+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:17:35.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:17:35.545+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:17:35.590+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:17:35.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:17:35.618+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:17:35.618+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:17:35.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.158 seconds
[2024-12-22T23:18:06.259+0000] {processor.py:186} INFO - Started process (PID=4132) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:18:06.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:18:06.269+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:18:06.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:18:06.323+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:18:06.365+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:18:06.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:18:06.404+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:18:06.403+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:18:06.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.192 seconds
[2024-12-22T23:18:36.788+0000] {processor.py:186} INFO - Started process (PID=4143) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:18:36.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:18:36.794+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:18:36.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:18:36.837+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:18:36.877+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:18:36.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:18:36.916+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:18:36.916+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:18:36.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.172 seconds
[2024-12-22T23:19:07.823+0000] {processor.py:186} INFO - Started process (PID=4154) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:19:07.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:19:07.833+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:19:07.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:19:07.877+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:19:07.921+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:19:07.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:19:07.959+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:19:07.958+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:19:07.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.183 seconds
[2024-12-22T23:19:38.617+0000] {processor.py:186} INFO - Started process (PID=4164) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:19:38.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:19:38.621+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:19:38.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:19:38.642+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:19:38.669+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:19:38.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:19:38.691+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:19:38.691+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:19:38.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.104 seconds
[2024-12-22T23:20:09.512+0000] {processor.py:186} INFO - Started process (PID=4175) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:20:09.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:20:09.517+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:20:09.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:20:09.543+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:20:09.574+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:20:09.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:20:09.600+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:20:09.600+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:20:09.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.118 seconds
[2024-12-22T23:20:40.262+0000] {processor.py:186} INFO - Started process (PID=4187) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:20:40.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:20:40.271+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:20:40.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:20:40.330+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:20:40.395+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:20:40.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:20:40.454+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:20:40.453+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:20:40.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.270 seconds
[2024-12-22T23:21:10.975+0000] {processor.py:186} INFO - Started process (PID=4198) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:21:10.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:21:10.984+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:21:10.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:21:11.043+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:21:11.110+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:21:11.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:21:11.170+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:21:11.170+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:21:11.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.253 seconds
[2024-12-22T23:21:42.120+0000] {processor.py:186} INFO - Started process (PID=4209) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:21:42.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:21:42.127+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:21:42.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:21:42.174+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:21:42.219+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:21:42.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:21:42.258+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:21:42.258+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:21:42.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.180 seconds
[2024-12-22T23:22:12.908+0000] {processor.py:186} INFO - Started process (PID=4220) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:22:12.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:22:12.917+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:22:12.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:22:12.982+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:22:13.049+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:22:13.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:22:13.106+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:22:13.105+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:22:13.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.259 seconds
[2024-12-22T23:22:43.763+0000] {processor.py:186} INFO - Started process (PID=4231) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:22:43.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:22:43.773+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:22:43.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:22:43.832+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:22:43.897+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:22:43.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:22:43.955+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:22:43.954+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:22:44.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.253 seconds
[2024-12-22T23:23:14.490+0000] {processor.py:186} INFO - Started process (PID=4242) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:23:14.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:23:14.499+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:23:14.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:23:14.556+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:23:14.613+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:23:14.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:23:14.670+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:23:14.670+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:23:14.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.243 seconds
[2024-12-22T23:23:45.497+0000] {processor.py:186} INFO - Started process (PID=4253) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:23:45.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:23:45.505+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:23:45.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:23:45.568+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:23:45.635+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:23:45.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:23:45.702+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:23:45.701+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:23:45.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.269 seconds
[2024-12-22T23:24:16.402+0000] {processor.py:186} INFO - Started process (PID=4264) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:24:16.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:24:16.408+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:24:16.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:24:16.452+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:24:16.497+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:24:16.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:24:16.537+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:24:16.537+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:24:16.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.179 seconds
[2024-12-22T23:24:47.096+0000] {processor.py:186} INFO - Started process (PID=4275) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:24:47.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:24:47.106+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:24:47.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:24:47.163+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:24:47.226+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:24:47.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:24:47.289+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:24:47.289+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:24:47.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.255 seconds
[2024-12-22T23:25:17.588+0000] {processor.py:186} INFO - Started process (PID=4286) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:25:17.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:25:17.599+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:25:17.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:25:17.665+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:25:17.720+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:25:17.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:25:17.787+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:25:17.787+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:25:17.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.260 seconds
[2024-12-22T23:25:48.562+0000] {processor.py:186} INFO - Started process (PID=4291) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:25:48.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:25:48.568+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:25:48.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:25:48.613+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:25:48.563+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:25:48.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:25:48.601+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:25:48.600+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:25:50.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.189 seconds
[2024-12-22T23:26:22.731+0000] {processor.py:186} INFO - Started process (PID=4303) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:26:22.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:26:22.737+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:26:22.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:26:22.775+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:26:22.805+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:26:22.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:26:22.830+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:26:22.830+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:26:22.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.129 seconds
[2024-12-22T23:26:55.609+0000] {processor.py:186} INFO - Started process (PID=4320) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:26:55.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:26:55.617+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:26:55.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:26:55.681+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:26:55.754+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:26:55.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:26:55.819+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:26:55.818+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:26:55.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.265 seconds
[2024-12-22T23:27:25.962+0000] {processor.py:186} INFO - Started process (PID=4325) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:27:25.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:27:25.970+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:27:25.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:27:26.029+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:27:26.097+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:27:26.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:27:27.439+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:27:27.439+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:27:27.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.256 seconds
[2024-12-22T23:28:00.475+0000] {processor.py:186} INFO - Started process (PID=4342) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:28:00.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:28:00.480+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:28:00.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:28:00.518+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:28:00.567+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:28:00.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:28:00.606+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:28:00.605+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:28:00.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.170 seconds
[2024-12-22T23:28:32.044+0000] {processor.py:186} INFO - Started process (PID=4347) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:28:32.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:28:32.050+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:28:32.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:28:32.102+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:28:32.167+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:28:32.166+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:28:32.218+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:28:32.217+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:28:32.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.207 seconds
[2024-12-22T23:29:04.945+0000] {processor.py:186} INFO - Started process (PID=4364) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:29:04.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:29:04.953+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:29:04.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:29:05.013+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:29:05.076+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:29:05.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:29:05.143+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:29:05.143+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:29:05.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.279 seconds
[2024-12-22T23:29:36.861+0000] {processor.py:186} INFO - Started process (PID=4369) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:29:36.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:29:36.868+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:29:36.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:29:36.930+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:29:37.001+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:29:37.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:29:37.063+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:29:37.063+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:29:37.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.263 seconds
[2024-12-22T23:30:09.690+0000] {processor.py:186} INFO - Started process (PID=4386) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:30:09.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:30:09.695+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:30:09.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:30:09.732+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:30:09.784+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:30:09.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:30:09.813+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:30:09.813+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:30:09.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.158 seconds
[2024-12-22T23:30:41.594+0000] {processor.py:186} INFO - Started process (PID=4391) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:30:41.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:30:41.606+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:30:41.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:30:41.650+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:30:41.723+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:30:41.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:30:41.781+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:30:41.781+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:30:41.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.249 seconds
[2024-12-22T23:31:14.417+0000] {processor.py:186} INFO - Started process (PID=4402) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:31:14.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:31:14.424+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:31:14.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:31:14.465+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:31:14.531+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:31:14.531+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:31:14.578+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:31:14.578+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:31:14.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.202 seconds
[2024-12-22T23:31:46.285+0000] {processor.py:186} INFO - Started process (PID=4413) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:31:46.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:31:46.291+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:31:46.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:31:46.350+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:31:46.413+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:31:46.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:31:46.472+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:31:46.472+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:31:46.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.248 seconds
[2024-12-22T23:32:19.008+0000] {processor.py:186} INFO - Started process (PID=4424) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:32:19.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:32:19.017+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:32:19.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:32:19.078+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:32:19.147+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:32:19.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:32:19.208+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:32:19.207+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:32:19.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.266 seconds
[2024-12-22T23:32:51.185+0000] {processor.py:186} INFO - Started process (PID=4435) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:32:51.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:32:51.197+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:32:51.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:32:51.252+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:32:51.318+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:32:51.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:32:51.353+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:32:51.353+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:32:51.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.228 seconds
[2024-12-22T23:33:23.972+0000] {processor.py:186} INFO - Started process (PID=4446) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:33:23.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:33:23.982+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:33:23.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:33:24.038+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:33:24.108+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:33:24.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:33:24.171+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:33:24.170+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:33:24.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.270 seconds
[2024-12-22T23:33:55.932+0000] {processor.py:186} INFO - Started process (PID=4457) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:33:55.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:33:55.941+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:33:55.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:33:56.001+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:33:56.058+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:33:56.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:33:56.127+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:33:56.126+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:33:56.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.275 seconds
[2024-12-22T23:34:28.865+0000] {processor.py:186} INFO - Started process (PID=4468) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:34:28.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:34:28.873+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:34:28.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:34:28.936+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:34:29.004+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:34:29.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:34:29.058+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:34:29.058+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:34:29.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.259 seconds
[2024-12-22T23:35:00.614+0000] {processor.py:186} INFO - Started process (PID=4479) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:35:00.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:35:00.619+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:35:00.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:35:00.650+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:35:00.699+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:35:00.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:35:00.734+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:35:00.734+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:35:00.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.160 seconds
[2024-12-22T23:35:33.624+0000] {processor.py:186} INFO - Started process (PID=4489) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:35:33.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:35:33.632+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:35:33.631+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:35:33.695+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:35:33.771+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:35:33.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:35:33.836+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:35:33.836+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:35:33.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.270 seconds
[2024-12-22T23:36:05.480+0000] {processor.py:186} INFO - Started process (PID=4500) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:36:05.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:36:05.485+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:36:05.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:36:05.519+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:36:05.559+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:36:05.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:36:05.595+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:36:05.594+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:36:05.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.171 seconds
[2024-12-22T23:36:38.204+0000] {processor.py:186} INFO - Started process (PID=4511) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:36:38.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:36:38.213+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:36:38.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:36:38.270+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:36:38.336+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:36:38.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:36:38.396+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:36:38.396+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:36:38.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.254 seconds
[2024-12-22T23:37:10.293+0000] {processor.py:186} INFO - Started process (PID=4522) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:37:10.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:37:10.301+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:37:10.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:37:10.363+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:37:10.431+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:37:10.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:37:10.490+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:37:10.489+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:37:10.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.253 seconds
[2024-12-22T23:37:43.167+0000] {processor.py:186} INFO - Started process (PID=4533) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:37:43.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:37:43.174+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:37:43.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:37:43.222+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:37:43.266+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:37:43.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:37:43.304+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:37:43.304+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:37:43.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.183 seconds
[2024-12-22T23:38:15.036+0000] {processor.py:186} INFO - Started process (PID=4544) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:38:15.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:38:15.040+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:38:15.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:38:15.066+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:38:15.091+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:38:15.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:38:15.112+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:38:15.111+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:38:15.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.102 seconds
[2024-12-22T23:38:47.696+0000] {processor.py:186} INFO - Started process (PID=4556) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:38:47.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:38:47.703+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:38:47.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:38:47.735+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:38:47.782+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:38:47.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:38:47.823+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:38:47.822+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:38:47.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.168 seconds
[2024-12-22T23:39:18.384+0000] {processor.py:186} INFO - Started process (PID=4568) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:39:18.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:39:18.393+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:39:18.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:39:18.444+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:39:18.518+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:39:18.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:39:18.575+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:39:18.575+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:39:18.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.262 seconds
[2024-12-22T23:39:49.051+0000] {processor.py:186} INFO - Started process (PID=4579) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:39:49.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:39:49.058+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:39:49.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:39:49.105+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:39:49.155+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:39:49.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:39:49.216+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:39:49.216+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:39:49.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.206 seconds
[2024-12-22T23:40:20.051+0000] {processor.py:186} INFO - Started process (PID=4589) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:40:20.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:40:20.057+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:40:20.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:40:20.100+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:40:20.126+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:40:20.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:40:20.146+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:40:20.146+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:40:20.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.127 seconds
[2024-12-22T23:40:50.945+0000] {processor.py:186} INFO - Started process (PID=4601) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:40:50.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:40:50.953+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:40:50.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:40:51.017+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:40:51.087+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:40:51.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:40:51.135+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:40:51.135+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:40:51.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.242 seconds
[2024-12-22T23:41:21.792+0000] {processor.py:186} INFO - Started process (PID=4612) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:41:21.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:41:21.801+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:41:21.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:41:21.860+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:41:21.927+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:41:21.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:41:21.993+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:41:21.992+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:41:22.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.266 seconds
[2024-12-22T23:41:52.725+0000] {processor.py:186} INFO - Started process (PID=4623) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:41:52.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:41:52.733+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:41:52.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:41:52.795+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:41:52.865+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:41:52.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:41:52.933+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:41:52.933+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:41:52.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.277 seconds
[2024-12-22T23:42:23.467+0000] {processor.py:186} INFO - Started process (PID=4634) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:42:23.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:42:23.476+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:42:23.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:42:23.591+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:42:23.630+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:42:23.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:42:23.655+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:42:23.655+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:42:23.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.229 seconds
[2024-12-22T23:42:54.456+0000] {processor.py:186} INFO - Started process (PID=4645) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:42:54.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:42:54.462+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:42:54.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:42:54.495+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:42:54.536+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:42:54.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:42:54.574+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:42:54.574+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:42:54.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.158 seconds
[2024-12-22T23:43:25.144+0000] {processor.py:186} INFO - Started process (PID=4656) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:43:25.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:43:25.149+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:43:25.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:43:25.190+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:43:25.219+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:43:25.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:43:25.240+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:43:25.240+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:43:25.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.126 seconds
[2024-12-22T23:43:55.940+0000] {processor.py:186} INFO - Started process (PID=4667) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:43:55.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:43:55.942+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:43:55.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:43:55.959+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:43:55.988+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:43:55.987+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:43:56.008+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:43:56.008+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:43:56.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.091 seconds
[2024-12-22T23:44:26.837+0000] {processor.py:186} INFO - Started process (PID=4678) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:44:26.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:44:26.846+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:44:26.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:44:26.909+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:44:26.975+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:44:26.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:44:27.011+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:44:27.011+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:44:27.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.220 seconds
[2024-12-22T23:44:57.577+0000] {processor.py:186} INFO - Started process (PID=4689) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:44:57.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:44:57.582+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:44:57.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:44:57.627+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:44:57.672+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:44:57.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:44:57.710+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:44:57.709+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:44:57.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.175 seconds
[2024-12-22T23:45:28.350+0000] {processor.py:186} INFO - Started process (PID=4700) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:45:28.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:45:28.359+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:45:28.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:45:28.421+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:45:28.466+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:45:28.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:45:28.500+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:45:28.499+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:45:28.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.197 seconds
[2024-12-22T23:45:59.194+0000] {processor.py:186} INFO - Started process (PID=4710) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:45:59.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:45:59.199+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:45:59.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:45:59.229+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:45:59.275+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:45:59.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:45:59.336+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:45:59.335+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:45:59.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.198 seconds
[2024-12-22T23:46:30.442+0000] {processor.py:186} INFO - Started process (PID=4722) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:46:30.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:46:30.508+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:46:30.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:46:30.705+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:46:30.907+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:46:30.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:46:31.082+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:46:31.082+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:46:31.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.867 seconds
[2024-12-22T23:47:01.403+0000] {processor.py:186} INFO - Started process (PID=4733) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:47:01.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:47:01.410+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:47:01.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:47:01.453+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:47:01.571+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:47:01.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:47:01.614+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:47:01.614+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:47:01.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.261 seconds
[2024-12-22T23:47:31.980+0000] {processor.py:186} INFO - Started process (PID=4744) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:47:31.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:47:31.989+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:47:31.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:47:32.041+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:47:32.114+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:47:32.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:47:32.173+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:47:32.173+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:47:32.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.269 seconds
[2024-12-22T23:48:03.049+0000] {processor.py:186} INFO - Started process (PID=4755) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:48:03.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:48:03.056+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:48:03.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:48:03.109+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:48:03.173+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:48:03.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:48:03.232+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:48:03.231+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:48:03.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.243 seconds
[2024-12-22T23:48:33.755+0000] {processor.py:186} INFO - Started process (PID=4766) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:48:33.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:48:33.762+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:48:33.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:48:33.815+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:48:33.888+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:48:33.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:48:33.946+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:48:33.945+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:48:33.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.256 seconds
[2024-12-22T23:49:04.621+0000] {processor.py:186} INFO - Started process (PID=4771) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:49:04.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:49:04.630+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:49:04.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:49:04.689+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:49:04.751+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:49:04.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:49:04.803+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:49:04.802+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:49:04.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.245 seconds
[2024-12-22T23:49:35.702+0000] {processor.py:186} INFO - Started process (PID=4782) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:49:35.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:49:35.710+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:49:35.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:49:35.771+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:49:35.844+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:49:35.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:49:35.955+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:49:35.955+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:49:35.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.299 seconds
[2024-12-22T23:50:06.544+0000] {processor.py:186} INFO - Started process (PID=4794) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:50:06.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:50:06.553+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:50:06.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:50:07.923+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:50:07.993+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:50:07.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:50:08.055+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:50:08.055+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:50:08.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.267 seconds
[2024-12-22T23:50:40.795+0000] {processor.py:186} INFO - Started process (PID=4805) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:50:40.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:50:40.803+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:50:40.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:50:40.858+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:50:40.927+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:50:40.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:50:40.993+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:50:40.992+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:50:41.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.263 seconds
[2024-12-22T23:51:12.705+0000] {processor.py:186} INFO - Started process (PID=4816) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:51:12.706+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:51:12.709+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:51:12.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:51:12.741+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:51:12.769+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:51:12.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:51:12.791+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:51:12.790+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:51:12.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.117 seconds
[2024-12-22T23:51:45.294+0000] {processor.py:186} INFO - Started process (PID=4827) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:51:45.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:51:45.298+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:51:45.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:51:45.327+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:51:45.361+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:51:45.361+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:51:45.387+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:51:45.387+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:51:45.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.122 seconds
[2024-12-22T23:52:17.398+0000] {processor.py:186} INFO - Started process (PID=4838) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:52:17.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:52:17.407+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:52:17.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:52:17.468+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:52:17.516+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:52:17.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:52:17.576+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:52:17.575+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:52:17.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.238 seconds
[2024-12-22T23:52:50.288+0000] {processor.py:186} INFO - Started process (PID=4849) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:52:50.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:52:50.303+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:52:50.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:52:50.377+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:52:50.454+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:52:50.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:52:50.520+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:52:50.520+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:52:50.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.311 seconds
[2024-12-22T23:53:22.288+0000] {processor.py:186} INFO - Started process (PID=4861) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:53:22.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:53:22.297+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:53:22.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:53:22.361+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:53:22.421+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:53:22.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:53:22.480+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:53:22.479+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:53:22.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.256 seconds
[2024-12-22T23:53:54.851+0000] {processor.py:186} INFO - Started process (PID=4873) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:53:54.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:53:54.858+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:53:54.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:53:54.911+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:53:54.970+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:53:54.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:53:55.016+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:53:55.016+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:53:55.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.210 seconds
[2024-12-22T23:54:27.101+0000] {processor.py:186} INFO - Started process (PID=4884) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:54:27.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:54:27.108+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:54:27.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:54:27.145+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:54:27.195+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:54:27.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:54:27.244+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:54:27.244+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:54:27.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.187 seconds
[2024-12-22T23:54:59.855+0000] {processor.py:186} INFO - Started process (PID=4895) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:54:59.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:54:59.863+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:54:59.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:54:59.923+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:54:59.991+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:54:59.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:55:00.050+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:55:00.049+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:55:00.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.262 seconds
[2024-12-22T23:55:31.895+0000] {processor.py:186} INFO - Started process (PID=4906) to work on /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:55:31.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_pipeline.py for tasks to queue
[2024-12-22T23:55:31.902+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:55:31.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:55:31.952+0000] {processor.py:925} INFO - DAG(s) 'spark_job_pipeline' retrieved from /opt/airflow/dags/spark_job_pipeline.py
[2024-12-22T23:55:32.045+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:55:32.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-22T23:55:32.100+0000] {logging_mixin.py:190} INFO - [2024-12-22T23:55:32.100+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_job_pipeline to 2024-12-22 22:00:00+00:00, run_after=2024-12-22 23:00:00+00:00
[2024-12-22T23:55:32.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_pipeline.py took 0.243 seconds
